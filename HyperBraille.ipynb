{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "y1=[]\n",
    "num=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "alp=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "rootDir = \"./Braille_Dataset\"\n",
    "for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "    for fname in fileList:\n",
    "        im=load_img(dirName+\"//\"+fname)\n",
    "        im1=np.asarray(im)\n",
    "        x.append(im1)\n",
    "        y.append(fname[0])\n",
    "x_train=np.asarray(x)\n",
    "y_train=np.asarray(y)\n",
    "for i in y_train:\n",
    "    for alpha in alp:\n",
    "        if(i==alpha):\n",
    "            i=num[alp.index(alpha)]\n",
    "            y1.append(i)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "input_shape = (28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1560, 28, 28, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1560"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "tuner = kt.tuners.BayesianOptimization(\n",
    "  kt.applications.HyperResNet(input_shape=input_shape, classes=27),\n",
    "  objective='val_accuracy',\n",
    "  max_trials=3,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y1=np.array(y1)\n",
    "y1.size\n",
    "from keras.utils import to_categorical\n",
    "y_binary = to_categorical(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_binary, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1045 samples, validate on 515 samples\n",
      "Epoch 1/50\n",
      "1045/1045 [==============================] - ETA: 15:26 - loss: 5.5740 - accuracy: 0.0000e+0 - ETA: 7:32 - loss: 16.3466 - accuracy: 0.0469    - ETA: 4:54 - loss: 18.9772 - accuracy: 0.041 - ETA: 3:34 - loss: 22.2665 - accuracy: 0.031 - ETA: 2:47 - loss: 22.6929 - accuracy: 0.031 - ETA: 2:15 - loss: 22.4814 - accuracy: 0.031 - ETA: 1:52 - loss: 20.9736 - accuracy: 0.035 - ETA: 1:35 - loss: 21.1014 - accuracy: 0.031 - ETA: 1:21 - loss: 22.9809 - accuracy: 0.048 - ETA: 1:11 - loss: 21.4173 - accuracy: 0.046 - ETA: 1:02 - loss: 21.6664 - accuracy: 0.045 - ETA: 54s - loss: 21.4215 - accuracy: 0.049 - ETA: 48s - loss: 22.8268 - accuracy: 0.04 - ETA: 43s - loss: 21.9795 - accuracy: 0.04 - ETA: 38s - loss: 21.6427 - accuracy: 0.04 - ETA: 34s - loss: 21.6971 - accuracy: 0.04 - ETA: 30s - loss: 21.5766 - accuracy: 0.04 - ETA: 27s - loss: 21.2504 - accuracy: 0.04 - ETA: 24s - loss: 21.4965 - accuracy: 0.04 - ETA: 21s - loss: 21.2791 - accuracy: 0.04 - ETA: 18s - loss: 21.1125 - accuracy: 0.04 - ETA: 16s - loss: 20.9948 - accuracy: 0.04 - ETA: 14s - loss: 21.2344 - accuracy: 0.04 - ETA: 12s - loss: 22.1906 - accuracy: 0.04 - ETA: 10s - loss: 21.6808 - accuracy: 0.04 - ETA: 9s - loss: 21.4777 - accuracy: 0.0505 - ETA: 7s - loss: 21.3704 - accuracy: 0.048 - ETA: 5s - loss: 21.1996 - accuracy: 0.049 - ETA: 4s - loss: 21.5517 - accuracy: 0.049 - ETA: 3s - loss: 21.0709 - accuracy: 0.049 - ETA: 1s - loss: 20.8801 - accuracy: 0.048 - ETA: 0s - loss: 20.7789 - accuracy: 0.047 - 50s 48ms/sample - loss: 20.7807 - accuracy: 0.0469 - val_loss: 1375740824210955.0000 - val_accuracy: 0.0330\n",
      "Epoch 2/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 16.4649 - accuracy: 0.062 - ETA: 7s - loss: 16.7525 - accuracy: 0.093 - ETA: 6s - loss: 16.6680 - accuracy: 0.072 - ETA: 6s - loss: 17.6021 - accuracy: 0.085 - ETA: 6s - loss: 16.1006 - accuracy: 0.075 - ETA: 6s - loss: 16.0568 - accuracy: 0.078 - ETA: 6s - loss: 17.1068 - accuracy: 0.098 - ETA: 5s - loss: 16.1423 - accuracy: 0.089 - ETA: 5s - loss: 15.8478 - accuracy: 0.093 - ETA: 5s - loss: 15.7156 - accuracy: 0.090 - ETA: 5s - loss: 15.6686 - accuracy: 0.088 - ETA: 4s - loss: 15.7569 - accuracy: 0.085 - ETA: 4s - loss: 16.1778 - accuracy: 0.084 - ETA: 4s - loss: 15.3467 - accuracy: 0.084 - ETA: 4s - loss: 15.9184 - accuracy: 0.089 - ETA: 3s - loss: 15.1991 - accuracy: 0.089 - ETA: 3s - loss: 15.1595 - accuracy: 0.091 - ETA: 3s - loss: 15.3714 - accuracy: 0.090 - ETA: 3s - loss: 15.6218 - accuracy: 0.088 - ETA: 2s - loss: 15.3165 - accuracy: 0.087 - ETA: 2s - loss: 15.4883 - accuracy: 0.093 - ETA: 2s - loss: 14.9585 - accuracy: 0.090 - ETA: 2s - loss: 15.3655 - accuracy: 0.091 - ETA: 2s - loss: 14.8617 - accuracy: 0.091 - ETA: 1s - loss: 14.5047 - accuracy: 0.090 - ETA: 1s - loss: 14.4941 - accuracy: 0.090 - ETA: 1s - loss: 14.5614 - accuracy: 0.092 - ETA: 1s - loss: 14.3241 - accuracy: 0.092 - ETA: 0s - loss: 14.4986 - accuracy: 0.093 - ETA: 0s - loss: 14.5890 - accuracy: 0.092 - ETA: 0s - loss: 14.3153 - accuracy: 0.091 - ETA: 0s - loss: 14.3151 - accuracy: 0.089 - 15s 14ms/sample - loss: 14.3495 - accuracy: 0.0880 - val_loss: 3830883193.7864 - val_accuracy: 0.0388\n",
      "Epoch 3/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 13.3194 - accuracy: 0.031 - ETA: 7s - loss: 12.6925 - accuracy: 0.078 - ETA: 7s - loss: 12.5060 - accuracy: 0.083 - ETA: 6s - loss: 12.3626 - accuracy: 0.078 - ETA: 6s - loss: 12.3408 - accuracy: 0.081 - ETA: 6s - loss: 10.8348 - accuracy: 0.088 - ETA: 6s - loss: 10.9064 - accuracy: 0.084 - ETA: 5s - loss: 11.2900 - accuracy: 0.089 - ETA: 5s - loss: 11.7999 - accuracy: 0.090 - ETA: 5s - loss: 10.8876 - accuracy: 0.103 - ETA: 5s - loss: 10.6627 - accuracy: 0.099 - ETA: 4s - loss: 10.8226 - accuracy: 0.099 - ETA: 4s - loss: 11.1327 - accuracy: 0.091 - ETA: 4s - loss: 11.4874 - accuracy: 0.084 - ETA: 4s - loss: 11.1231 - accuracy: 0.083 - ETA: 3s - loss: 11.2633 - accuracy: 0.080 - ETA: 3s - loss: 11.3256 - accuracy: 0.075 - ETA: 3s - loss: 11.3790 - accuracy: 0.071 - ETA: 3s - loss: 11.3362 - accuracy: 0.070 - ETA: 2s - loss: 11.3521 - accuracy: 0.068 - ETA: 2s - loss: 11.3978 - accuracy: 0.065 - ETA: 2s - loss: 11.3686 - accuracy: 0.063 - ETA: 2s - loss: 11.0390 - accuracy: 0.063 - ETA: 2s - loss: 11.0949 - accuracy: 0.062 - ETA: 1s - loss: 11.0309 - accuracy: 0.062 - ETA: 1s - loss: 11.1336 - accuracy: 0.063 - ETA: 1s - loss: 11.0272 - accuracy: 0.063 - ETA: 1s - loss: 11.0536 - accuracy: 0.063 - ETA: 0s - loss: 11.0149 - accuracy: 0.064 - ETA: 0s - loss: 10.9691 - accuracy: 0.063 - ETA: 0s - loss: 10.9205 - accuracy: 0.063 - ETA: 0s - loss: 11.0237 - accuracy: 0.063 - 9s 8ms/sample - loss: 11.0291 - accuracy: 0.0622 - val_loss: 1050301.8845 - val_accuracy: 0.0272\n",
      "Epoch 4/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 16.0305 - accuracy: 0.125 - ETA: 7s - loss: 9.5517 - accuracy: 0.125 - ETA: 7s - loss: 8.1269 - accuracy: 0.10 - ETA: 6s - loss: 6.8448 - accuracy: 0.11 - ETA: 6s - loss: 7.4607 - accuracy: 0.11 - ETA: 6s - loss: 8.8732 - accuracy: 0.10 - ETA: 6s - loss: 8.0332 - accuracy: 0.10 - ETA: 5s - loss: 8.2422 - accuracy: 0.10 - ETA: 5s - loss: 8.1623 - accuracy: 0.09 - ETA: 5s - loss: 8.2821 - accuracy: 0.09 - ETA: 5s - loss: 8.7207 - accuracy: 0.08 - ETA: 4s - loss: 9.8721 - accuracy: 0.08 - ETA: 4s - loss: 10.0601 - accuracy: 0.084 - ETA: 4s - loss: 11.1475 - accuracy: 0.080 - ETA: 4s - loss: 11.9364 - accuracy: 0.087 - ETA: 3s - loss: 13.2061 - accuracy: 0.087 - ETA: 3s - loss: 13.8702 - accuracy: 0.086 - ETA: 3s - loss: 14.4077 - accuracy: 0.085 - ETA: 3s - loss: 14.4669 - accuracy: 0.083 - ETA: 2s - loss: 14.4104 - accuracy: 0.084 - ETA: 2s - loss: 14.3485 - accuracy: 0.087 - ETA: 2s - loss: 14.0033 - accuracy: 0.085 - ETA: 2s - loss: 14.6028 - accuracy: 0.088 - ETA: 2s - loss: 14.1994 - accuracy: 0.085 - ETA: 1s - loss: 14.1595 - accuracy: 0.082 - ETA: 1s - loss: 13.9693 - accuracy: 0.082 - ETA: 1s - loss: 13.8813 - accuracy: 0.082 - ETA: 1s - loss: 13.5486 - accuracy: 0.085 - ETA: 0s - loss: 13.4442 - accuracy: 0.085 - ETA: 0s - loss: 13.1569 - accuracy: 0.083 - ETA: 0s - loss: 13.0336 - accuracy: 0.082 - ETA: 0s - loss: 13.0596 - accuracy: 0.082 - 9s 8ms/sample - loss: 13.1398 - accuracy: 0.0804 - val_loss: 6729.6998 - val_accuracy: 0.0311\n",
      "Epoch 5/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 13.8477 - accuracy: 0.0000e+0 - ETA: 7s - loss: 11.9523 - accuracy: 0.0156    - ETA: 6s - loss: 10.4043 - accuracy: 0.031 - ETA: 6s - loss: 10.2002 - accuracy: 0.039 - ETA: 6s - loss: 10.0922 - accuracy: 0.037 - ETA: 6s - loss: 9.1093 - accuracy: 0.046 - ETA: 6s - loss: 10.1789 - accuracy: 0.049 - ETA: 5s - loss: 10.2617 - accuracy: 0.050 - ETA: 5s - loss: 10.0336 - accuracy: 0.045 - ETA: 5s - loss: 10.0021 - accuracy: 0.046 - ETA: 5s - loss: 10.3701 - accuracy: 0.045 - ETA: 4s - loss: 10.2008 - accuracy: 0.041 - ETA: 4s - loss: 10.1236 - accuracy: 0.045 - ETA: 4s - loss: 10.2316 - accuracy: 0.051 - ETA: 4s - loss: 9.9116 - accuracy: 0.052 - ETA: 3s - loss: 10.0687 - accuracy: 0.054 - ETA: 3s - loss: 9.9585 - accuracy: 0.053 - ETA: 3s - loss: 10.0496 - accuracy: 0.053 - ETA: 3s - loss: 10.0367 - accuracy: 0.055 - ETA: 2s - loss: 9.9278 - accuracy: 0.054 - ETA: 2s - loss: 9.9962 - accuracy: 0.05 - ETA: 2s - loss: 9.9398 - accuracy: 0.05 - ETA: 2s - loss: 9.9316 - accuracy: 0.05 - ETA: 2s - loss: 9.8419 - accuracy: 0.05 - ETA: 1s - loss: 9.6989 - accuracy: 0.05 - ETA: 1s - loss: 9.6654 - accuracy: 0.06 - ETA: 1s - loss: 9.6804 - accuracy: 0.06 - ETA: 1s - loss: 9.7407 - accuracy: 0.05 - ETA: 0s - loss: 9.6967 - accuracy: 0.06 - ETA: 0s - loss: 9.6944 - accuracy: 0.05 - ETA: 0s - loss: 9.6888 - accuracy: 0.06 - ETA: 0s - loss: 9.6894 - accuracy: 0.05 - 9s 8ms/sample - loss: 9.7712 - accuracy: 0.0593 - val_loss: 229.9668 - val_accuracy: 0.0330\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 8.6087 - accuracy: 0.09 - ETA: 7s - loss: 8.6439 - accuracy: 0.07 - ETA: 7s - loss: 10.2806 - accuracy: 0.052 - ETA: 6s - loss: 9.8332 - accuracy: 0.046 - ETA: 6s - loss: 9.3605 - accuracy: 0.05 - ETA: 6s - loss: 10.1660 - accuracy: 0.041 - ETA: 6s - loss: 9.5574 - accuracy: 0.053 - ETA: 5s - loss: 9.5354 - accuracy: 0.05 - ETA: 5s - loss: 9.5883 - accuracy: 0.05 - ETA: 5s - loss: 9.5109 - accuracy: 0.05 - ETA: 5s - loss: 9.3960 - accuracy: 0.04 - ETA: 4s - loss: 9.0902 - accuracy: 0.04 - ETA: 4s - loss: 9.0491 - accuracy: 0.04 - ETA: 4s - loss: 9.0697 - accuracy: 0.04 - ETA: 4s - loss: 9.1313 - accuracy: 0.04 - ETA: 3s - loss: 8.8225 - accuracy: 0.04 - ETA: 3s - loss: 8.9598 - accuracy: 0.04 - ETA: 3s - loss: 8.9480 - accuracy: 0.05 - ETA: 3s - loss: 8.8517 - accuracy: 0.04 - ETA: 2s - loss: 8.8907 - accuracy: 0.05 - ETA: 2s - loss: 8.8573 - accuracy: 0.05 - ETA: 2s - loss: 8.7253 - accuracy: 0.05 - ETA: 2s - loss: 8.8404 - accuracy: 0.05 - ETA: 2s - loss: 8.7561 - accuracy: 0.04 - ETA: 1s - loss: 8.7473 - accuracy: 0.04 - ETA: 1s - loss: 8.8595 - accuracy: 0.04 - ETA: 1s - loss: 8.8089 - accuracy: 0.04 - ETA: 1s - loss: 8.7100 - accuracy: 0.04 - ETA: 0s - loss: 8.7481 - accuracy: 0.04 - ETA: 0s - loss: 8.6465 - accuracy: 0.04 - ETA: 0s - loss: 8.7310 - accuracy: 0.04 - ETA: 0s - loss: 8.6022 - accuracy: 0.04 - 14s 13ms/sample - loss: 8.6703 - accuracy: 0.0469 - val_loss: 7689.9413 - val_accuracy: 0.0524\n",
      "Epoch 7/50\n",
      "1045/1045 [==============================] - ETA: 8s - loss: 7.6018 - accuracy: 0.03 - ETA: 7s - loss: 6.8463 - accuracy: 0.01 - ETA: 7s - loss: 5.5718 - accuracy: 0.05 - ETA: 7s - loss: 4.9786 - accuracy: 0.07 - ETA: 6s - loss: 5.7022 - accuracy: 0.07 - ETA: 6s - loss: 5.6884 - accuracy: 0.06 - ETA: 6s - loss: 6.1113 - accuracy: 0.07 - ETA: 5s - loss: 5.9260 - accuracy: 0.06 - ETA: 5s - loss: 6.2321 - accuracy: 0.07 - ETA: 5s - loss: 6.3772 - accuracy: 0.07 - ETA: 5s - loss: 6.4288 - accuracy: 0.07 - ETA: 4s - loss: 6.4549 - accuracy: 0.08 - ETA: 4s - loss: 6.7789 - accuracy: 0.08 - ETA: 4s - loss: 6.5213 - accuracy: 0.08 - ETA: 4s - loss: 6.5757 - accuracy: 0.07 - ETA: 3s - loss: 6.5422 - accuracy: 0.08 - ETA: 3s - loss: 6.5922 - accuracy: 0.07 - ETA: 3s - loss: 6.5717 - accuracy: 0.07 - ETA: 3s - loss: 6.6486 - accuracy: 0.07 - ETA: 2s - loss: 6.6807 - accuracy: 0.07 - ETA: 2s - loss: 6.7672 - accuracy: 0.07 - ETA: 2s - loss: 6.7619 - accuracy: 0.07 - ETA: 2s - loss: 6.7991 - accuracy: 0.06 - ETA: 2s - loss: 6.7141 - accuracy: 0.06 - ETA: 1s - loss: 6.7661 - accuracy: 0.06 - ETA: 1s - loss: 6.9130 - accuracy: 0.06 - ETA: 1s - loss: 6.8430 - accuracy: 0.06 - ETA: 1s - loss: 6.8467 - accuracy: 0.06 - ETA: 0s - loss: 6.9013 - accuracy: 0.06 - ETA: 0s - loss: 6.9069 - accuracy: 0.06 - ETA: 0s - loss: 6.8723 - accuracy: 0.06 - ETA: 0s - loss: 6.8584 - accuracy: 0.06 - 9s 8ms/sample - loss: 6.9306 - accuracy: 0.0622 - val_loss: 482.7138 - val_accuracy: 0.0388\n",
      "Epoch 8/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 7.5124 - accuracy: 0.06 - ETA: 7s - loss: 6.6790 - accuracy: 0.04 - ETA: 7s - loss: 6.9261 - accuracy: 0.07 - ETA: 6s - loss: 6.9048 - accuracy: 0.05 - ETA: 6s - loss: 6.8420 - accuracy: 0.07 - ETA: 6s - loss: 6.2494 - accuracy: 0.07 - ETA: 6s - loss: 6.5125 - accuracy: 0.07 - ETA: 5s - loss: 6.5786 - accuracy: 0.07 - ETA: 5s - loss: 6.1844 - accuracy: 0.09 - ETA: 5s - loss: 6.1593 - accuracy: 0.09 - ETA: 5s - loss: 6.3111 - accuracy: 0.09 - ETA: 4s - loss: 6.2765 - accuracy: 0.09 - ETA: 4s - loss: 6.3478 - accuracy: 0.08 - ETA: 4s - loss: 6.4485 - accuracy: 0.08 - ETA: 4s - loss: 6.4673 - accuracy: 0.08 - ETA: 3s - loss: 6.5151 - accuracy: 0.08 - ETA: 3s - loss: 6.4937 - accuracy: 0.08 - ETA: 3s - loss: 6.4876 - accuracy: 0.08 - ETA: 3s - loss: 6.5215 - accuracy: 0.08 - ETA: 2s - loss: 6.3860 - accuracy: 0.08 - ETA: 2s - loss: 6.3993 - accuracy: 0.08 - ETA: 2s - loss: 6.4073 - accuracy: 0.08 - ETA: 2s - loss: 6.4679 - accuracy: 0.08 - ETA: 2s - loss: 6.4450 - accuracy: 0.08 - ETA: 1s - loss: 6.4722 - accuracy: 0.08 - ETA: 1s - loss: 6.4594 - accuracy: 0.08 - ETA: 1s - loss: 6.4805 - accuracy: 0.07 - ETA: 1s - loss: 6.4866 - accuracy: 0.07 - ETA: 0s - loss: 6.4790 - accuracy: 0.07 - ETA: 0s - loss: 6.5161 - accuracy: 0.07 - ETA: 0s - loss: 6.5498 - accuracy: 0.07 - ETA: 0s - loss: 6.5613 - accuracy: 0.07 - 9s 8ms/sample - loss: 6.4906 - accuracy: 0.0766 - val_loss: 36.3615 - val_accuracy: 0.0427\n",
      "Epoch 9/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 6.3885 - accuracy: 0.15 - ETA: 7s - loss: 6.6883 - accuracy: 0.07 - ETA: 7s - loss: 6.4313 - accuracy: 0.06 - ETA: 6s - loss: 6.5484 - accuracy: 0.05 - ETA: 6s - loss: 6.7210 - accuracy: 0.05 - ETA: 6s - loss: 6.8472 - accuracy: 0.05 - ETA: 6s - loss: 6.6771 - accuracy: 0.05 - ETA: 5s - loss: 6.4838 - accuracy: 0.07 - ETA: 5s - loss: 6.6510 - accuracy: 0.07 - ETA: 5s - loss: 6.6330 - accuracy: 0.07 - ETA: 5s - loss: 6.5999 - accuracy: 0.07 - ETA: 4s - loss: 6.5701 - accuracy: 0.07 - ETA: 4s - loss: 6.2977 - accuracy: 0.08 - ETA: 4s - loss: 6.3581 - accuracy: 0.07 - ETA: 4s - loss: 6.3982 - accuracy: 0.07 - ETA: 3s - loss: 6.3725 - accuracy: 0.07 - ETA: 3s - loss: 6.3607 - accuracy: 0.07 - ETA: 3s - loss: 6.4861 - accuracy: 0.07 - ETA: 3s - loss: 6.5134 - accuracy: 0.07 - ETA: 2s - loss: 6.4788 - accuracy: 0.07 - ETA: 2s - loss: 6.6188 - accuracy: 0.06 - ETA: 2s - loss: 6.5665 - accuracy: 0.06 - ETA: 2s - loss: 6.6037 - accuracy: 0.06 - ETA: 2s - loss: 6.5617 - accuracy: 0.06 - ETA: 1s - loss: 6.5823 - accuracy: 0.06 - ETA: 1s - loss: 6.6027 - accuracy: 0.06 - ETA: 1s - loss: 6.5557 - accuracy: 0.06 - ETA: 1s - loss: 6.5645 - accuracy: 0.06 - ETA: 0s - loss: 6.6084 - accuracy: 0.06 - ETA: 0s - loss: 6.4930 - accuracy: 0.06 - ETA: 0s - loss: 6.4764 - accuracy: 0.06 - ETA: 0s - loss: 6.3830 - accuracy: 0.06 - 9s 8ms/sample - loss: 6.3899 - accuracy: 0.0689 - val_loss: 3.4040 - val_accuracy: 0.0408\n",
      "Epoch 10/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 7.3476 - accuracy: 0.03 - ETA: 7s - loss: 7.9527 - accuracy: 0.01 - ETA: 7s - loss: 6.9081 - accuracy: 0.04 - ETA: 6s - loss: 6.9149 - accuracy: 0.06 - ETA: 6s - loss: 6.7410 - accuracy: 0.06 - ETA: 6s - loss: 6.7082 - accuracy: 0.06 - ETA: 6s - loss: 6.8077 - accuracy: 0.06 - ETA: 5s - loss: 6.6628 - accuracy: 0.07 - ETA: 5s - loss: 6.6519 - accuracy: 0.06 - ETA: 5s - loss: 6.7464 - accuracy: 0.06 - ETA: 5s - loss: 6.7406 - accuracy: 0.07 - ETA: 4s - loss: 6.6710 - accuracy: 0.06 - ETA: 4s - loss: 6.7070 - accuracy: 0.06 - ETA: 4s - loss: 6.4717 - accuracy: 0.06 - ETA: 4s - loss: 6.3523 - accuracy: 0.06 - ETA: 3s - loss: 6.3782 - accuracy: 0.06 - ETA: 3s - loss: 6.5219 - accuracy: 0.06 - ETA: 3s - loss: 6.3951 - accuracy: 0.06 - ETA: 3s - loss: 6.4606 - accuracy: 0.06 - ETA: 2s - loss: 6.4697 - accuracy: 0.06 - ETA: 2s - loss: 6.4272 - accuracy: 0.06 - ETA: 2s - loss: 6.4470 - accuracy: 0.06 - ETA: 2s - loss: 6.5195 - accuracy: 0.06 - ETA: 2s - loss: 6.4376 - accuracy: 0.06 - ETA: 1s - loss: 6.4112 - accuracy: 0.06 - ETA: 1s - loss: 6.4255 - accuracy: 0.06 - ETA: 1s - loss: 6.4603 - accuracy: 0.07 - ETA: 1s - loss: 6.4771 - accuracy: 0.07 - ETA: 0s - loss: 6.3923 - accuracy: 0.07 - ETA: 0s - loss: 6.4482 - accuracy: 0.07 - ETA: 0s - loss: 6.3882 - accuracy: 0.07 - ETA: 0s - loss: 6.3991 - accuracy: 0.07 - 9s 8ms/sample - loss: 6.3996 - accuracy: 0.0737 - val_loss: 9.2164 - val_accuracy: 0.0291\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 2.9353 - accuracy: 0.21 - ETA: 7s - loss: 6.1280 - accuracy: 0.17 - ETA: 7s - loss: 5.4963 - accuracy: 0.13 - ETA: 7s - loss: 4.8450 - accuracy: 0.12 - ETA: 6s - loss: 5.4086 - accuracy: 0.12 - ETA: 6s - loss: 5.4033 - accuracy: 0.10 - ETA: 6s - loss: 5.0841 - accuracy: 0.10 - ETA: 5s - loss: 5.4417 - accuracy: 0.10 - ETA: 5s - loss: 5.6072 - accuracy: 0.10 - ETA: 5s - loss: 5.7324 - accuracy: 0.10 - ETA: 5s - loss: 5.6992 - accuracy: 0.09 - ETA: 4s - loss: 5.6594 - accuracy: 0.09 - ETA: 4s - loss: 5.7623 - accuracy: 0.09 - ETA: 4s - loss: 5.8484 - accuracy: 0.09 - ETA: 4s - loss: 5.8041 - accuracy: 0.08 - ETA: 3s - loss: 5.8507 - accuracy: 0.08 - ETA: 3s - loss: 5.9082 - accuracy: 0.08 - ETA: 3s - loss: 5.8428 - accuracy: 0.08 - ETA: 3s - loss: 5.9110 - accuracy: 0.09 - ETA: 3s - loss: 5.9025 - accuracy: 0.09 - ETA: 2s - loss: 5.9074 - accuracy: 0.09 - ETA: 2s - loss: 5.9587 - accuracy: 0.09 - ETA: 2s - loss: 5.9467 - accuracy: 0.09 - ETA: 2s - loss: 5.9268 - accuracy: 0.09 - ETA: 1s - loss: 6.0040 - accuracy: 0.09 - ETA: 1s - loss: 5.9401 - accuracy: 0.09 - ETA: 1s - loss: 6.0002 - accuracy: 0.09 - ETA: 1s - loss: 5.9745 - accuracy: 0.09 - ETA: 0s - loss: 5.9866 - accuracy: 0.09 - ETA: 0s - loss: 5.9518 - accuracy: 0.09 - ETA: 0s - loss: 5.9947 - accuracy: 0.09 - ETA: 0s - loss: 5.9423 - accuracy: 0.09 - 13s 13ms/sample - loss: 5.9634 - accuracy: 0.0919 - val_loss: 4.3252 - val_accuracy: 0.0563\n",
      "Epoch 12/50\n",
      "1045/1045 [==============================] - ETA: 8s - loss: 5.9603 - accuracy: 0.06 - ETA: 7s - loss: 6.8173 - accuracy: 0.04 - ETA: 7s - loss: 5.8924 - accuracy: 0.03 - ETA: 6s - loss: 6.3148 - accuracy: 0.03 - ETA: 6s - loss: 6.3659 - accuracy: 0.03 - ETA: 6s - loss: 6.2829 - accuracy: 0.05 - ETA: 6s - loss: 5.8291 - accuracy: 0.06 - ETA: 5s - loss: 5.9167 - accuracy: 0.07 - ETA: 5s - loss: 5.8144 - accuracy: 0.07 - ETA: 5s - loss: 5.8471 - accuracy: 0.06 - ETA: 5s - loss: 5.7620 - accuracy: 0.07 - ETA: 4s - loss: 5.6753 - accuracy: 0.07 - ETA: 4s - loss: 5.7480 - accuracy: 0.07 - ETA: 4s - loss: 5.7464 - accuracy: 0.07 - ETA: 4s - loss: 5.8225 - accuracy: 0.07 - ETA: 3s - loss: 5.9139 - accuracy: 0.07 - ETA: 3s - loss: 5.8356 - accuracy: 0.07 - ETA: 3s - loss: 5.8912 - accuracy: 0.07 - ETA: 3s - loss: 5.7300 - accuracy: 0.08 - ETA: 3s - loss: 5.7359 - accuracy: 0.07 - ETA: 2s - loss: 5.6952 - accuracy: 0.07 - ETA: 2s - loss: 5.7679 - accuracy: 0.07 - ETA: 2s - loss: 5.7048 - accuracy: 0.07 - ETA: 2s - loss: 5.7454 - accuracy: 0.07 - ETA: 1s - loss: 5.7453 - accuracy: 0.07 - ETA: 1s - loss: 5.7547 - accuracy: 0.07 - ETA: 1s - loss: 5.7801 - accuracy: 0.08 - ETA: 1s - loss: 5.7529 - accuracy: 0.08 - ETA: 0s - loss: 5.7665 - accuracy: 0.07 - ETA: 0s - loss: 5.7631 - accuracy: 0.07 - ETA: 0s - loss: 5.7383 - accuracy: 0.07 - ETA: 0s - loss: 5.7738 - accuracy: 0.07 - 9s 8ms/sample - loss: 5.7835 - accuracy: 0.0775 - val_loss: 3.4408 - val_accuracy: 0.0350\n",
      "Epoch 13/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.0100 - accuracy: 0.18 - ETA: 7s - loss: 4.6981 - accuracy: 0.17 - ETA: 7s - loss: 5.3053 - accuracy: 0.13 - ETA: 6s - loss: 5.3845 - accuracy: 0.12 - ETA: 6s - loss: 5.3906 - accuracy: 0.11 - ETA: 6s - loss: 5.2911 - accuracy: 0.12 - ETA: 6s - loss: 5.4115 - accuracy: 0.12 - ETA: 5s - loss: 5.5247 - accuracy: 0.12 - ETA: 5s - loss: 5.5982 - accuracy: 0.12 - ETA: 5s - loss: 5.4790 - accuracy: 0.12 - ETA: 5s - loss: 5.5933 - accuracy: 0.11 - ETA: 4s - loss: 5.5922 - accuracy: 0.11 - ETA: 4s - loss: 5.5614 - accuracy: 0.11 - ETA: 4s - loss: 5.7069 - accuracy: 0.11 - ETA: 4s - loss: 5.5571 - accuracy: 0.11 - ETA: 3s - loss: 5.6720 - accuracy: 0.11 - ETA: 3s - loss: 5.7583 - accuracy: 0.11 - ETA: 3s - loss: 5.7311 - accuracy: 0.11 - ETA: 3s - loss: 5.7620 - accuracy: 0.10 - ETA: 2s - loss: 5.8307 - accuracy: 0.10 - ETA: 2s - loss: 5.7720 - accuracy: 0.10 - ETA: 2s - loss: 5.6442 - accuracy: 0.10 - ETA: 2s - loss: 5.6788 - accuracy: 0.09 - ETA: 2s - loss: 5.7011 - accuracy: 0.09 - ETA: 1s - loss: 5.6678 - accuracy: 0.09 - ETA: 1s - loss: 5.7040 - accuracy: 0.09 - ETA: 1s - loss: 5.6852 - accuracy: 0.09 - ETA: 1s - loss: 5.6705 - accuracy: 0.09 - ETA: 0s - loss: 5.6590 - accuracy: 0.09 - ETA: 0s - loss: 5.6909 - accuracy: 0.09 - ETA: 0s - loss: 5.6843 - accuracy: 0.09 - ETA: 0s - loss: 5.6725 - accuracy: 0.09 - 9s 8ms/sample - loss: 5.7003 - accuracy: 0.0957 - val_loss: 3.4409 - val_accuracy: 0.0252\n",
      "Epoch 14/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 7.8629 - accuracy: 0.0000e+ - ETA: 7s - loss: 6.8076 - accuracy: 0.0000e+ - ETA: 7s - loss: 6.4227 - accuracy: 0.0104   - ETA: 6s - loss: 6.4523 - accuracy: 0.02 - ETA: 6s - loss: 6.1901 - accuracy: 0.04 - ETA: 6s - loss: 5.9281 - accuracy: 0.04 - ETA: 6s - loss: 6.1931 - accuracy: 0.04 - ETA: 5s - loss: 6.1547 - accuracy: 0.04 - ETA: 5s - loss: 6.1312 - accuracy: 0.04 - ETA: 5s - loss: 6.1387 - accuracy: 0.04 - ETA: 5s - loss: 5.8943 - accuracy: 0.03 - ETA: 4s - loss: 5.8768 - accuracy: 0.04 - ETA: 4s - loss: 5.9956 - accuracy: 0.04 - ETA: 4s - loss: 5.9206 - accuracy: 0.04 - ETA: 4s - loss: 5.9826 - accuracy: 0.05 - ETA: 3s - loss: 5.9832 - accuracy: 0.05 - ETA: 3s - loss: 5.8963 - accuracy: 0.05 - ETA: 3s - loss: 5.7370 - accuracy: 0.05 - ETA: 3s - loss: 5.7440 - accuracy: 0.05 - ETA: 2s - loss: 5.7536 - accuracy: 0.05 - ETA: 2s - loss: 5.7607 - accuracy: 0.05 - ETA: 2s - loss: 5.7064 - accuracy: 0.06 - ETA: 2s - loss: 5.7478 - accuracy: 0.06 - ETA: 2s - loss: 5.7072 - accuracy: 0.06 - ETA: 1s - loss: 5.6557 - accuracy: 0.06 - ETA: 1s - loss: 5.7359 - accuracy: 0.06 - ETA: 1s - loss: 5.7176 - accuracy: 0.06 - ETA: 1s - loss: 5.7209 - accuracy: 0.06 - ETA: 0s - loss: 5.6915 - accuracy: 0.06 - ETA: 0s - loss: 5.7238 - accuracy: 0.06 - ETA: 0s - loss: 5.7048 - accuracy: 0.06 - ETA: 0s - loss: 5.6675 - accuracy: 0.06 - 9s 8ms/sample - loss: 5.6915 - accuracy: 0.0651 - val_loss: 8.1082 - val_accuracy: 0.0563\n",
      "Epoch 15/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 5.2726 - accuracy: 0.21 - ETA: 7s - loss: 5.7138 - accuracy: 0.15 - ETA: 7s - loss: 5.1994 - accuracy: 0.14 - ETA: 6s - loss: 4.6550 - accuracy: 0.13 - ETA: 6s - loss: 4.9221 - accuracy: 0.11 - ETA: 6s - loss: 5.1038 - accuracy: 0.10 - ETA: 6s - loss: 4.8089 - accuracy: 0.12 - ETA: 5s - loss: 4.8614 - accuracy: 0.12 - ETA: 5s - loss: 4.9840 - accuracy: 0.12 - ETA: 5s - loss: 4.9169 - accuracy: 0.13 - ETA: 5s - loss: 4.9930 - accuracy: 0.13 - ETA: 4s - loss: 5.0748 - accuracy: 0.12 - ETA: 4s - loss: 5.0115 - accuracy: 0.12 - ETA: 4s - loss: 5.0170 - accuracy: 0.12 - ETA: 4s - loss: 5.1486 - accuracy: 0.12 - ETA: 3s - loss: 5.1243 - accuracy: 0.12 - ETA: 3s - loss: 5.1783 - accuracy: 0.12 - ETA: 3s - loss: 5.1868 - accuracy: 0.13 - ETA: 3s - loss: 5.0976 - accuracy: 0.12 - ETA: 3s - loss: 5.1720 - accuracy: 0.13 - ETA: 2s - loss: 5.2153 - accuracy: 0.12 - ETA: 2s - loss: 5.2151 - accuracy: 0.12 - ETA: 2s - loss: 5.1587 - accuracy: 0.12 - ETA: 2s - loss: 5.2157 - accuracy: 0.12 - ETA: 1s - loss: 5.2529 - accuracy: 0.12 - ETA: 1s - loss: 5.2474 - accuracy: 0.11 - ETA: 1s - loss: 5.2345 - accuracy: 0.11 - ETA: 1s - loss: 5.2171 - accuracy: 0.11 - ETA: 0s - loss: 5.1699 - accuracy: 0.11 - ETA: 0s - loss: 5.2399 - accuracy: 0.11 - ETA: 0s - loss: 5.1789 - accuracy: 0.11 - ETA: 0s - loss: 5.2068 - accuracy: 0.12 - 9s 8ms/sample - loss: 5.1955 - accuracy: 0.1206 - val_loss: 3.3674 - val_accuracy: 0.0563\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 2.6749 - accuracy: 0.25 - ETA: 7s - loss: 4.7605 - accuracy: 0.17 - ETA: 7s - loss: 5.1924 - accuracy: 0.16 - ETA: 6s - loss: 4.8962 - accuracy: 0.14 - ETA: 6s - loss: 4.7080 - accuracy: 0.13 - ETA: 6s - loss: 5.1015 - accuracy: 0.13 - ETA: 6s - loss: 4.7206 - accuracy: 0.16 - ETA: 5s - loss: 4.7660 - accuracy: 0.14 - ETA: 5s - loss: 4.8817 - accuracy: 0.15 - ETA: 5s - loss: 4.7332 - accuracy: 0.15 - ETA: 5s - loss: 4.9499 - accuracy: 0.15 - ETA: 4s - loss: 4.8210 - accuracy: 0.14 - ETA: 4s - loss: 4.9874 - accuracy: 0.14 - ETA: 4s - loss: 4.9876 - accuracy: 0.14 - ETA: 4s - loss: 5.0289 - accuracy: 0.13 - ETA: 3s - loss: 4.9241 - accuracy: 0.14 - ETA: 3s - loss: 5.0437 - accuracy: 0.14 - ETA: 3s - loss: 5.0651 - accuracy: 0.14 - ETA: 3s - loss: 5.0205 - accuracy: 0.14 - ETA: 2s - loss: 5.0726 - accuracy: 0.13 - ETA: 2s - loss: 5.0618 - accuracy: 0.13 - ETA: 2s - loss: 5.0114 - accuracy: 0.13 - ETA: 2s - loss: 5.0715 - accuracy: 0.13 - ETA: 2s - loss: 5.0716 - accuracy: 0.13 - ETA: 1s - loss: 4.9846 - accuracy: 0.13 - ETA: 1s - loss: 4.9522 - accuracy: 0.13 - ETA: 1s - loss: 4.9704 - accuracy: 0.13 - ETA: 1s - loss: 4.9812 - accuracy: 0.14 - ETA: 0s - loss: 5.0045 - accuracy: 0.14 - ETA: 0s - loss: 4.9344 - accuracy: 0.13 - ETA: 0s - loss: 4.9595 - accuracy: 0.13 - ETA: 0s - loss: 5.0281 - accuracy: 0.13 - 13s 13ms/sample - loss: 5.0294 - accuracy: 0.1407 - val_loss: 3.1563 - val_accuracy: 0.1010\n",
      "Epoch 17/50\n",
      "1045/1045 [==============================] - ETA: 8s - loss: 4.7001 - accuracy: 0.25 - ETA: 7s - loss: 4.8016 - accuracy: 0.21 - ETA: 7s - loss: 4.9936 - accuracy: 0.19 - ETA: 7s - loss: 5.1251 - accuracy: 0.18 - ETA: 6s - loss: 5.1229 - accuracy: 0.16 - ETA: 6s - loss: 5.0163 - accuracy: 0.16 - ETA: 6s - loss: 4.9285 - accuracy: 0.17 - ETA: 5s - loss: 4.9856 - accuracy: 0.17 - ETA: 5s - loss: 4.7673 - accuracy: 0.17 - ETA: 5s - loss: 4.6038 - accuracy: 0.17 - ETA: 5s - loss: 4.7474 - accuracy: 0.16 - ETA: 4s - loss: 4.7421 - accuracy: 0.16 - ETA: 4s - loss: 4.7953 - accuracy: 0.16 - ETA: 4s - loss: 4.8384 - accuracy: 0.17 - ETA: 4s - loss: 4.7987 - accuracy: 0.16 - ETA: 3s - loss: 4.8270 - accuracy: 0.16 - ETA: 3s - loss: 4.7904 - accuracy: 0.17 - ETA: 3s - loss: 4.8206 - accuracy: 0.16 - ETA: 3s - loss: 4.8862 - accuracy: 0.16 - ETA: 3s - loss: 4.8485 - accuracy: 0.16 - ETA: 2s - loss: 4.8361 - accuracy: 0.16 - ETA: 2s - loss: 4.8655 - accuracy: 0.16 - ETA: 2s - loss: 4.8491 - accuracy: 0.16 - ETA: 2s - loss: 4.7600 - accuracy: 0.16 - ETA: 1s - loss: 4.8035 - accuracy: 0.16 - ETA: 1s - loss: 4.7981 - accuracy: 0.16 - ETA: 1s - loss: 4.7566 - accuracy: 0.16 - ETA: 1s - loss: 4.8196 - accuracy: 0.16 - ETA: 0s - loss: 4.8032 - accuracy: 0.15 - ETA: 0s - loss: 4.8444 - accuracy: 0.15 - ETA: 0s - loss: 4.8230 - accuracy: 0.15 - ETA: 0s - loss: 4.8329 - accuracy: 0.15 - 9s 8ms/sample - loss: 4.8397 - accuracy: 0.1522 - val_loss: 3.2694 - val_accuracy: 0.0835\n",
      "Epoch 18/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 4.6941 - accuracy: 0.15 - ETA: 7s - loss: 5.4384 - accuracy: 0.14 - ETA: 7s - loss: 4.8958 - accuracy: 0.15 - ETA: 6s - loss: 4.3471 - accuracy: 0.15 - ETA: 6s - loss: 4.5266 - accuracy: 0.15 - ETA: 6s - loss: 4.6032 - accuracy: 0.18 - ETA: 6s - loss: 4.6267 - accuracy: 0.20 - ETA: 5s - loss: 4.5050 - accuracy: 0.20 - ETA: 5s - loss: 4.5443 - accuracy: 0.19 - ETA: 5s - loss: 4.6733 - accuracy: 0.20 - ETA: 5s - loss: 4.6509 - accuracy: 0.19 - ETA: 4s - loss: 4.5878 - accuracy: 0.19 - ETA: 4s - loss: 4.7379 - accuracy: 0.18 - ETA: 4s - loss: 4.7332 - accuracy: 0.18 - ETA: 4s - loss: 4.7001 - accuracy: 0.18 - ETA: 3s - loss: 4.6871 - accuracy: 0.18 - ETA: 3s - loss: 4.6710 - accuracy: 0.18 - ETA: 3s - loss: 4.7432 - accuracy: 0.17 - ETA: 3s - loss: 4.6316 - accuracy: 0.18 - ETA: 3s - loss: 4.6598 - accuracy: 0.18 - ETA: 2s - loss: 4.6500 - accuracy: 0.18 - ETA: 2s - loss: 4.6376 - accuracy: 0.18 - ETA: 2s - loss: 4.6890 - accuracy: 0.17 - ETA: 2s - loss: 4.6809 - accuracy: 0.17 - ETA: 1s - loss: 4.6278 - accuracy: 0.17 - ETA: 1s - loss: 4.6694 - accuracy: 0.17 - ETA: 1s - loss: 4.7075 - accuracy: 0.17 - ETA: 1s - loss: 4.7051 - accuracy: 0.17 - ETA: 0s - loss: 4.6313 - accuracy: 0.17 - ETA: 0s - loss: 4.5905 - accuracy: 0.16 - ETA: 0s - loss: 4.6107 - accuracy: 0.16 - ETA: 0s - loss: 4.6243 - accuracy: 0.16 - 9s 8ms/sample - loss: 4.6222 - accuracy: 0.1684 - val_loss: 2.9757 - val_accuracy: 0.0971\n",
      "Epoch 19/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 5.1913 - accuracy: 0.03 - ETA: 7s - loss: 5.4688 - accuracy: 0.14 - ETA: 7s - loss: 4.8415 - accuracy: 0.13 - ETA: 6s - loss: 4.8240 - accuracy: 0.16 - ETA: 6s - loss: 4.8321 - accuracy: 0.15 - ETA: 6s - loss: 4.9525 - accuracy: 0.15 - ETA: 6s - loss: 4.8952 - accuracy: 0.15 - ETA: 5s - loss: 4.7539 - accuracy: 0.14 - ETA: 5s - loss: 4.8745 - accuracy: 0.14 - ETA: 5s - loss: 4.8556 - accuracy: 0.14 - ETA: 5s - loss: 4.7768 - accuracy: 0.14 - ETA: 4s - loss: 4.8536 - accuracy: 0.15 - ETA: 4s - loss: 4.8352 - accuracy: 0.15 - ETA: 4s - loss: 4.7336 - accuracy: 0.15 - ETA: 4s - loss: 4.7787 - accuracy: 0.15 - ETA: 3s - loss: 4.7345 - accuracy: 0.15 - ETA: 3s - loss: 4.7890 - accuracy: 0.16 - ETA: 3s - loss: 4.7731 - accuracy: 0.16 - ETA: 3s - loss: 4.7987 - accuracy: 0.16 - ETA: 3s - loss: 4.7515 - accuracy: 0.16 - ETA: 2s - loss: 4.8210 - accuracy: 0.15 - ETA: 2s - loss: 4.8036 - accuracy: 0.15 - ETA: 2s - loss: 4.7888 - accuracy: 0.15 - ETA: 2s - loss: 4.7513 - accuracy: 0.15 - ETA: 1s - loss: 4.7642 - accuracy: 0.15 - ETA: 1s - loss: 4.8015 - accuracy: 0.15 - ETA: 1s - loss: 4.7887 - accuracy: 0.15 - ETA: 1s - loss: 4.7925 - accuracy: 0.15 - ETA: 0s - loss: 4.7506 - accuracy: 0.15 - ETA: 0s - loss: 4.7569 - accuracy: 0.15 - ETA: 0s - loss: 4.7649 - accuracy: 0.15 - ETA: 0s - loss: 4.7745 - accuracy: 0.15 - 15s 15ms/sample - loss: 4.7913 - accuracy: 0.1512 - val_loss: 3.2795 - val_accuracy: 0.1262\n",
      "Epoch 20/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 5.1612 - accuracy: 0.25 - ETA: 7s - loss: 4.3181 - accuracy: 0.20 - ETA: 7s - loss: 3.7664 - accuracy: 0.18 - ETA: 6s - loss: 3.9406 - accuracy: 0.21 - ETA: 6s - loss: 4.0613 - accuracy: 0.19 - ETA: 6s - loss: 3.8172 - accuracy: 0.19 - ETA: 6s - loss: 4.1295 - accuracy: 0.19 - ETA: 5s - loss: 4.1146 - accuracy: 0.17 - ETA: 5s - loss: 4.2388 - accuracy: 0.17 - ETA: 5s - loss: 4.1421 - accuracy: 0.17 - ETA: 5s - loss: 4.2749 - accuracy: 0.17 - ETA: 4s - loss: 4.2473 - accuracy: 0.18 - ETA: 4s - loss: 4.3185 - accuracy: 0.18 - ETA: 4s - loss: 4.3288 - accuracy: 0.18 - ETA: 4s - loss: 4.4614 - accuracy: 0.17 - ETA: 3s - loss: 4.4706 - accuracy: 0.16 - ETA: 3s - loss: 4.4375 - accuracy: 0.16 - ETA: 3s - loss: 4.5271 - accuracy: 0.16 - ETA: 3s - loss: 4.4406 - accuracy: 0.16 - ETA: 3s - loss: 4.3558 - accuracy: 0.17 - ETA: 2s - loss: 4.3336 - accuracy: 0.16 - ETA: 2s - loss: 4.4058 - accuracy: 0.16 - ETA: 2s - loss: 4.3994 - accuracy: 0.16 - ETA: 2s - loss: 4.4302 - accuracy: 0.15 - ETA: 1s - loss: 4.4360 - accuracy: 0.16 - ETA: 1s - loss: 4.4399 - accuracy: 0.16 - ETA: 1s - loss: 4.5048 - accuracy: 0.15 - ETA: 1s - loss: 4.4546 - accuracy: 0.15 - ETA: 0s - loss: 4.4171 - accuracy: 0.15 - ETA: 0s - loss: 4.4826 - accuracy: 0.15 - ETA: 0s - loss: 4.5026 - accuracy: 0.14 - ETA: 0s - loss: 4.4810 - accuracy: 0.14 - 9s 8ms/sample - loss: 4.5273 - accuracy: 0.1407 - val_loss: 3.3666 - val_accuracy: 0.0893\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 4.5392 - accuracy: 0.09 - ETA: 7s - loss: 5.1353 - accuracy: 0.07 - ETA: 7s - loss: 4.8518 - accuracy: 0.10 - ETA: 6s - loss: 4.9119 - accuracy: 0.11 - ETA: 6s - loss: 4.6986 - accuracy: 0.10 - ETA: 6s - loss: 4.8571 - accuracy: 0.11 - ETA: 6s - loss: 4.8068 - accuracy: 0.10 - ETA: 5s - loss: 4.7950 - accuracy: 0.11 - ETA: 5s - loss: 4.8442 - accuracy: 0.11 - ETA: 5s - loss: 4.7212 - accuracy: 0.11 - ETA: 5s - loss: 4.8837 - accuracy: 0.11 - ETA: 4s - loss: 4.9386 - accuracy: 0.10 - ETA: 4s - loss: 4.9837 - accuracy: 0.10 - ETA: 4s - loss: 4.9870 - accuracy: 0.09 - ETA: 4s - loss: 4.9515 - accuracy: 0.09 - ETA: 3s - loss: 5.0102 - accuracy: 0.08 - ETA: 3s - loss: 5.0104 - accuracy: 0.08 - ETA: 3s - loss: 4.9935 - accuracy: 0.08 - ETA: 3s - loss: 5.0083 - accuracy: 0.08 - ETA: 3s - loss: 4.9945 - accuracy: 0.08 - ETA: 2s - loss: 4.9958 - accuracy: 0.08 - ETA: 2s - loss: 4.9975 - accuracy: 0.07 - ETA: 2s - loss: 5.0130 - accuracy: 0.07 - ETA: 2s - loss: 4.9931 - accuracy: 0.07 - ETA: 1s - loss: 5.0004 - accuracy: 0.07 - ETA: 1s - loss: 4.9900 - accuracy: 0.07 - ETA: 1s - loss: 4.9979 - accuracy: 0.07 - ETA: 1s - loss: 4.9250 - accuracy: 0.07 - ETA: 0s - loss: 4.9232 - accuracy: 0.07 - ETA: 0s - loss: 4.9226 - accuracy: 0.07 - ETA: 0s - loss: 4.9247 - accuracy: 0.07 - ETA: 0s - loss: 4.9242 - accuracy: 0.07 - 9s 8ms/sample - loss: 4.9350 - accuracy: 0.0756 - val_loss: 10.8665 - val_accuracy: 0.0427\n",
      "Epoch 22/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 5.3221 - accuracy: 0.15 - ETA: 7s - loss: 4.6519 - accuracy: 0.10 - ETA: 7s - loss: 4.9988 - accuracy: 0.10 - ETA: 6s - loss: 4.8484 - accuracy: 0.10 - ETA: 6s - loss: 4.9557 - accuracy: 0.10 - ETA: 6s - loss: 4.8633 - accuracy: 0.08 - ETA: 6s - loss: 4.9124 - accuracy: 0.09 - ETA: 5s - loss: 4.8450 - accuracy: 0.09 - ETA: 5s - loss: 4.9295 - accuracy: 0.09 - ETA: 5s - loss: 4.8231 - accuracy: 0.08 - ETA: 5s - loss: 4.9323 - accuracy: 0.08 - ETA: 4s - loss: 4.8980 - accuracy: 0.08 - ETA: 4s - loss: 4.9145 - accuracy: 0.07 - ETA: 4s - loss: 4.9619 - accuracy: 0.08 - ETA: 4s - loss: 4.9275 - accuracy: 0.09 - ETA: 3s - loss: 4.9265 - accuracy: 0.08 - ETA: 3s - loss: 4.9436 - accuracy: 0.08 - ETA: 3s - loss: 4.9261 - accuracy: 0.08 - ETA: 3s - loss: 4.8206 - accuracy: 0.08 - ETA: 3s - loss: 4.8415 - accuracy: 0.08 - ETA: 2s - loss: 4.8356 - accuracy: 0.08 - ETA: 2s - loss: 4.8038 - accuracy: 0.08 - ETA: 2s - loss: 4.8039 - accuracy: 0.08 - ETA: 2s - loss: 4.8183 - accuracy: 0.09 - ETA: 1s - loss: 4.8619 - accuracy: 0.09 - ETA: 1s - loss: 4.8621 - accuracy: 0.08 - ETA: 1s - loss: 4.8572 - accuracy: 0.08 - ETA: 1s - loss: 4.7925 - accuracy: 0.08 - ETA: 0s - loss: 4.8277 - accuracy: 0.08 - ETA: 0s - loss: 4.8364 - accuracy: 0.08 - ETA: 0s - loss: 4.8366 - accuracy: 0.07 - ETA: 0s - loss: 4.8275 - accuracy: 0.07 - 9s 8ms/sample - loss: 4.8548 - accuracy: 0.0766 - val_loss: 40.6731 - val_accuracy: 0.0388\n",
      "Epoch 23/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.9368 - accuracy: 0.12 - ETA: 7s - loss: 4.8579 - accuracy: 0.10 - ETA: 7s - loss: 4.7197 - accuracy: 0.08 - ETA: 6s - loss: 4.8756 - accuracy: 0.07 - ETA: 6s - loss: 4.8767 - accuracy: 0.06 - ETA: 6s - loss: 4.8356 - accuracy: 0.06 - ETA: 6s - loss: 4.8436 - accuracy: 0.06 - ETA: 5s - loss: 4.8121 - accuracy: 0.07 - ETA: 5s - loss: 4.8551 - accuracy: 0.06 - ETA: 5s - loss: 4.8272 - accuracy: 0.06 - ETA: 5s - loss: 4.8528 - accuracy: 0.05 - ETA: 4s - loss: 4.8813 - accuracy: 0.06 - ETA: 4s - loss: 4.8666 - accuracy: 0.06 - ETA: 4s - loss: 4.8401 - accuracy: 0.06 - ETA: 4s - loss: 4.8617 - accuracy: 0.06 - ETA: 4s - loss: 4.8215 - accuracy: 0.07 - ETA: 3s - loss: 4.8771 - accuracy: 0.08 - ETA: 3s - loss: 4.8594 - accuracy: 0.08 - ETA: 3s - loss: 4.7984 - accuracy: 0.08 - ETA: 3s - loss: 4.7927 - accuracy: 0.08 - ETA: 2s - loss: 4.8358 - accuracy: 0.07 - ETA: 2s - loss: 4.7787 - accuracy: 0.07 - ETA: 2s - loss: 4.8399 - accuracy: 0.08 - ETA: 2s - loss: 4.7809 - accuracy: 0.07 - ETA: 1s - loss: 4.8224 - accuracy: 0.07 - ETA: 1s - loss: 4.8041 - accuracy: 0.08 - ETA: 1s - loss: 4.7708 - accuracy: 0.08 - ETA: 1s - loss: 4.7959 - accuracy: 0.08 - ETA: 0s - loss: 4.7880 - accuracy: 0.08 - ETA: 0s - loss: 4.7863 - accuracy: 0.08 - ETA: 0s - loss: 4.7579 - accuracy: 0.08 - ETA: 0s - loss: 4.7861 - accuracy: 0.08 - 9s 9ms/sample - loss: 4.7816 - accuracy: 0.0871 - val_loss: 6.1255 - val_accuracy: 0.0874\n",
      "Epoch 24/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 4.4885 - accuracy: 0.09 - ETA: 7s - loss: 5.2812 - accuracy: 0.10 - ETA: 7s - loss: 4.8231 - accuracy: 0.11 - ETA: 7s - loss: 4.9079 - accuracy: 0.10 - ETA: 6s - loss: 4.8747 - accuracy: 0.08 - ETA: 6s - loss: 4.8203 - accuracy: 0.07 - ETA: 6s - loss: 4.7216 - accuracy: 0.08 - ETA: 6s - loss: 4.8119 - accuracy: 0.08 - ETA: 5s - loss: 4.8010 - accuracy: 0.09 - ETA: 5s - loss: 4.7815 - accuracy: 0.09 - ETA: 5s - loss: 4.7655 - accuracy: 0.10 - ETA: 5s - loss: 4.7790 - accuracy: 0.09 - ETA: 4s - loss: 4.7933 - accuracy: 0.09 - ETA: 4s - loss: 4.8173 - accuracy: 0.10 - ETA: 4s - loss: 4.8147 - accuracy: 0.09 - ETA: 4s - loss: 4.7444 - accuracy: 0.09 - ETA: 3s - loss: 4.7838 - accuracy: 0.09 - ETA: 3s - loss: 4.8192 - accuracy: 0.09 - ETA: 3s - loss: 4.7559 - accuracy: 0.09 - ETA: 3s - loss: 4.7985 - accuracy: 0.09 - ETA: 2s - loss: 4.7481 - accuracy: 0.09 - ETA: 2s - loss: 4.7450 - accuracy: 0.09 - ETA: 2s - loss: 4.8217 - accuracy: 0.08 - ETA: 2s - loss: 4.7861 - accuracy: 0.08 - ETA: 1s - loss: 4.7975 - accuracy: 0.08 - ETA: 1s - loss: 4.7847 - accuracy: 0.08 - ETA: 1s - loss: 4.7869 - accuracy: 0.08 - ETA: 1s - loss: 4.7581 - accuracy: 0.08 - ETA: 0s - loss: 4.7805 - accuracy: 0.08 - ETA: 0s - loss: 4.7564 - accuracy: 0.08 - ETA: 0s - loss: 4.7714 - accuracy: 0.08 - ETA: 0s - loss: 4.7103 - accuracy: 0.08 - 9s 9ms/sample - loss: 4.7222 - accuracy: 0.0871 - val_loss: 3.5113 - val_accuracy: 0.0563\n",
      "Epoch 25/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 5.3405 - accuracy: 0.06 - ETA: 7s - loss: 5.1087 - accuracy: 0.09 - ETA: 7s - loss: 4.5720 - accuracy: 0.11 - ETA: 7s - loss: 4.7514 - accuracy: 0.11 - ETA: 7s - loss: 4.6189 - accuracy: 0.11 - ETA: 7s - loss: 4.6789 - accuracy: 0.11 - ETA: 6s - loss: 4.7267 - accuracy: 0.12 - ETA: 6s - loss: 4.6823 - accuracy: 0.11 - ETA: 6s - loss: 4.6695 - accuracy: 0.11 - ETA: 6s - loss: 4.5814 - accuracy: 0.11 - ETA: 5s - loss: 4.7038 - accuracy: 0.12 - ETA: 5s - loss: 4.5688 - accuracy: 0.13 - ETA: 5s - loss: 4.5894 - accuracy: 0.12 - ETA: 5s - loss: 4.5851 - accuracy: 0.12 - ETA: 4s - loss: 4.5571 - accuracy: 0.12 - ETA: 4s - loss: 4.5681 - accuracy: 0.12 - ETA: 4s - loss: 4.5922 - accuracy: 0.11 - ETA: 4s - loss: 4.5916 - accuracy: 0.11 - ETA: 3s - loss: 4.6025 - accuracy: 0.11 - ETA: 3s - loss: 4.5669 - accuracy: 0.11 - ETA: 3s - loss: 4.6055 - accuracy: 0.11 - ETA: 2s - loss: 4.5941 - accuracy: 0.11 - ETA: 2s - loss: 4.5900 - accuracy: 0.11 - ETA: 2s - loss: 4.6078 - accuracy: 0.11 - ETA: 2s - loss: 4.5760 - accuracy: 0.12 - ETA: 1s - loss: 4.5877 - accuracy: 0.12 - ETA: 1s - loss: 4.5573 - accuracy: 0.12 - ETA: 1s - loss: 4.5962 - accuracy: 0.12 - ETA: 1s - loss: 4.5310 - accuracy: 0.12 - ETA: 0s - loss: 4.5248 - accuracy: 0.12 - ETA: 0s - loss: 4.5214 - accuracy: 0.12 - ETA: 0s - loss: 4.5099 - accuracy: 0.12 - 10s 10ms/sample - loss: 4.5016 - accuracy: 0.1282 - val_loss: 3.2130 - val_accuracy: 0.0738\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 8s - loss: 4.9308 - accuracy: 0.06 - ETA: 8s - loss: 4.9363 - accuracy: 0.12 - ETA: 7s - loss: 4.4521 - accuracy: 0.13 - ETA: 7s - loss: 4.5078 - accuracy: 0.12 - ETA: 7s - loss: 4.6544 - accuracy: 0.13 - ETA: 6s - loss: 4.6455 - accuracy: 0.11 - ETA: 6s - loss: 4.6071 - accuracy: 0.12 - ETA: 6s - loss: 4.5095 - accuracy: 0.12 - ETA: 6s - loss: 4.3436 - accuracy: 0.11 - ETA: 5s - loss: 4.3310 - accuracy: 0.12 - ETA: 5s - loss: 4.2043 - accuracy: 0.12 - ETA: 5s - loss: 4.2130 - accuracy: 0.12 - ETA: 4s - loss: 4.2389 - accuracy: 0.12 - ETA: 4s - loss: 4.3292 - accuracy: 0.12 - ETA: 4s - loss: 4.3238 - accuracy: 0.11 - ETA: 4s - loss: 4.3172 - accuracy: 0.11 - ETA: 3s - loss: 4.3591 - accuracy: 0.12 - ETA: 3s - loss: 4.3420 - accuracy: 0.12 - ETA: 3s - loss: 4.3433 - accuracy: 0.12 - ETA: 3s - loss: 4.3466 - accuracy: 0.12 - ETA: 2s - loss: 4.3169 - accuracy: 0.12 - ETA: 2s - loss: 4.3489 - accuracy: 0.12 - ETA: 2s - loss: 4.3206 - accuracy: 0.12 - ETA: 2s - loss: 4.3452 - accuracy: 0.12 - ETA: 1s - loss: 4.3449 - accuracy: 0.12 - ETA: 1s - loss: 4.3338 - accuracy: 0.12 - ETA: 1s - loss: 4.3691 - accuracy: 0.12 - ETA: 1s - loss: 4.3698 - accuracy: 0.11 - ETA: 0s - loss: 4.3964 - accuracy: 0.11 - ETA: 0s - loss: 4.3695 - accuracy: 0.11 - ETA: 0s - loss: 4.3192 - accuracy: 0.11 - ETA: 0s - loss: 4.3381 - accuracy: 0.10 - 10s 9ms/sample - loss: 4.3322 - accuracy: 0.1100 - val_loss: 3.2232 - val_accuracy: 0.0835\n",
      "Epoch 27/50\n",
      "1045/1045 [==============================] - ETA: 8s - loss: 5.4639 - accuracy: 0.09 - ETA: 7s - loss: 4.2755 - accuracy: 0.12 - ETA: 7s - loss: 4.5263 - accuracy: 0.14 - ETA: 7s - loss: 4.7256 - accuracy: 0.14 - ETA: 6s - loss: 4.8628 - accuracy: 0.13 - ETA: 6s - loss: 4.6450 - accuracy: 0.11 - ETA: 6s - loss: 4.6597 - accuracy: 0.11 - ETA: 6s - loss: 4.4578 - accuracy: 0.10 - ETA: 5s - loss: 4.5544 - accuracy: 0.10 - ETA: 5s - loss: 4.5075 - accuracy: 0.10 - ETA: 5s - loss: 4.5147 - accuracy: 0.10 - ETA: 5s - loss: 4.4778 - accuracy: 0.09 - ETA: 4s - loss: 4.5524 - accuracy: 0.10 - ETA: 4s - loss: 4.5366 - accuracy: 0.10 - ETA: 4s - loss: 4.5216 - accuracy: 0.10 - ETA: 4s - loss: 4.5224 - accuracy: 0.10 - ETA: 3s - loss: 4.5074 - accuracy: 0.11 - ETA: 3s - loss: 4.4689 - accuracy: 0.11 - ETA: 3s - loss: 4.5284 - accuracy: 0.11 - ETA: 3s - loss: 4.4883 - accuracy: 0.11 - ETA: 2s - loss: 4.5034 - accuracy: 0.11 - ETA: 2s - loss: 4.4898 - accuracy: 0.11 - ETA: 2s - loss: 4.4561 - accuracy: 0.11 - ETA: 2s - loss: 4.4457 - accuracy: 0.11 - ETA: 1s - loss: 4.4955 - accuracy: 0.11 - ETA: 1s - loss: 4.4846 - accuracy: 0.11 - ETA: 1s - loss: 4.4742 - accuracy: 0.11 - ETA: 1s - loss: 4.4708 - accuracy: 0.10 - ETA: 0s - loss: 4.4738 - accuracy: 0.10 - ETA: 0s - loss: 4.4486 - accuracy: 0.10 - ETA: 0s - loss: 4.4369 - accuracy: 0.11 - ETA: 0s - loss: 4.4312 - accuracy: 0.11 - 9s 9ms/sample - loss: 4.4395 - accuracy: 0.1110 - val_loss: 4.0685 - val_accuracy: 0.0718\n",
      "Epoch 28/50\n",
      "1045/1045 [==============================] - ETA: 8s - loss: 5.5191 - accuracy: 0.09 - ETA: 7s - loss: 5.0763 - accuracy: 0.06 - ETA: 7s - loss: 4.5964 - accuracy: 0.08 - ETA: 7s - loss: 4.6974 - accuracy: 0.07 - ETA: 6s - loss: 4.6144 - accuracy: 0.08 - ETA: 6s - loss: 4.5691 - accuracy: 0.07 - ETA: 6s - loss: 4.5810 - accuracy: 0.08 - ETA: 5s - loss: 4.4750 - accuracy: 0.08 - ETA: 5s - loss: 4.5601 - accuracy: 0.09 - ETA: 5s - loss: 4.4685 - accuracy: 0.10 - ETA: 5s - loss: 4.3869 - accuracy: 0.10 - ETA: 4s - loss: 4.4482 - accuracy: 0.11 - ETA: 4s - loss: 4.4081 - accuracy: 0.11 - ETA: 4s - loss: 4.3444 - accuracy: 0.11 - ETA: 4s - loss: 4.3512 - accuracy: 0.11 - ETA: 4s - loss: 4.2819 - accuracy: 0.11 - ETA: 3s - loss: 4.3583 - accuracy: 0.10 - ETA: 3s - loss: 4.3460 - accuracy: 0.10 - ETA: 3s - loss: 4.3554 - accuracy: 0.11 - ETA: 3s - loss: 4.3256 - accuracy: 0.11 - ETA: 2s - loss: 4.3545 - accuracy: 0.10 - ETA: 2s - loss: 4.3907 - accuracy: 0.10 - ETA: 2s - loss: 4.3833 - accuracy: 0.10 - ETA: 2s - loss: 4.4117 - accuracy: 0.09 - ETA: 1s - loss: 4.3871 - accuracy: 0.09 - ETA: 1s - loss: 4.4031 - accuracy: 0.09 - ETA: 1s - loss: 4.4137 - accuracy: 0.09 - ETA: 1s - loss: 4.4056 - accuracy: 0.09 - ETA: 0s - loss: 4.4158 - accuracy: 0.09 - ETA: 0s - loss: 4.4071 - accuracy: 0.09 - ETA: 0s - loss: 4.3883 - accuracy: 0.09 - ETA: 0s - loss: 4.3429 - accuracy: 0.09 - 9s 9ms/sample - loss: 4.3528 - accuracy: 0.1005 - val_loss: 4.4098 - val_accuracy: 0.0680\n",
      "Epoch 29/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 4.7659 - accuracy: 0.21 - ETA: 7s - loss: 4.7689 - accuracy: 0.17 - ETA: 7s - loss: 4.2282 - accuracy: 0.14 - ETA: 6s - loss: 4.4587 - accuracy: 0.14 - ETA: 6s - loss: 4.3526 - accuracy: 0.13 - ETA: 6s - loss: 4.4777 - accuracy: 0.13 - ETA: 6s - loss: 4.3895 - accuracy: 0.14 - ETA: 5s - loss: 4.4940 - accuracy: 0.14 - ETA: 5s - loss: 4.4518 - accuracy: 0.13 - ETA: 5s - loss: 4.3856 - accuracy: 0.13 - ETA: 5s - loss: 4.4535 - accuracy: 0.13 - ETA: 4s - loss: 4.3762 - accuracy: 0.13 - ETA: 4s - loss: 4.4323 - accuracy: 0.12 - ETA: 4s - loss: 4.3974 - accuracy: 0.12 - ETA: 4s - loss: 4.3832 - accuracy: 0.12 - ETA: 3s - loss: 4.4456 - accuracy: 0.12 - ETA: 3s - loss: 4.4284 - accuracy: 0.12 - ETA: 3s - loss: 4.3875 - accuracy: 0.12 - ETA: 3s - loss: 4.4208 - accuracy: 0.12 - ETA: 3s - loss: 4.4261 - accuracy: 0.12 - ETA: 2s - loss: 4.4115 - accuracy: 0.12 - ETA: 2s - loss: 4.3809 - accuracy: 0.12 - ETA: 2s - loss: 4.3778 - accuracy: 0.12 - ETA: 2s - loss: 4.4008 - accuracy: 0.12 - ETA: 1s - loss: 4.3805 - accuracy: 0.12 - ETA: 1s - loss: 4.3699 - accuracy: 0.12 - ETA: 1s - loss: 4.3937 - accuracy: 0.12 - ETA: 1s - loss: 4.4102 - accuracy: 0.12 - ETA: 0s - loss: 4.3972 - accuracy: 0.12 - ETA: 0s - loss: 4.3848 - accuracy: 0.11 - ETA: 0s - loss: 4.4102 - accuracy: 0.11 - ETA: 0s - loss: 4.3759 - accuracy: 0.11 - 9s 9ms/sample - loss: 4.3949 - accuracy: 0.1158 - val_loss: 524.8069 - val_accuracy: 0.0350\n",
      "Epoch 30/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 4.9653 - accuracy: 0.03 - ETA: 7s - loss: 4.7762 - accuracy: 0.06 - ETA: 7s - loss: 4.7004 - accuracy: 0.07 - ETA: 6s - loss: 4.7908 - accuracy: 0.07 - ETA: 6s - loss: 4.5886 - accuracy: 0.08 - ETA: 6s - loss: 4.6129 - accuracy: 0.09 - ETA: 6s - loss: 4.6951 - accuracy: 0.09 - ETA: 5s - loss: 4.6464 - accuracy: 0.08 - ETA: 5s - loss: 4.5778 - accuracy: 0.09 - ETA: 5s - loss: 4.5681 - accuracy: 0.09 - ETA: 5s - loss: 4.5846 - accuracy: 0.08 - ETA: 4s - loss: 4.5411 - accuracy: 0.08 - ETA: 4s - loss: 4.5799 - accuracy: 0.08 - ETA: 4s - loss: 4.6000 - accuracy: 0.08 - ETA: 4s - loss: 4.5284 - accuracy: 0.07 - ETA: 4s - loss: 4.5811 - accuracy: 0.07 - ETA: 3s - loss: 4.5799 - accuracy: 0.07 - ETA: 3s - loss: 4.5726 - accuracy: 0.07 - ETA: 3s - loss: 4.5302 - accuracy: 0.07 - ETA: 3s - loss: 4.5083 - accuracy: 0.07 - ETA: 2s - loss: 4.5687 - accuracy: 0.07 - ETA: 2s - loss: 4.5624 - accuracy: 0.07 - ETA: 2s - loss: 4.5666 - accuracy: 0.07 - ETA: 2s - loss: 4.5551 - accuracy: 0.07 - ETA: 1s - loss: 4.5413 - accuracy: 0.07 - ETA: 1s - loss: 4.5487 - accuracy: 0.07 - ETA: 1s - loss: 4.5301 - accuracy: 0.07 - ETA: 1s - loss: 4.5212 - accuracy: 0.07 - ETA: 0s - loss: 4.5336 - accuracy: 0.07 - ETA: 0s - loss: 4.5192 - accuracy: 0.07 - ETA: 0s - loss: 4.5001 - accuracy: 0.07 - ETA: 0s - loss: 4.4952 - accuracy: 0.07 - 9s 9ms/sample - loss: 4.5024 - accuracy: 0.0794 - val_loss: 3.2532 - val_accuracy: 0.0660\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 5.1612 - accuracy: 0.03 - ETA: 7s - loss: 4.5495 - accuracy: 0.04 - ETA: 7s - loss: 3.9489 - accuracy: 0.05 - ETA: 6s - loss: 4.0585 - accuracy: 0.07 - ETA: 6s - loss: 4.1230 - accuracy: 0.09 - ETA: 6s - loss: 4.1256 - accuracy: 0.08 - ETA: 6s - loss: 4.1560 - accuracy: 0.08 - ETA: 5s - loss: 4.1949 - accuracy: 0.09 - ETA: 5s - loss: 4.1098 - accuracy: 0.09 - ETA: 5s - loss: 4.1881 - accuracy: 0.09 - ETA: 5s - loss: 4.1530 - accuracy: 0.09 - ETA: 4s - loss: 4.2351 - accuracy: 0.09 - ETA: 4s - loss: 4.1893 - accuracy: 0.09 - ETA: 4s - loss: 4.2198 - accuracy: 0.09 - ETA: 4s - loss: 4.2262 - accuracy: 0.08 - ETA: 3s - loss: 4.2650 - accuracy: 0.08 - ETA: 3s - loss: 4.2433 - accuracy: 0.09 - ETA: 3s - loss: 4.1681 - accuracy: 0.09 - ETA: 3s - loss: 4.1824 - accuracy: 0.09 - ETA: 3s - loss: 4.2116 - accuracy: 0.09 - ETA: 2s - loss: 4.1988 - accuracy: 0.09 - ETA: 2s - loss: 4.2004 - accuracy: 0.09 - ETA: 2s - loss: 4.1779 - accuracy: 0.09 - ETA: 2s - loss: 4.1862 - accuracy: 0.09 - ETA: 1s - loss: 4.1972 - accuracy: 0.10 - ETA: 1s - loss: 4.1914 - accuracy: 0.10 - ETA: 1s - loss: 4.1956 - accuracy: 0.10 - ETA: 1s - loss: 4.2068 - accuracy: 0.10 - ETA: 0s - loss: 4.1846 - accuracy: 0.10 - ETA: 0s - loss: 4.2026 - accuracy: 0.10 - ETA: 0s - loss: 4.1882 - accuracy: 0.10 - ETA: 0s - loss: 4.1914 - accuracy: 0.10 - 9s 9ms/sample - loss: 4.1599 - accuracy: 0.1024 - val_loss: 3.1418 - val_accuracy: 0.0738\n",
      "Epoch 32/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 4.3584 - accuracy: 0.09 - ETA: 7s - loss: 4.2353 - accuracy: 0.12 - ETA: 7s - loss: 4.3324 - accuracy: 0.11 - ETA: 6s - loss: 4.2126 - accuracy: 0.11 - ETA: 6s - loss: 4.1009 - accuracy: 0.11 - ETA: 6s - loss: 4.0703 - accuracy: 0.10 - ETA: 6s - loss: 4.1700 - accuracy: 0.10 - ETA: 5s - loss: 4.2603 - accuracy: 0.10 - ETA: 5s - loss: 4.2374 - accuracy: 0.11 - ETA: 5s - loss: 4.1772 - accuracy: 0.12 - ETA: 5s - loss: 4.1731 - accuracy: 0.11 - ETA: 4s - loss: 4.1614 - accuracy: 0.11 - ETA: 4s - loss: 4.2170 - accuracy: 0.11 - ETA: 4s - loss: 4.1136 - accuracy: 0.11 - ETA: 4s - loss: 4.0710 - accuracy: 0.12 - ETA: 3s - loss: 4.0984 - accuracy: 0.12 - ETA: 3s - loss: 4.1123 - accuracy: 0.12 - ETA: 3s - loss: 4.0703 - accuracy: 0.12 - ETA: 3s - loss: 4.0987 - accuracy: 0.12 - ETA: 3s - loss: 4.0804 - accuracy: 0.12 - ETA: 2s - loss: 4.0756 - accuracy: 0.13 - ETA: 2s - loss: 4.0796 - accuracy: 0.13 - ETA: 2s - loss: 4.1073 - accuracy: 0.13 - ETA: 2s - loss: 4.0939 - accuracy: 0.13 - ETA: 1s - loss: 4.0824 - accuracy: 0.13 - ETA: 1s - loss: 4.1034 - accuracy: 0.13 - ETA: 1s - loss: 4.1076 - accuracy: 0.13 - ETA: 1s - loss: 4.1123 - accuracy: 0.14 - ETA: 0s - loss: 4.0869 - accuracy: 0.14 - ETA: 0s - loss: 4.0425 - accuracy: 0.14 - ETA: 0s - loss: 4.0763 - accuracy: 0.14 - ETA: 0s - loss: 4.0821 - accuracy: 0.13 - 9s 8ms/sample - loss: 4.0862 - accuracy: 0.1397 - val_loss: 3.1052 - val_accuracy: 0.0854\n",
      "Epoch 33/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 4.2118 - accuracy: 0.15 - ETA: 7s - loss: 4.4467 - accuracy: 0.12 - ETA: 7s - loss: 4.2303 - accuracy: 0.14 - ETA: 6s - loss: 4.1418 - accuracy: 0.14 - ETA: 6s - loss: 4.0201 - accuracy: 0.13 - ETA: 6s - loss: 4.1156 - accuracy: 0.15 - ETA: 6s - loss: 3.9403 - accuracy: 0.15 - ETA: 5s - loss: 3.9604 - accuracy: 0.14 - ETA: 5s - loss: 4.0023 - accuracy: 0.13 - ETA: 5s - loss: 3.9774 - accuracy: 0.12 - ETA: 5s - loss: 4.0150 - accuracy: 0.12 - ETA: 5s - loss: 3.9867 - accuracy: 0.13 - ETA: 4s - loss: 3.9704 - accuracy: 0.12 - ETA: 4s - loss: 4.0306 - accuracy: 0.12 - ETA: 4s - loss: 3.9946 - accuracy: 0.12 - ETA: 4s - loss: 3.9863 - accuracy: 0.13 - ETA: 3s - loss: 4.0266 - accuracy: 0.12 - ETA: 3s - loss: 4.0058 - accuracy: 0.13 - ETA: 3s - loss: 3.9393 - accuracy: 0.13 - ETA: 3s - loss: 3.9478 - accuracy: 0.13 - ETA: 2s - loss: 3.8867 - accuracy: 0.13 - ETA: 2s - loss: 3.8572 - accuracy: 0.13 - ETA: 2s - loss: 3.9118 - accuracy: 0.13 - ETA: 2s - loss: 3.9104 - accuracy: 0.13 - ETA: 1s - loss: 3.9090 - accuracy: 0.13 - ETA: 1s - loss: 3.9259 - accuracy: 0.13 - ETA: 1s - loss: 3.8971 - accuracy: 0.14 - ETA: 1s - loss: 3.9108 - accuracy: 0.14 - ETA: 0s - loss: 3.8824 - accuracy: 0.14 - ETA: 0s - loss: 3.9001 - accuracy: 0.14 - ETA: 0s - loss: 3.9247 - accuracy: 0.14 - ETA: 0s - loss: 3.9171 - accuracy: 0.14 - 9s 9ms/sample - loss: 3.9391 - accuracy: 0.1445 - val_loss: 2.9851 - val_accuracy: 0.1029\n",
      "Epoch 34/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.5808 - accuracy: 0.15 - ETA: 7s - loss: 3.7699 - accuracy: 0.15 - ETA: 7s - loss: 3.7414 - accuracy: 0.14 - ETA: 6s - loss: 4.0311 - accuracy: 0.12 - ETA: 6s - loss: 3.9466 - accuracy: 0.13 - ETA: 6s - loss: 3.9699 - accuracy: 0.14 - ETA: 6s - loss: 3.9697 - accuracy: 0.14 - ETA: 5s - loss: 3.9330 - accuracy: 0.14 - ETA: 5s - loss: 3.9488 - accuracy: 0.14 - ETA: 5s - loss: 4.0093 - accuracy: 0.15 - ETA: 5s - loss: 3.9396 - accuracy: 0.15 - ETA: 4s - loss: 3.9746 - accuracy: 0.16 - ETA: 4s - loss: 3.9826 - accuracy: 0.15 - ETA: 4s - loss: 3.9727 - accuracy: 0.16 - ETA: 4s - loss: 3.9038 - accuracy: 0.16 - ETA: 3s - loss: 3.9612 - accuracy: 0.16 - ETA: 3s - loss: 3.9407 - accuracy: 0.16 - ETA: 3s - loss: 3.9157 - accuracy: 0.17 - ETA: 3s - loss: 3.9139 - accuracy: 0.17 - ETA: 3s - loss: 3.9283 - accuracy: 0.17 - ETA: 2s - loss: 3.9214 - accuracy: 0.16 - ETA: 2s - loss: 3.9021 - accuracy: 0.16 - ETA: 2s - loss: 3.9142 - accuracy: 0.16 - ETA: 2s - loss: 3.9523 - accuracy: 0.16 - ETA: 1s - loss: 3.9601 - accuracy: 0.16 - ETA: 1s - loss: 4.0025 - accuracy: 0.15 - ETA: 1s - loss: 4.0002 - accuracy: 0.15 - ETA: 1s - loss: 4.0228 - accuracy: 0.15 - ETA: 0s - loss: 4.0487 - accuracy: 0.15 - ETA: 0s - loss: 4.0296 - accuracy: 0.15 - ETA: 0s - loss: 4.0347 - accuracy: 0.14 - ETA: 0s - loss: 4.0302 - accuracy: 0.14 - 9s 9ms/sample - loss: 4.0508 - accuracy: 0.1445 - val_loss: 1212.2999 - val_accuracy: 0.0621\n",
      "Epoch 35/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 4.1799 - accuracy: 0.09 - ETA: 7s - loss: 4.2147 - accuracy: 0.09 - ETA: 7s - loss: 4.1588 - accuracy: 0.08 - ETA: 6s - loss: 4.0220 - accuracy: 0.09 - ETA: 6s - loss: 4.0772 - accuracy: 0.10 - ETA: 6s - loss: 4.1417 - accuracy: 0.11 - ETA: 6s - loss: 4.1285 - accuracy: 0.10 - ETA: 5s - loss: 4.1839 - accuracy: 0.12 - ETA: 5s - loss: 4.1110 - accuracy: 0.12 - ETA: 5s - loss: 4.0921 - accuracy: 0.12 - ETA: 5s - loss: 4.1778 - accuracy: 0.12 - ETA: 4s - loss: 4.1258 - accuracy: 0.12 - ETA: 4s - loss: 4.1173 - accuracy: 0.11 - ETA: 4s - loss: 4.1366 - accuracy: 0.11 - ETA: 4s - loss: 4.1011 - accuracy: 0.12 - ETA: 3s - loss: 4.0910 - accuracy: 0.12 - ETA: 3s - loss: 4.1433 - accuracy: 0.11 - ETA: 3s - loss: 4.1391 - accuracy: 0.11 - ETA: 3s - loss: 4.1068 - accuracy: 0.11 - ETA: 3s - loss: 4.1142 - accuracy: 0.11 - ETA: 2s - loss: 4.0996 - accuracy: 0.12 - ETA: 2s - loss: 4.0452 - accuracy: 0.12 - ETA: 2s - loss: 4.0860 - accuracy: 0.11 - ETA: 2s - loss: 4.0367 - accuracy: 0.11 - ETA: 1s - loss: 4.0353 - accuracy: 0.11 - ETA: 1s - loss: 4.0716 - accuracy: 0.11 - ETA: 1s - loss: 4.0690 - accuracy: 0.11 - ETA: 1s - loss: 4.0796 - accuracy: 0.10 - ETA: 0s - loss: 4.0671 - accuracy: 0.10 - ETA: 0s - loss: 4.0786 - accuracy: 0.10 - ETA: 0s - loss: 4.0860 - accuracy: 0.10 - ETA: 0s - loss: 4.0868 - accuracy: 0.10 - 9s 9ms/sample - loss: 4.0828 - accuracy: 0.1053 - val_loss: 453.7356 - val_accuracy: 0.0369\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 4.5858 - accuracy: 0.09 - ETA: 7s - loss: 4.7402 - accuracy: 0.10 - ETA: 7s - loss: 4.0664 - accuracy: 0.10 - ETA: 6s - loss: 4.0339 - accuracy: 0.09 - ETA: 6s - loss: 3.9478 - accuracy: 0.10 - ETA: 6s - loss: 3.9978 - accuracy: 0.09 - ETA: 6s - loss: 4.0836 - accuracy: 0.08 - ETA: 5s - loss: 4.0854 - accuracy: 0.08 - ETA: 5s - loss: 4.0340 - accuracy: 0.09 - ETA: 5s - loss: 4.0650 - accuracy: 0.09 - ETA: 5s - loss: 4.0601 - accuracy: 0.10 - ETA: 4s - loss: 4.0447 - accuracy: 0.10 - ETA: 4s - loss: 4.0227 - accuracy: 0.10 - ETA: 4s - loss: 4.0337 - accuracy: 0.10 - ETA: 4s - loss: 4.0795 - accuracy: 0.10 - ETA: 3s - loss: 3.9973 - accuracy: 0.11 - ETA: 3s - loss: 3.9621 - accuracy: 0.11 - ETA: 3s - loss: 3.9371 - accuracy: 0.10 - ETA: 3s - loss: 3.9340 - accuracy: 0.11 - ETA: 3s - loss: 3.9264 - accuracy: 0.11 - ETA: 2s - loss: 3.9556 - accuracy: 0.11 - ETA: 2s - loss: 3.9389 - accuracy: 0.11 - ETA: 2s - loss: 3.9328 - accuracy: 0.11 - ETA: 2s - loss: 3.9420 - accuracy: 0.12 - ETA: 1s - loss: 3.9350 - accuracy: 0.12 - ETA: 1s - loss: 3.9413 - accuracy: 0.11 - ETA: 1s - loss: 3.9379 - accuracy: 0.11 - ETA: 1s - loss: 3.9587 - accuracy: 0.11 - ETA: 0s - loss: 3.9714 - accuracy: 0.11 - ETA: 0s - loss: 3.9479 - accuracy: 0.11 - ETA: 0s - loss: 3.9569 - accuracy: 0.12 - ETA: 0s - loss: 3.9445 - accuracy: 0.12 - 9s 9ms/sample - loss: 3.9556 - accuracy: 0.1234 - val_loss: 35.3938 - val_accuracy: 0.0913\n",
      "Epoch 37/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.9861 - accuracy: 0.12 - ETA: 7s - loss: 4.0651 - accuracy: 0.14 - ETA: 7s - loss: 3.8694 - accuracy: 0.16 - ETA: 6s - loss: 3.5483 - accuracy: 0.17 - ETA: 6s - loss: 3.6646 - accuracy: 0.17 - ETA: 6s - loss: 3.8196 - accuracy: 0.15 - ETA: 6s - loss: 3.7919 - accuracy: 0.16 - ETA: 5s - loss: 3.7677 - accuracy: 0.16 - ETA: 5s - loss: 3.6322 - accuracy: 0.16 - ETA: 5s - loss: 3.6555 - accuracy: 0.15 - ETA: 5s - loss: 3.6812 - accuracy: 0.15 - ETA: 4s - loss: 3.7458 - accuracy: 0.15 - ETA: 4s - loss: 3.7364 - accuracy: 0.15 - ETA: 4s - loss: 3.7715 - accuracy: 0.15 - ETA: 4s - loss: 3.7947 - accuracy: 0.15 - ETA: 3s - loss: 3.7884 - accuracy: 0.16 - ETA: 3s - loss: 3.7649 - accuracy: 0.16 - ETA: 3s - loss: 3.7845 - accuracy: 0.15 - ETA: 3s - loss: 3.7879 - accuracy: 0.15 - ETA: 3s - loss: 3.7731 - accuracy: 0.15 - ETA: 2s - loss: 3.7978 - accuracy: 0.15 - ETA: 2s - loss: 3.7983 - accuracy: 0.15 - ETA: 2s - loss: 3.7780 - accuracy: 0.15 - ETA: 2s - loss: 3.7775 - accuracy: 0.15 - ETA: 1s - loss: 3.7984 - accuracy: 0.15 - ETA: 1s - loss: 3.7632 - accuracy: 0.15 - ETA: 1s - loss: 3.7531 - accuracy: 0.16 - ETA: 1s - loss: 3.7493 - accuracy: 0.16 - ETA: 0s - loss: 3.7619 - accuracy: 0.16 - ETA: 0s - loss: 3.7880 - accuracy: 0.15 - ETA: 0s - loss: 3.7777 - accuracy: 0.15 - ETA: 0s - loss: 3.7584 - accuracy: 0.16 - 9s 9ms/sample - loss: 3.7757 - accuracy: 0.1598 - val_loss: 24.0676 - val_accuracy: 0.0932\n",
      "Epoch 38/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 4.1451 - accuracy: 0.15 - ETA: 7s - loss: 3.9585 - accuracy: 0.21 - ETA: 7s - loss: 3.8663 - accuracy: 0.22 - ETA: 6s - loss: 3.9362 - accuracy: 0.21 - ETA: 6s - loss: 3.8152 - accuracy: 0.21 - ETA: 6s - loss: 3.8185 - accuracy: 0.22 - ETA: 6s - loss: 3.7252 - accuracy: 0.22 - ETA: 5s - loss: 3.8150 - accuracy: 0.22 - ETA: 5s - loss: 3.7961 - accuracy: 0.21 - ETA: 5s - loss: 3.8237 - accuracy: 0.20 - ETA: 5s - loss: 3.8721 - accuracy: 0.20 - ETA: 4s - loss: 3.8674 - accuracy: 0.19 - ETA: 4s - loss: 3.8524 - accuracy: 0.18 - ETA: 4s - loss: 3.8160 - accuracy: 0.17 - ETA: 4s - loss: 3.8842 - accuracy: 0.17 - ETA: 4s - loss: 3.8136 - accuracy: 0.18 - ETA: 3s - loss: 3.8618 - accuracy: 0.18 - ETA: 3s - loss: 3.8361 - accuracy: 0.17 - ETA: 3s - loss: 3.8889 - accuracy: 0.17 - ETA: 3s - loss: 3.8608 - accuracy: 0.16 - ETA: 2s - loss: 3.8974 - accuracy: 0.16 - ETA: 2s - loss: 3.9040 - accuracy: 0.16 - ETA: 2s - loss: 3.8942 - accuracy: 0.15 - ETA: 2s - loss: 3.8963 - accuracy: 0.16 - ETA: 1s - loss: 3.8704 - accuracy: 0.16 - ETA: 1s - loss: 3.8553 - accuracy: 0.16 - ETA: 1s - loss: 3.8729 - accuracy: 0.16 - ETA: 1s - loss: 3.8734 - accuracy: 0.16 - ETA: 0s - loss: 3.8584 - accuracy: 0.16 - ETA: 0s - loss: 3.8724 - accuracy: 0.16 - ETA: 0s - loss: 3.8575 - accuracy: 0.15 - ETA: 0s - loss: 3.8746 - accuracy: 0.16 - 9s 9ms/sample - loss: 3.8539 - accuracy: 0.1608 - val_loss: 22.2182 - val_accuracy: 0.1049\n",
      "Epoch 39/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 2.6199 - accuracy: 0.12 - ETA: 7s - loss: 3.3747 - accuracy: 0.17 - ETA: 7s - loss: 3.5193 - accuracy: 0.12 - ETA: 6s - loss: 3.8063 - accuracy: 0.12 - ETA: 6s - loss: 3.7918 - accuracy: 0.15 - ETA: 6s - loss: 3.6747 - accuracy: 0.15 - ETA: 6s - loss: 3.5562 - accuracy: 0.16 - ETA: 5s - loss: 3.4449 - accuracy: 0.17 - ETA: 5s - loss: 3.5268 - accuracy: 0.18 - ETA: 5s - loss: 3.5552 - accuracy: 0.17 - ETA: 5s - loss: 3.4781 - accuracy: 0.18 - ETA: 4s - loss: 3.5368 - accuracy: 0.19 - ETA: 4s - loss: 3.5726 - accuracy: 0.20 - ETA: 4s - loss: 3.5449 - accuracy: 0.19 - ETA: 4s - loss: 3.5441 - accuracy: 0.18 - ETA: 3s - loss: 3.5793 - accuracy: 0.18 - ETA: 3s - loss: 3.6131 - accuracy: 0.18 - ETA: 3s - loss: 3.5705 - accuracy: 0.18 - ETA: 3s - loss: 3.6366 - accuracy: 0.18 - ETA: 3s - loss: 3.6527 - accuracy: 0.19 - ETA: 2s - loss: 3.6434 - accuracy: 0.19 - ETA: 2s - loss: 3.6440 - accuracy: 0.19 - ETA: 2s - loss: 3.6512 - accuracy: 0.18 - ETA: 2s - loss: 3.6490 - accuracy: 0.18 - ETA: 1s - loss: 3.6438 - accuracy: 0.19 - ETA: 1s - loss: 3.6296 - accuracy: 0.19 - ETA: 1s - loss: 3.6523 - accuracy: 0.19 - ETA: 1s - loss: 3.6506 - accuracy: 0.19 - ETA: 0s - loss: 3.6474 - accuracy: 0.19 - ETA: 0s - loss: 3.6359 - accuracy: 0.19 - ETA: 0s - loss: 3.6406 - accuracy: 0.19 - ETA: 0s - loss: 3.6358 - accuracy: 0.19 - 14s 13ms/sample - loss: 3.6524 - accuracy: 0.1923 - val_loss: 11.2564 - val_accuracy: 0.1359\n",
      "Epoch 40/50\n",
      "1045/1045 [==============================] - ETA: 8s - loss: 4.4473 - accuracy: 0.12 - ETA: 8s - loss: 4.0910 - accuracy: 0.12 - ETA: 7s - loss: 3.9165 - accuracy: 0.14 - ETA: 7s - loss: 3.8873 - accuracy: 0.14 - ETA: 6s - loss: 3.6258 - accuracy: 0.17 - ETA: 6s - loss: 3.5567 - accuracy: 0.16 - ETA: 6s - loss: 3.6306 - accuracy: 0.16 - ETA: 5s - loss: 3.6170 - accuracy: 0.18 - ETA: 5s - loss: 3.6123 - accuracy: 0.17 - ETA: 5s - loss: 3.6644 - accuracy: 0.16 - ETA: 5s - loss: 3.7127 - accuracy: 0.16 - ETA: 4s - loss: 3.6634 - accuracy: 0.17 - ETA: 4s - loss: 3.7025 - accuracy: 0.17 - ETA: 4s - loss: 3.6958 - accuracy: 0.17 - ETA: 4s - loss: 3.6477 - accuracy: 0.18 - ETA: 3s - loss: 3.6872 - accuracy: 0.18 - ETA: 3s - loss: 3.6734 - accuracy: 0.18 - ETA: 3s - loss: 3.7001 - accuracy: 0.18 - ETA: 3s - loss: 3.6496 - accuracy: 0.18 - ETA: 3s - loss: 3.6349 - accuracy: 0.18 - ETA: 2s - loss: 3.5826 - accuracy: 0.18 - ETA: 2s - loss: 3.5859 - accuracy: 0.18 - ETA: 2s - loss: 3.5723 - accuracy: 0.18 - ETA: 2s - loss: 3.6074 - accuracy: 0.18 - ETA: 1s - loss: 3.6173 - accuracy: 0.17 - ETA: 1s - loss: 3.6159 - accuracy: 0.17 - ETA: 1s - loss: 3.6497 - accuracy: 0.17 - ETA: 1s - loss: 3.6450 - accuracy: 0.17 - ETA: 0s - loss: 3.6566 - accuracy: 0.17 - ETA: 0s - loss: 3.6487 - accuracy: 0.17 - ETA: 0s - loss: 3.6648 - accuracy: 0.17 - ETA: 0s - loss: 3.6474 - accuracy: 0.17 - 9s 9ms/sample - loss: 3.6629 - accuracy: 0.1694 - val_loss: 244.8599 - val_accuracy: 0.1068\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 4.0036 - accuracy: 0.31 - ETA: 7s - loss: 3.8169 - accuracy: 0.28 - ETA: 7s - loss: 3.9265 - accuracy: 0.21 - ETA: 6s - loss: 3.6670 - accuracy: 0.18 - ETA: 6s - loss: 3.6558 - accuracy: 0.17 - ETA: 6s - loss: 3.8332 - accuracy: 0.17 - ETA: 6s - loss: 3.7838 - accuracy: 0.16 - ETA: 5s - loss: 3.7542 - accuracy: 0.16 - ETA: 5s - loss: 3.8049 - accuracy: 0.16 - ETA: 5s - loss: 3.7513 - accuracy: 0.16 - ETA: 5s - loss: 3.7293 - accuracy: 0.16 - ETA: 4s - loss: 3.7390 - accuracy: 0.16 - ETA: 4s - loss: 3.7104 - accuracy: 0.16 - ETA: 4s - loss: 3.6680 - accuracy: 0.15 - ETA: 4s - loss: 3.7159 - accuracy: 0.15 - ETA: 3s - loss: 3.6835 - accuracy: 0.16 - ETA: 3s - loss: 3.7015 - accuracy: 0.15 - ETA: 3s - loss: 3.7077 - accuracy: 0.15 - ETA: 3s - loss: 3.7375 - accuracy: 0.15 - ETA: 3s - loss: 3.7135 - accuracy: 0.15 - ETA: 2s - loss: 3.6742 - accuracy: 0.14 - ETA: 2s - loss: 3.6997 - accuracy: 0.14 - ETA: 2s - loss: 3.6857 - accuracy: 0.14 - ETA: 2s - loss: 3.6836 - accuracy: 0.14 - ETA: 1s - loss: 3.7071 - accuracy: 0.15 - ETA: 1s - loss: 3.6994 - accuracy: 0.15 - ETA: 1s - loss: 3.6570 - accuracy: 0.15 - ETA: 1s - loss: 3.6442 - accuracy: 0.15 - ETA: 0s - loss: 3.6298 - accuracy: 0.15 - ETA: 0s - loss: 3.6358 - accuracy: 0.15 - ETA: 0s - loss: 3.6611 - accuracy: 0.15 - ETA: 0s - loss: 3.6174 - accuracy: 0.15 - 9s 8ms/sample - loss: 3.6253 - accuracy: 0.1550 - val_loss: 81.6605 - val_accuracy: 0.1301\n",
      "Epoch 42/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.8325 - accuracy: 0.15 - ETA: 7s - loss: 3.5912 - accuracy: 0.20 - ETA: 7s - loss: 3.7881 - accuracy: 0.17 - ETA: 6s - loss: 3.5815 - accuracy: 0.17 - ETA: 6s - loss: 3.5726 - accuracy: 0.18 - ETA: 6s - loss: 3.6805 - accuracy: 0.16 - ETA: 6s - loss: 3.6366 - accuracy: 0.17 - ETA: 5s - loss: 3.6927 - accuracy: 0.19 - ETA: 5s - loss: 3.5972 - accuracy: 0.19 - ETA: 5s - loss: 3.6352 - accuracy: 0.19 - ETA: 5s - loss: 3.6452 - accuracy: 0.18 - ETA: 4s - loss: 3.6744 - accuracy: 0.19 - ETA: 4s - loss: 3.6241 - accuracy: 0.20 - ETA: 4s - loss: 3.6462 - accuracy: 0.18 - ETA: 4s - loss: 3.6521 - accuracy: 0.18 - ETA: 3s - loss: 3.5894 - accuracy: 0.18 - ETA: 3s - loss: 3.5964 - accuracy: 0.18 - ETA: 3s - loss: 3.5415 - accuracy: 0.18 - ETA: 3s - loss: 3.5884 - accuracy: 0.18 - ETA: 3s - loss: 3.5429 - accuracy: 0.17 - ETA: 2s - loss: 3.5378 - accuracy: 0.17 - ETA: 2s - loss: 3.5331 - accuracy: 0.17 - ETA: 2s - loss: 3.5613 - accuracy: 0.17 - ETA: 2s - loss: 3.5400 - accuracy: 0.17 - ETA: 1s - loss: 3.5478 - accuracy: 0.17 - ETA: 1s - loss: 3.5730 - accuracy: 0.17 - ETA: 1s - loss: 3.5594 - accuracy: 0.17 - ETA: 1s - loss: 3.5729 - accuracy: 0.17 - ETA: 0s - loss: 3.5707 - accuracy: 0.17 - ETA: 0s - loss: 3.5498 - accuracy: 0.17 - ETA: 0s - loss: 3.5880 - accuracy: 0.17 - ETA: 0s - loss: 3.5687 - accuracy: 0.17 - 9s 8ms/sample - loss: 3.5684 - accuracy: 0.1780 - val_loss: 29.8024 - val_accuracy: 0.1320\n",
      "Epoch 43/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.9167 - accuracy: 0.15 - ETA: 7s - loss: 3.5739 - accuracy: 0.21 - ETA: 7s - loss: 3.7616 - accuracy: 0.18 - ETA: 6s - loss: 3.4881 - accuracy: 0.19 - ETA: 6s - loss: 3.5475 - accuracy: 0.20 - ETA: 6s - loss: 3.5050 - accuracy: 0.20 - ETA: 6s - loss: 3.5312 - accuracy: 0.20 - ETA: 5s - loss: 3.5719 - accuracy: 0.22 - ETA: 5s - loss: 3.5160 - accuracy: 0.22 - ETA: 5s - loss: 3.5339 - accuracy: 0.21 - ETA: 5s - loss: 3.5629 - accuracy: 0.21 - ETA: 4s - loss: 3.5086 - accuracy: 0.21 - ETA: 4s - loss: 3.6087 - accuracy: 0.20 - ETA: 4s - loss: 3.5702 - accuracy: 0.19 - ETA: 4s - loss: 3.5892 - accuracy: 0.19 - ETA: 3s - loss: 3.5714 - accuracy: 0.19 - ETA: 3s - loss: 3.5680 - accuracy: 0.19 - ETA: 3s - loss: 3.6393 - accuracy: 0.19 - ETA: 3s - loss: 3.6128 - accuracy: 0.19 - ETA: 3s - loss: 3.6084 - accuracy: 0.19 - ETA: 2s - loss: 3.6280 - accuracy: 0.19 - ETA: 2s - loss: 3.6065 - accuracy: 0.19 - ETA: 2s - loss: 3.6124 - accuracy: 0.19 - ETA: 2s - loss: 3.5682 - accuracy: 0.19 - ETA: 1s - loss: 3.5730 - accuracy: 0.19 - ETA: 1s - loss: 3.5725 - accuracy: 0.19 - ETA: 1s - loss: 3.5637 - accuracy: 0.19 - ETA: 1s - loss: 3.5685 - accuracy: 0.19 - ETA: 0s - loss: 3.6180 - accuracy: 0.18 - ETA: 0s - loss: 3.5817 - accuracy: 0.19 - ETA: 0s - loss: 3.5846 - accuracy: 0.19 - ETA: 0s - loss: 3.5866 - accuracy: 0.19 - 14s 13ms/sample - loss: 3.5829 - accuracy: 0.1943 - val_loss: 11.9250 - val_accuracy: 0.1398\n",
      "Epoch 44/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.9078 - accuracy: 0.21 - ETA: 7s - loss: 3.8539 - accuracy: 0.15 - ETA: 7s - loss: 3.9274 - accuracy: 0.18 - ETA: 6s - loss: 3.8406 - accuracy: 0.20 - ETA: 6s - loss: 3.6460 - accuracy: 0.20 - ETA: 6s - loss: 3.6317 - accuracy: 0.20 - ETA: 6s - loss: 3.6990 - accuracy: 0.20 - ETA: 5s - loss: 3.7198 - accuracy: 0.20 - ETA: 5s - loss: 3.6859 - accuracy: 0.19 - ETA: 5s - loss: 3.6121 - accuracy: 0.19 - ETA: 5s - loss: 3.6233 - accuracy: 0.19 - ETA: 4s - loss: 3.5948 - accuracy: 0.19 - ETA: 4s - loss: 3.5498 - accuracy: 0.20 - ETA: 4s - loss: 3.5550 - accuracy: 0.20 - ETA: 4s - loss: 3.4858 - accuracy: 0.20 - ETA: 3s - loss: 3.4541 - accuracy: 0.20 - ETA: 3s - loss: 3.4531 - accuracy: 0.20 - ETA: 3s - loss: 3.4537 - accuracy: 0.20 - ETA: 3s - loss: 3.4968 - accuracy: 0.20 - ETA: 3s - loss: 3.4608 - accuracy: 0.20 - ETA: 2s - loss: 3.4298 - accuracy: 0.19 - ETA: 2s - loss: 3.4398 - accuracy: 0.19 - ETA: 2s - loss: 3.4370 - accuracy: 0.19 - ETA: 2s - loss: 3.4441 - accuracy: 0.19 - ETA: 1s - loss: 3.4476 - accuracy: 0.19 - ETA: 1s - loss: 3.4397 - accuracy: 0.19 - ETA: 1s - loss: 3.4376 - accuracy: 0.20 - ETA: 1s - loss: 3.4403 - accuracy: 0.19 - ETA: 0s - loss: 3.4418 - accuracy: 0.19 - ETA: 0s - loss: 3.4349 - accuracy: 0.19 - ETA: 0s - loss: 3.4595 - accuracy: 0.19 - ETA: 0s - loss: 3.4576 - accuracy: 0.19 - 12s 12ms/sample - loss: 3.4508 - accuracy: 0.1943 - val_loss: 4.1339 - val_accuracy: 0.1786\n",
      "Epoch 45/50\n",
      "1045/1045 [==============================] - ETA: 8s - loss: 2.3171 - accuracy: 0.31 - ETA: 7s - loss: 2.3045 - accuracy: 0.28 - ETA: 7s - loss: 2.7727 - accuracy: 0.26 - ETA: 7s - loss: 2.9442 - accuracy: 0.22 - ETA: 6s - loss: 3.0676 - accuracy: 0.22 - ETA: 6s - loss: 3.1139 - accuracy: 0.22 - ETA: 6s - loss: 3.1619 - accuracy: 0.22 - ETA: 5s - loss: 3.1313 - accuracy: 0.21 - ETA: 5s - loss: 3.1803 - accuracy: 0.20 - ETA: 5s - loss: 3.1719 - accuracy: 0.20 - ETA: 5s - loss: 3.2221 - accuracy: 0.20 - ETA: 4s - loss: 3.2429 - accuracy: 0.20 - ETA: 4s - loss: 3.2801 - accuracy: 0.20 - ETA: 4s - loss: 3.2851 - accuracy: 0.20 - ETA: 4s - loss: 3.2325 - accuracy: 0.20 - ETA: 4s - loss: 3.2631 - accuracy: 0.20 - ETA: 3s - loss: 3.2730 - accuracy: 0.20 - ETA: 3s - loss: 3.2754 - accuracy: 0.20 - ETA: 3s - loss: 3.2689 - accuracy: 0.21 - ETA: 3s - loss: 3.2814 - accuracy: 0.21 - ETA: 2s - loss: 3.2985 - accuracy: 0.21 - ETA: 2s - loss: 3.2910 - accuracy: 0.21 - ETA: 2s - loss: 3.2876 - accuracy: 0.21 - ETA: 2s - loss: 3.3317 - accuracy: 0.20 - ETA: 1s - loss: 3.3377 - accuracy: 0.21 - ETA: 1s - loss: 3.3299 - accuracy: 0.21 - ETA: 1s - loss: 3.3209 - accuracy: 0.21 - ETA: 1s - loss: 3.3279 - accuracy: 0.21 - ETA: 0s - loss: 3.3563 - accuracy: 0.20 - ETA: 0s - loss: 3.3588 - accuracy: 0.20 - ETA: 0s - loss: 3.3344 - accuracy: 0.20 - ETA: 0s - loss: 3.3436 - accuracy: 0.20 - 13s 12ms/sample - loss: 3.3554 - accuracy: 0.2048 - val_loss: 3.8895 - val_accuracy: 0.2175\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 3.3850 - accuracy: 0.21 - ETA: 7s - loss: 3.1408 - accuracy: 0.18 - ETA: 7s - loss: 3.2126 - accuracy: 0.22 - ETA: 6s - loss: 3.0099 - accuracy: 0.22 - ETA: 6s - loss: 2.9999 - accuracy: 0.23 - ETA: 6s - loss: 3.1279 - accuracy: 0.23 - ETA: 6s - loss: 3.1608 - accuracy: 0.22 - ETA: 5s - loss: 3.1319 - accuracy: 0.21 - ETA: 5s - loss: 3.1883 - accuracy: 0.22 - ETA: 5s - loss: 3.2407 - accuracy: 0.21 - ETA: 5s - loss: 3.2778 - accuracy: 0.22 - ETA: 5s - loss: 3.2247 - accuracy: 0.23 - ETA: 4s - loss: 3.2884 - accuracy: 0.22 - ETA: 4s - loss: 3.2759 - accuracy: 0.21 - ETA: 4s - loss: 3.2505 - accuracy: 0.22 - ETA: 4s - loss: 3.2285 - accuracy: 0.22 - ETA: 3s - loss: 3.2603 - accuracy: 0.22 - ETA: 3s - loss: 3.2518 - accuracy: 0.23 - ETA: 3s - loss: 3.2384 - accuracy: 0.23 - ETA: 3s - loss: 3.2485 - accuracy: 0.22 - ETA: 2s - loss: 3.2714 - accuracy: 0.22 - ETA: 2s - loss: 3.2699 - accuracy: 0.22 - ETA: 2s - loss: 3.2323 - accuracy: 0.22 - ETA: 2s - loss: 3.2258 - accuracy: 0.22 - ETA: 1s - loss: 3.2199 - accuracy: 0.22 - ETA: 1s - loss: 3.2269 - accuracy: 0.22 - ETA: 1s - loss: 3.2498 - accuracy: 0.22 - ETA: 1s - loss: 3.2421 - accuracy: 0.22 - ETA: 0s - loss: 3.2733 - accuracy: 0.21 - ETA: 0s - loss: 3.2755 - accuracy: 0.21 - ETA: 0s - loss: 3.2728 - accuracy: 0.21 - ETA: 0s - loss: 3.2758 - accuracy: 0.21 - 10s 9ms/sample - loss: 3.2947 - accuracy: 0.2096 - val_loss: 5.0618 - val_accuracy: 0.1806\n",
      "Epoch 47/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.5785 - accuracy: 0.12 - ETA: 7s - loss: 3.5975 - accuracy: 0.17 - ETA: 7s - loss: 3.4261 - accuracy: 0.17 - ETA: 6s - loss: 3.3370 - accuracy: 0.18 - ETA: 6s - loss: 3.4055 - accuracy: 0.20 - ETA: 6s - loss: 3.3220 - accuracy: 0.20 - ETA: 6s - loss: 3.3452 - accuracy: 0.20 - ETA: 5s - loss: 3.3644 - accuracy: 0.21 - ETA: 5s - loss: 3.3371 - accuracy: 0.22 - ETA: 5s - loss: 3.3646 - accuracy: 0.22 - ETA: 5s - loss: 3.3321 - accuracy: 0.23 - ETA: 4s - loss: 3.3370 - accuracy: 0.22 - ETA: 4s - loss: 3.3017 - accuracy: 0.23 - ETA: 4s - loss: 3.2967 - accuracy: 0.24 - ETA: 4s - loss: 3.3039 - accuracy: 0.23 - ETA: 3s - loss: 3.2989 - accuracy: 0.22 - ETA: 3s - loss: 3.3528 - accuracy: 0.22 - ETA: 3s - loss: 3.3302 - accuracy: 0.22 - ETA: 3s - loss: 3.3281 - accuracy: 0.22 - ETA: 3s - loss: 3.2997 - accuracy: 0.22 - ETA: 2s - loss: 3.3001 - accuracy: 0.22 - ETA: 2s - loss: 3.3037 - accuracy: 0.22 - ETA: 2s - loss: 3.2588 - accuracy: 0.23 - ETA: 2s - loss: 3.2612 - accuracy: 0.23 - ETA: 1s - loss: 3.2293 - accuracy: 0.24 - ETA: 1s - loss: 3.1876 - accuracy: 0.24 - ETA: 1s - loss: 3.1939 - accuracy: 0.24 - ETA: 1s - loss: 3.2059 - accuracy: 0.24 - ETA: 0s - loss: 3.2191 - accuracy: 0.24 - ETA: 0s - loss: 3.1872 - accuracy: 0.24 - ETA: 0s - loss: 3.1467 - accuracy: 0.24 - ETA: 0s - loss: 3.1570 - accuracy: 0.24 - 9s 8ms/sample - loss: 3.1712 - accuracy: 0.2459 - val_loss: 2.9782 - val_accuracy: 0.2039\n",
      "Epoch 48/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 2.6357 - accuracy: 0.21 - ETA: 7s - loss: 2.9729 - accuracy: 0.21 - ETA: 7s - loss: 2.7285 - accuracy: 0.27 - ETA: 6s - loss: 2.6130 - accuracy: 0.27 - ETA: 6s - loss: 2.7746 - accuracy: 0.26 - ETA: 6s - loss: 2.6516 - accuracy: 0.28 - ETA: 6s - loss: 2.6515 - accuracy: 0.28 - ETA: 5s - loss: 2.7363 - accuracy: 0.26 - ETA: 5s - loss: 2.7492 - accuracy: 0.26 - ETA: 5s - loss: 2.8041 - accuracy: 0.26 - ETA: 5s - loss: 2.8504 - accuracy: 0.26 - ETA: 4s - loss: 2.8663 - accuracy: 0.25 - ETA: 4s - loss: 2.8844 - accuracy: 0.25 - ETA: 4s - loss: 2.9261 - accuracy: 0.25 - ETA: 4s - loss: 2.9272 - accuracy: 0.25 - ETA: 3s - loss: 2.9653 - accuracy: 0.25 - ETA: 3s - loss: 2.9953 - accuracy: 0.25 - ETA: 3s - loss: 3.0032 - accuracy: 0.25 - ETA: 3s - loss: 3.0225 - accuracy: 0.25 - ETA: 3s - loss: 3.0076 - accuracy: 0.25 - ETA: 2s - loss: 3.0304 - accuracy: 0.25 - ETA: 2s - loss: 3.0572 - accuracy: 0.25 - ETA: 2s - loss: 3.0704 - accuracy: 0.25 - ETA: 2s - loss: 3.0590 - accuracy: 0.25 - ETA: 1s - loss: 3.0807 - accuracy: 0.25 - ETA: 1s - loss: 3.0902 - accuracy: 0.25 - ETA: 1s - loss: 3.1033 - accuracy: 0.25 - ETA: 1s - loss: 3.0902 - accuracy: 0.25 - ETA: 0s - loss: 3.0680 - accuracy: 0.25 - ETA: 0s - loss: 3.0414 - accuracy: 0.25 - ETA: 0s - loss: 3.0374 - accuracy: 0.25 - ETA: 0s - loss: 3.0349 - accuracy: 0.25 - 12s 12ms/sample - loss: 3.0447 - accuracy: 0.2593 - val_loss: 4.6194 - val_accuracy: 0.2583\n",
      "Epoch 49/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.2365 - accuracy: 0.31 - ETA: 7s - loss: 3.3217 - accuracy: 0.23 - ETA: 7s - loss: 2.9455 - accuracy: 0.23 - ETA: 6s - loss: 2.9605 - accuracy: 0.26 - ETA: 6s - loss: 3.0015 - accuracy: 0.25 - ETA: 6s - loss: 2.9860 - accuracy: 0.25 - ETA: 6s - loss: 2.8557 - accuracy: 0.26 - ETA: 5s - loss: 2.8426 - accuracy: 0.27 - ETA: 5s - loss: 2.9018 - accuracy: 0.27 - ETA: 5s - loss: 2.8634 - accuracy: 0.27 - ETA: 5s - loss: 2.8947 - accuracy: 0.28 - ETA: 4s - loss: 2.9471 - accuracy: 0.28 - ETA: 4s - loss: 2.9637 - accuracy: 0.27 - ETA: 4s - loss: 2.9791 - accuracy: 0.27 - ETA: 4s - loss: 3.0167 - accuracy: 0.26 - ETA: 3s - loss: 3.0238 - accuracy: 0.27 - ETA: 3s - loss: 3.0380 - accuracy: 0.28 - ETA: 3s - loss: 3.0373 - accuracy: 0.27 - ETA: 3s - loss: 3.0628 - accuracy: 0.27 - ETA: 3s - loss: 3.0371 - accuracy: 0.27 - ETA: 2s - loss: 3.0438 - accuracy: 0.27 - ETA: 2s - loss: 3.0883 - accuracy: 0.26 - ETA: 2s - loss: 3.0822 - accuracy: 0.26 - ETA: 2s - loss: 3.0744 - accuracy: 0.26 - ETA: 1s - loss: 3.0718 - accuracy: 0.26 - ETA: 1s - loss: 3.0885 - accuracy: 0.26 - ETA: 1s - loss: 3.0914 - accuracy: 0.26 - ETA: 1s - loss: 3.0905 - accuracy: 0.26 - ETA: 0s - loss: 3.0710 - accuracy: 0.26 - ETA: 0s - loss: 3.0715 - accuracy: 0.26 - ETA: 0s - loss: 3.0630 - accuracy: 0.26 - ETA: 0s - loss: 3.0870 - accuracy: 0.26 - 9s 9ms/sample - loss: 3.0815 - accuracy: 0.2593 - val_loss: 4.4856 - val_accuracy: 0.2408\n",
      "Epoch 50/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.4512 - accuracy: 0.28 - ETA: 7s - loss: 3.3269 - accuracy: 0.28 - ETA: 7s - loss: 3.1589 - accuracy: 0.29 - ETA: 6s - loss: 3.2346 - accuracy: 0.26 - ETA: 6s - loss: 3.1244 - accuracy: 0.30 - ETA: 6s - loss: 3.0586 - accuracy: 0.29 - ETA: 6s - loss: 3.1174 - accuracy: 0.29 - ETA: 5s - loss: 3.0846 - accuracy: 0.28 - ETA: 5s - loss: 3.0445 - accuracy: 0.27 - ETA: 5s - loss: 3.1266 - accuracy: 0.26 - ETA: 5s - loss: 3.0532 - accuracy: 0.26 - ETA: 4s - loss: 3.0482 - accuracy: 0.26 - ETA: 4s - loss: 2.9801 - accuracy: 0.26 - ETA: 4s - loss: 3.0079 - accuracy: 0.27 - ETA: 4s - loss: 3.0366 - accuracy: 0.26 - ETA: 3s - loss: 3.0218 - accuracy: 0.26 - ETA: 3s - loss: 2.9826 - accuracy: 0.27 - ETA: 3s - loss: 2.9434 - accuracy: 0.27 - ETA: 3s - loss: 2.9320 - accuracy: 0.27 - ETA: 3s - loss: 2.9415 - accuracy: 0.27 - ETA: 2s - loss: 2.8938 - accuracy: 0.28 - ETA: 2s - loss: 2.8984 - accuracy: 0.28 - ETA: 2s - loss: 2.9068 - accuracy: 0.28 - ETA: 2s - loss: 2.9223 - accuracy: 0.28 - ETA: 1s - loss: 2.8806 - accuracy: 0.28 - ETA: 1s - loss: 2.8781 - accuracy: 0.28 - ETA: 1s - loss: 2.8398 - accuracy: 0.28 - ETA: 1s - loss: 2.8662 - accuracy: 0.28 - ETA: 0s - loss: 2.8340 - accuracy: 0.28 - ETA: 0s - loss: 2.8187 - accuracy: 0.28 - ETA: 0s - loss: 2.8232 - accuracy: 0.29 - ETA: 0s - loss: 2.8322 - accuracy: 0.28 - 13s 12ms/sample - loss: 2.8509 - accuracy: 0.2880 - val_loss: 3.8903 - val_accuracy: 0.2621\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: b18ec7449791eea38bf8bad88a89bcd4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.26213592290878296</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv3_depth: 8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv4_depth: 36</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: sgd</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-pooling: max</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-version: next</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1045 samples, validate on 515 samples\n",
      "Epoch 1/50\n",
      "1045/1045 [==============================] - ETA: 14:52 - loss: 5.2203 - accuracy: 0.0000e+0 - ETA: 7:15 - loss: 7.6960 - accuracy: 0.0156    - ETA: 4:43 - loss: 9.4112 - accuracy: 0.01 - ETA: 3:27 - loss: 10.2342 - accuracy: 0.015 - ETA: 2:41 - loss: 10.2715 - accuracy: 0.012 - ETA: 2:10 - loss: 10.3234 - accuracy: 0.020 - ETA: 1:48 - loss: 9.9141 - accuracy: 0.031 - ETA: 1:31 - loss: 9.8002 - accuracy: 0.02 - ETA: 1:18 - loss: 9.7102 - accuracy: 0.02 - ETA: 1:08 - loss: 9.4558 - accuracy: 0.02 - ETA: 59s - loss: 9.2995 - accuracy: 0.0341 - ETA: 52s - loss: 9.1493 - accuracy: 0.033 - ETA: 46s - loss: 9.0645 - accuracy: 0.033 - ETA: 41s - loss: 8.8170 - accuracy: 0.040 - ETA: 36s - loss: 8.6312 - accuracy: 0.041 - ETA: 32s - loss: 8.4250 - accuracy: 0.041 - ETA: 29s - loss: 8.3283 - accuracy: 0.038 - ETA: 26s - loss: 8.1695 - accuracy: 0.039 - ETA: 23s - loss: 7.9848 - accuracy: 0.041 - ETA: 20s - loss: 7.7731 - accuracy: 0.043 - ETA: 18s - loss: 7.6586 - accuracy: 0.044 - ETA: 15s - loss: 7.4882 - accuracy: 0.044 - ETA: 13s - loss: 7.3952 - accuracy: 0.043 - ETA: 12s - loss: 7.3122 - accuracy: 0.044 - ETA: 10s - loss: 7.2354 - accuracy: 0.043 - ETA: 8s - loss: 7.1128 - accuracy: 0.044 - ETA: 7s - loss: 7.0200 - accuracy: 0.04 - ETA: 5s - loss: 6.9291 - accuracy: 0.04 - ETA: 4s - loss: 6.8648 - accuracy: 0.04 - ETA: 3s - loss: 6.7685 - accuracy: 0.04 - ETA: 1s - loss: 6.7146 - accuracy: 0.04 - ETA: 0s - loss: 6.6342 - accuracy: 0.04 - 47s 45ms/sample - loss: 6.5964 - accuracy: 0.0488 - val_loss: 3.2967 - val_accuracy: 0.0388\n",
      "Epoch 2/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 5.0763 - accuracy: 0.03 - ETA: 6s - loss: 5.0021 - accuracy: 0.01 - ETA: 6s - loss: 4.5902 - accuracy: 0.03 - ETA: 6s - loss: 4.6344 - accuracy: 0.05 - ETA: 5s - loss: 4.6090 - accuracy: 0.06 - ETA: 5s - loss: 4.5010 - accuracy: 0.05 - ETA: 5s - loss: 4.3905 - accuracy: 0.06 - ETA: 5s - loss: 4.7286 - accuracy: 0.06 - ETA: 5s - loss: 4.6178 - accuracy: 0.06 - ETA: 4s - loss: 4.5385 - accuracy: 0.07 - ETA: 4s - loss: 4.4940 - accuracy: 0.08 - ETA: 4s - loss: 4.4298 - accuracy: 0.08 - ETA: 4s - loss: 4.4345 - accuracy: 0.08 - ETA: 4s - loss: 4.3830 - accuracy: 0.08 - ETA: 3s - loss: 4.3957 - accuracy: 0.08 - ETA: 3s - loss: 4.3278 - accuracy: 0.08 - ETA: 3s - loss: 4.4021 - accuracy: 0.08 - ETA: 3s - loss: 4.3582 - accuracy: 0.07 - ETA: 2s - loss: 4.3693 - accuracy: 0.08 - ETA: 2s - loss: 4.3260 - accuracy: 0.08 - ETA: 2s - loss: 4.3122 - accuracy: 0.08 - ETA: 2s - loss: 4.3295 - accuracy: 0.07 - ETA: 2s - loss: 4.3209 - accuracy: 0.08 - ETA: 1s - loss: 4.2972 - accuracy: 0.08 - ETA: 1s - loss: 4.2928 - accuracy: 0.08 - ETA: 1s - loss: 4.2878 - accuracy: 0.08 - ETA: 1s - loss: 4.2994 - accuracy: 0.08 - ETA: 1s - loss: 4.2980 - accuracy: 0.08 - ETA: 0s - loss: 4.2693 - accuracy: 0.07 - ETA: 0s - loss: 4.2952 - accuracy: 0.08 - ETA: 0s - loss: 4.2735 - accuracy: 0.08 - ETA: 0s - loss: 4.2610 - accuracy: 0.08 - 8s 8ms/sample - loss: 4.2433 - accuracy: 0.0813 - val_loss: 3.3338 - val_accuracy: 0.0291\n",
      "Epoch 3/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.8178 - accuracy: 0.06 - ETA: 6s - loss: 4.1520 - accuracy: 0.07 - ETA: 6s - loss: 3.7554 - accuracy: 0.10 - ETA: 6s - loss: 3.8191 - accuracy: 0.10 - ETA: 6s - loss: 3.8147 - accuracy: 0.10 - ETA: 5s - loss: 3.7362 - accuracy: 0.10 - ETA: 5s - loss: 3.7732 - accuracy: 0.11 - ETA: 5s - loss: 3.9519 - accuracy: 0.11 - ETA: 5s - loss: 4.1851 - accuracy: 0.10 - ETA: 4s - loss: 4.2144 - accuracy: 0.10 - ETA: 4s - loss: 4.1478 - accuracy: 0.11 - ETA: 4s - loss: 4.1374 - accuracy: 0.11 - ETA: 4s - loss: 4.1854 - accuracy: 0.11 - ETA: 4s - loss: 4.2776 - accuracy: 0.10 - ETA: 3s - loss: 4.2105 - accuracy: 0.10 - ETA: 3s - loss: 4.1819 - accuracy: 0.10 - ETA: 3s - loss: 4.1639 - accuracy: 0.10 - ETA: 3s - loss: 4.1341 - accuracy: 0.10 - ETA: 2s - loss: 4.1159 - accuracy: 0.10 - ETA: 2s - loss: 4.1178 - accuracy: 0.10 - ETA: 2s - loss: 4.1664 - accuracy: 0.10 - ETA: 2s - loss: 4.1173 - accuracy: 0.10 - ETA: 2s - loss: 4.0828 - accuracy: 0.10 - ETA: 1s - loss: 4.0809 - accuracy: 0.10 - ETA: 1s - loss: 4.0715 - accuracy: 0.10 - ETA: 1s - loss: 4.1244 - accuracy: 0.09 - ETA: 1s - loss: 4.1499 - accuracy: 0.09 - ETA: 1s - loss: 4.1557 - accuracy: 0.09 - ETA: 0s - loss: 4.1459 - accuracy: 0.09 - ETA: 0s - loss: 4.1415 - accuracy: 0.09 - ETA: 0s - loss: 4.1117 - accuracy: 0.10 - ETA: 0s - loss: 4.0935 - accuracy: 0.10 - 8s 8ms/sample - loss: 4.1104 - accuracy: 0.1062 - val_loss: 3.3674 - val_accuracy: 0.0350\n",
      "Epoch 4/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 4.0124 - accuracy: 0.06 - ETA: 6s - loss: 4.2925 - accuracy: 0.06 - ETA: 6s - loss: 4.2172 - accuracy: 0.05 - ETA: 6s - loss: 4.1619 - accuracy: 0.03 - ETA: 6s - loss: 4.4500 - accuracy: 0.04 - ETA: 5s - loss: 4.2452 - accuracy: 0.04 - ETA: 5s - loss: 4.2568 - accuracy: 0.04 - ETA: 5s - loss: 4.1912 - accuracy: 0.05 - ETA: 5s - loss: 4.1582 - accuracy: 0.06 - ETA: 4s - loss: 4.1899 - accuracy: 0.06 - ETA: 4s - loss: 4.1893 - accuracy: 0.06 - ETA: 4s - loss: 4.2060 - accuracy: 0.06 - ETA: 4s - loss: 4.2274 - accuracy: 0.06 - ETA: 4s - loss: 4.2276 - accuracy: 0.06 - ETA: 3s - loss: 4.2433 - accuracy: 0.06 - ETA: 3s - loss: 4.2393 - accuracy: 0.06 - ETA: 3s - loss: 4.1831 - accuracy: 0.06 - ETA: 3s - loss: 4.2274 - accuracy: 0.06 - ETA: 2s - loss: 4.2101 - accuracy: 0.06 - ETA: 2s - loss: 4.1594 - accuracy: 0.06 - ETA: 2s - loss: 4.1308 - accuracy: 0.06 - ETA: 2s - loss: 4.1564 - accuracy: 0.06 - ETA: 2s - loss: 4.1340 - accuracy: 0.06 - ETA: 1s - loss: 4.1662 - accuracy: 0.06 - ETA: 1s - loss: 4.1660 - accuracy: 0.06 - ETA: 1s - loss: 4.1428 - accuracy: 0.06 - ETA: 1s - loss: 4.1643 - accuracy: 0.06 - ETA: 1s - loss: 4.1442 - accuracy: 0.07 - ETA: 0s - loss: 4.1125 - accuracy: 0.07 - ETA: 0s - loss: 4.1124 - accuracy: 0.07 - ETA: 0s - loss: 4.1321 - accuracy: 0.07 - ETA: 0s - loss: 4.1166 - accuracy: 0.07 - 8s 8ms/sample - loss: 4.1238 - accuracy: 0.0727 - val_loss: 3.4392 - val_accuracy: 0.0388\n",
      "Epoch 5/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 4.2464 - accuracy: 0.09 - ETA: 6s - loss: 4.5992 - accuracy: 0.10 - ETA: 6s - loss: 4.8575 - accuracy: 0.09 - ETA: 6s - loss: 5.0571 - accuracy: 0.09 - ETA: 6s - loss: 4.9625 - accuracy: 0.08 - ETA: 5s - loss: 4.7903 - accuracy: 0.07 - ETA: 5s - loss: 4.7395 - accuracy: 0.07 - ETA: 5s - loss: 4.6761 - accuracy: 0.06 - ETA: 5s - loss: 4.5737 - accuracy: 0.07 - ETA: 4s - loss: 4.5021 - accuracy: 0.07 - ETA: 4s - loss: 4.3839 - accuracy: 0.07 - ETA: 4s - loss: 4.3858 - accuracy: 0.07 - ETA: 4s - loss: 4.3567 - accuracy: 0.08 - ETA: 4s - loss: 4.3071 - accuracy: 0.08 - ETA: 3s - loss: 4.2991 - accuracy: 0.08 - ETA: 3s - loss: 4.2985 - accuracy: 0.08 - ETA: 3s - loss: 4.2425 - accuracy: 0.08 - ETA: 3s - loss: 4.2201 - accuracy: 0.08 - ETA: 2s - loss: 4.1929 - accuracy: 0.08 - ETA: 2s - loss: 4.1495 - accuracy: 0.08 - ETA: 2s - loss: 4.1599 - accuracy: 0.08 - ETA: 2s - loss: 4.1369 - accuracy: 0.08 - ETA: 2s - loss: 4.1371 - accuracy: 0.09 - ETA: 1s - loss: 4.1435 - accuracy: 0.09 - ETA: 1s - loss: 4.0970 - accuracy: 0.09 - ETA: 1s - loss: 4.0936 - accuracy: 0.09 - ETA: 1s - loss: 4.0855 - accuracy: 0.09 - ETA: 1s - loss: 4.0594 - accuracy: 0.09 - ETA: 0s - loss: 4.0543 - accuracy: 0.09 - ETA: 0s - loss: 4.0296 - accuracy: 0.09 - ETA: 0s - loss: 4.0382 - accuracy: 0.09 - ETA: 0s - loss: 4.0514 - accuracy: 0.09 - 16s 16ms/sample - loss: 4.0620 - accuracy: 0.0919 - val_loss: 3.3239 - val_accuracy: 0.0447\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 4.5302 - accuracy: 0.18 - ETA: 7s - loss: 4.2490 - accuracy: 0.14 - ETA: 6s - loss: 4.3752 - accuracy: 0.12 - ETA: 6s - loss: 4.2456 - accuracy: 0.10 - ETA: 6s - loss: 4.1526 - accuracy: 0.11 - ETA: 5s - loss: 4.1155 - accuracy: 0.11 - ETA: 5s - loss: 4.1344 - accuracy: 0.11 - ETA: 5s - loss: 4.0414 - accuracy: 0.12 - ETA: 5s - loss: 3.9946 - accuracy: 0.11 - ETA: 4s - loss: 3.8934 - accuracy: 0.10 - ETA: 4s - loss: 3.8993 - accuracy: 0.10 - ETA: 4s - loss: 3.8586 - accuracy: 0.10 - ETA: 4s - loss: 3.8758 - accuracy: 0.10 - ETA: 4s - loss: 3.9641 - accuracy: 0.09 - ETA: 3s - loss: 4.0312 - accuracy: 0.09 - ETA: 3s - loss: 4.0633 - accuracy: 0.09 - ETA: 3s - loss: 4.0609 - accuracy: 0.09 - ETA: 3s - loss: 4.0627 - accuracy: 0.09 - ETA: 3s - loss: 4.0004 - accuracy: 0.09 - ETA: 2s - loss: 3.9686 - accuracy: 0.09 - ETA: 2s - loss: 3.9727 - accuracy: 0.08 - ETA: 2s - loss: 3.9596 - accuracy: 0.08 - ETA: 2s - loss: 3.9546 - accuracy: 0.08 - ETA: 1s - loss: 3.9495 - accuracy: 0.08 - ETA: 1s - loss: 3.9514 - accuracy: 0.08 - ETA: 1s - loss: 3.9915 - accuracy: 0.08 - ETA: 1s - loss: 3.9536 - accuracy: 0.08 - ETA: 1s - loss: 3.9558 - accuracy: 0.08 - ETA: 0s - loss: 3.9553 - accuracy: 0.08 - ETA: 0s - loss: 3.9169 - accuracy: 0.09 - ETA: 0s - loss: 3.8934 - accuracy: 0.09 - ETA: 0s - loss: 3.8830 - accuracy: 0.09 - 8s 8ms/sample - loss: 3.8870 - accuracy: 0.0967 - val_loss: 3.3880 - val_accuracy: 0.0447\n",
      "Epoch 7/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.6225 - accuracy: 0.09 - ETA: 7s - loss: 3.6811 - accuracy: 0.14 - ETA: 6s - loss: 3.6024 - accuracy: 0.14 - ETA: 6s - loss: 3.5953 - accuracy: 0.13 - ETA: 6s - loss: 3.5958 - accuracy: 0.15 - ETA: 5s - loss: 3.5189 - accuracy: 0.14 - ETA: 5s - loss: 3.5482 - accuracy: 0.13 - ETA: 5s - loss: 3.4862 - accuracy: 0.13 - ETA: 5s - loss: 3.4997 - accuracy: 0.13 - ETA: 5s - loss: 3.4795 - accuracy: 0.14 - ETA: 4s - loss: 3.4612 - accuracy: 0.13 - ETA: 4s - loss: 3.4565 - accuracy: 0.14 - ETA: 4s - loss: 3.4046 - accuracy: 0.14 - ETA: 4s - loss: 3.3657 - accuracy: 0.15 - ETA: 3s - loss: 3.3484 - accuracy: 0.14 - ETA: 3s - loss: 3.4127 - accuracy: 0.14 - ETA: 3s - loss: 3.3783 - accuracy: 0.14 - ETA: 3s - loss: 3.3384 - accuracy: 0.14 - ETA: 2s - loss: 3.3298 - accuracy: 0.14 - ETA: 2s - loss: 3.3642 - accuracy: 0.14 - ETA: 2s - loss: 3.3586 - accuracy: 0.15 - ETA: 2s - loss: 3.3834 - accuracy: 0.15 - ETA: 2s - loss: 3.3847 - accuracy: 0.15 - ETA: 1s - loss: 3.3894 - accuracy: 0.16 - ETA: 1s - loss: 3.3968 - accuracy: 0.16 - ETA: 1s - loss: 3.4027 - accuracy: 0.15 - ETA: 1s - loss: 3.3746 - accuracy: 0.16 - ETA: 1s - loss: 3.3730 - accuracy: 0.15 - ETA: 0s - loss: 3.3634 - accuracy: 0.15 - ETA: 0s - loss: 3.3406 - accuracy: 0.15 - ETA: 0s - loss: 3.3365 - accuracy: 0.15 - ETA: 0s - loss: 3.3315 - accuracy: 0.15 - 8s 8ms/sample - loss: 3.3218 - accuracy: 0.1598 - val_loss: 3.4314 - val_accuracy: 0.0447\n",
      "Epoch 8/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.7903 - accuracy: 0.18 - ETA: 6s - loss: 3.0557 - accuracy: 0.28 - ETA: 6s - loss: 3.3159 - accuracy: 0.26 - ETA: 6s - loss: 3.2077 - accuracy: 0.25 - ETA: 6s - loss: 3.2132 - accuracy: 0.25 - ETA: 5s - loss: 3.3818 - accuracy: 0.23 - ETA: 5s - loss: 3.3021 - accuracy: 0.21 - ETA: 5s - loss: 3.2052 - accuracy: 0.21 - ETA: 5s - loss: 3.0787 - accuracy: 0.23 - ETA: 4s - loss: 3.2044 - accuracy: 0.22 - ETA: 4s - loss: 3.1719 - accuracy: 0.22 - ETA: 4s - loss: 3.2140 - accuracy: 0.21 - ETA: 4s - loss: 3.3183 - accuracy: 0.21 - ETA: 4s - loss: 3.3239 - accuracy: 0.20 - ETA: 3s - loss: 3.4023 - accuracy: 0.19 - ETA: 3s - loss: 3.4259 - accuracy: 0.19 - ETA: 3s - loss: 3.4438 - accuracy: 0.18 - ETA: 3s - loss: 3.4529 - accuracy: 0.18 - ETA: 2s - loss: 3.5387 - accuracy: 0.18 - ETA: 2s - loss: 3.5185 - accuracy: 0.17 - ETA: 2s - loss: 3.5116 - accuracy: 0.17 - ETA: 2s - loss: 3.5209 - accuracy: 0.16 - ETA: 2s - loss: 3.5125 - accuracy: 0.17 - ETA: 1s - loss: 3.5067 - accuracy: 0.17 - ETA: 1s - loss: 3.5140 - accuracy: 0.17 - ETA: 1s - loss: 3.5207 - accuracy: 0.17 - ETA: 1s - loss: 3.5129 - accuracy: 0.17 - ETA: 1s - loss: 3.5109 - accuracy: 0.17 - ETA: 0s - loss: 3.5451 - accuracy: 0.17 - ETA: 0s - loss: 3.5568 - accuracy: 0.17 - ETA: 0s - loss: 3.5630 - accuracy: 0.16 - ETA: 0s - loss: 3.5386 - accuracy: 0.16 - 8s 8ms/sample - loss: 3.5350 - accuracy: 0.1617 - val_loss: 3.3301 - val_accuracy: 0.0427\n",
      "Epoch 9/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.4512 - accuracy: 0.21 - ETA: 6s - loss: 3.0927 - accuracy: 0.20 - ETA: 6s - loss: 3.4126 - accuracy: 0.16 - ETA: 6s - loss: 3.4739 - accuracy: 0.14 - ETA: 6s - loss: 3.6032 - accuracy: 0.16 - ETA: 5s - loss: 3.5566 - accuracy: 0.15 - ETA: 5s - loss: 3.4509 - accuracy: 0.15 - ETA: 5s - loss: 3.4759 - accuracy: 0.14 - ETA: 5s - loss: 3.3603 - accuracy: 0.15 - ETA: 4s - loss: 3.3214 - accuracy: 0.16 - ETA: 4s - loss: 3.3202 - accuracy: 0.17 - ETA: 4s - loss: 3.3093 - accuracy: 0.18 - ETA: 4s - loss: 3.2887 - accuracy: 0.17 - ETA: 4s - loss: 3.2689 - accuracy: 0.17 - ETA: 3s - loss: 3.3568 - accuracy: 0.17 - ETA: 3s - loss: 3.3683 - accuracy: 0.17 - ETA: 3s - loss: 3.3281 - accuracy: 0.17 - ETA: 3s - loss: 3.3698 - accuracy: 0.17 - ETA: 2s - loss: 3.3638 - accuracy: 0.16 - ETA: 2s - loss: 3.3923 - accuracy: 0.16 - ETA: 2s - loss: 3.4411 - accuracy: 0.16 - ETA: 2s - loss: 3.4417 - accuracy: 0.15 - ETA: 2s - loss: 3.4658 - accuracy: 0.15 - ETA: 1s - loss: 3.4748 - accuracy: 0.14 - ETA: 1s - loss: 3.4708 - accuracy: 0.15 - ETA: 1s - loss: 3.4960 - accuracy: 0.15 - ETA: 1s - loss: 3.5088 - accuracy: 0.15 - ETA: 1s - loss: 3.5007 - accuracy: 0.15 - ETA: 0s - loss: 3.5142 - accuracy: 0.15 - ETA: 0s - loss: 3.5222 - accuracy: 0.15 - ETA: 0s - loss: 3.5416 - accuracy: 0.15 - ETA: 0s - loss: 3.5625 - accuracy: 0.14 - 8s 8ms/sample - loss: 3.5799 - accuracy: 0.1474 - val_loss: 3.4926 - val_accuracy: 0.0330\n",
      "Epoch 10/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 3.9102 - accuracy: 0.09 - ETA: 6s - loss: 3.4560 - accuracy: 0.10 - ETA: 6s - loss: 3.5567 - accuracy: 0.12 - ETA: 6s - loss: 3.7698 - accuracy: 0.11 - ETA: 6s - loss: 3.6575 - accuracy: 0.10 - ETA: 5s - loss: 3.6121 - accuracy: 0.09 - ETA: 5s - loss: 3.6828 - accuracy: 0.09 - ETA: 5s - loss: 3.6668 - accuracy: 0.10 - ETA: 5s - loss: 3.6763 - accuracy: 0.11 - ETA: 4s - loss: 3.6859 - accuracy: 0.11 - ETA: 4s - loss: 3.6191 - accuracy: 0.11 - ETA: 4s - loss: 3.7397 - accuracy: 0.12 - ETA: 4s - loss: 3.7493 - accuracy: 0.11 - ETA: 4s - loss: 3.7432 - accuracy: 0.11 - ETA: 3s - loss: 3.7367 - accuracy: 0.11 - ETA: 3s - loss: 3.7475 - accuracy: 0.11 - ETA: 3s - loss: 3.7353 - accuracy: 0.11 - ETA: 3s - loss: 3.7468 - accuracy: 0.11 - ETA: 3s - loss: 3.7599 - accuracy: 0.11 - ETA: 2s - loss: 3.7627 - accuracy: 0.11 - ETA: 2s - loss: 3.7645 - accuracy: 0.10 - ETA: 2s - loss: 3.7597 - accuracy: 0.10 - ETA: 2s - loss: 3.7906 - accuracy: 0.10 - ETA: 1s - loss: 3.8630 - accuracy: 0.10 - ETA: 1s - loss: 3.8991 - accuracy: 0.10 - ETA: 1s - loss: 3.8882 - accuracy: 0.10 - ETA: 1s - loss: 3.8905 - accuracy: 0.09 - ETA: 1s - loss: 3.8599 - accuracy: 0.09 - ETA: 0s - loss: 3.8419 - accuracy: 0.09 - ETA: 0s - loss: 3.8425 - accuracy: 0.09 - ETA: 0s - loss: 3.8361 - accuracy: 0.09 - ETA: 0s - loss: 3.8358 - accuracy: 0.09 - 8s 8ms/sample - loss: 3.8226 - accuracy: 0.0986 - val_loss: 3.4376 - val_accuracy: 0.0330\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 3.7899 - accuracy: 0.18 - ETA: 6s - loss: 3.6016 - accuracy: 0.18 - ETA: 6s - loss: 3.5100 - accuracy: 0.15 - ETA: 6s - loss: 3.4768 - accuracy: 0.14 - ETA: 6s - loss: 3.6155 - accuracy: 0.13 - ETA: 5s - loss: 3.6214 - accuracy: 0.13 - ETA: 5s - loss: 3.5543 - accuracy: 0.13 - ETA: 5s - loss: 3.6231 - accuracy: 0.13 - ETA: 5s - loss: 3.5778 - accuracy: 0.14 - ETA: 4s - loss: 3.5793 - accuracy: 0.13 - ETA: 4s - loss: 3.5790 - accuracy: 0.12 - ETA: 4s - loss: 3.5640 - accuracy: 0.11 - ETA: 4s - loss: 3.5952 - accuracy: 0.11 - ETA: 4s - loss: 3.5784 - accuracy: 0.11 - ETA: 3s - loss: 3.5383 - accuracy: 0.11 - ETA: 3s - loss: 3.6116 - accuracy: 0.11 - ETA: 3s - loss: 3.5862 - accuracy: 0.11 - ETA: 3s - loss: 3.5748 - accuracy: 0.11 - ETA: 3s - loss: 3.5721 - accuracy: 0.12 - ETA: 2s - loss: 3.5709 - accuracy: 0.12 - ETA: 2s - loss: 3.5700 - accuracy: 0.12 - ETA: 2s - loss: 3.5701 - accuracy: 0.12 - ETA: 2s - loss: 3.5562 - accuracy: 0.12 - ETA: 1s - loss: 3.5718 - accuracy: 0.12 - ETA: 1s - loss: 3.5442 - accuracy: 0.13 - ETA: 1s - loss: 3.5313 - accuracy: 0.13 - ETA: 1s - loss: 3.5373 - accuracy: 0.13 - ETA: 1s - loss: 3.5263 - accuracy: 0.14 - ETA: 0s - loss: 3.5212 - accuracy: 0.14 - ETA: 0s - loss: 3.5200 - accuracy: 0.14 - ETA: 0s - loss: 3.5391 - accuracy: 0.14 - ETA: 0s - loss: 3.5363 - accuracy: 0.14 - 8s 8ms/sample - loss: 3.5437 - accuracy: 0.1455 - val_loss: 3.4401 - val_accuracy: 0.0388\n",
      "Epoch 12/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 2.8916 - accuracy: 0.03 - ETA: 6s - loss: 3.5929 - accuracy: 0.10 - ETA: 6s - loss: 3.9785 - accuracy: 0.11 - ETA: 6s - loss: 3.7630 - accuracy: 0.10 - ETA: 6s - loss: 3.7365 - accuracy: 0.11 - ETA: 5s - loss: 3.6826 - accuracy: 0.11 - ETA: 5s - loss: 3.6740 - accuracy: 0.12 - ETA: 5s - loss: 3.7148 - accuracy: 0.12 - ETA: 5s - loss: 3.6372 - accuracy: 0.12 - ETA: 5s - loss: 3.6071 - accuracy: 0.12 - ETA: 4s - loss: 3.5951 - accuracy: 0.12 - ETA: 4s - loss: 3.5609 - accuracy: 0.13 - ETA: 4s - loss: 3.5778 - accuracy: 0.12 - ETA: 4s - loss: 3.5224 - accuracy: 0.14 - ETA: 3s - loss: 3.5034 - accuracy: 0.15 - ETA: 3s - loss: 3.4438 - accuracy: 0.16 - ETA: 3s - loss: 3.3934 - accuracy: 0.16 - ETA: 3s - loss: 3.3881 - accuracy: 0.16 - ETA: 3s - loss: 3.3900 - accuracy: 0.16 - ETA: 2s - loss: 3.3971 - accuracy: 0.16 - ETA: 2s - loss: 3.3944 - accuracy: 0.16 - ETA: 2s - loss: 3.3803 - accuracy: 0.16 - ETA: 2s - loss: 3.3643 - accuracy: 0.16 - ETA: 1s - loss: 3.3322 - accuracy: 0.17 - ETA: 1s - loss: 3.2835 - accuracy: 0.18 - ETA: 1s - loss: 3.2859 - accuracy: 0.18 - ETA: 1s - loss: 3.2989 - accuracy: 0.18 - ETA: 1s - loss: 3.3110 - accuracy: 0.18 - ETA: 0s - loss: 3.3115 - accuracy: 0.18 - ETA: 0s - loss: 3.3466 - accuracy: 0.17 - ETA: 0s - loss: 3.3705 - accuracy: 0.17 - ETA: 0s - loss: 3.3767 - accuracy: 0.16 - 8s 8ms/sample - loss: 3.3984 - accuracy: 0.1694 - val_loss: 3.3858 - val_accuracy: 0.0330\n",
      "Epoch 13/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.5592 - accuracy: 0.06 - ETA: 6s - loss: 3.3030 - accuracy: 0.12 - ETA: 6s - loss: 3.3466 - accuracy: 0.17 - ETA: 6s - loss: 3.2095 - accuracy: 0.19 - ETA: 6s - loss: 3.1850 - accuracy: 0.19 - ETA: 5s - loss: 3.2377 - accuracy: 0.20 - ETA: 5s - loss: 3.2822 - accuracy: 0.19 - ETA: 5s - loss: 3.3136 - accuracy: 0.19 - ETA: 5s - loss: 3.2562 - accuracy: 0.19 - ETA: 4s - loss: 3.2503 - accuracy: 0.20 - ETA: 4s - loss: 3.2352 - accuracy: 0.19 - ETA: 4s - loss: 3.2705 - accuracy: 0.19 - ETA: 4s - loss: 3.2909 - accuracy: 0.19 - ETA: 4s - loss: 3.2608 - accuracy: 0.19 - ETA: 3s - loss: 3.1869 - accuracy: 0.20 - ETA: 3s - loss: 3.1737 - accuracy: 0.20 - ETA: 3s - loss: 3.1614 - accuracy: 0.20 - ETA: 3s - loss: 3.1685 - accuracy: 0.20 - ETA: 2s - loss: 3.1513 - accuracy: 0.21 - ETA: 2s - loss: 3.1476 - accuracy: 0.20 - ETA: 2s - loss: 3.1463 - accuracy: 0.20 - ETA: 2s - loss: 3.1490 - accuracy: 0.20 - ETA: 2s - loss: 3.1481 - accuracy: 0.21 - ETA: 1s - loss: 3.1450 - accuracy: 0.21 - ETA: 1s - loss: 3.1306 - accuracy: 0.22 - ETA: 1s - loss: 3.1287 - accuracy: 0.21 - ETA: 1s - loss: 3.1305 - accuracy: 0.21 - ETA: 1s - loss: 3.1162 - accuracy: 0.22 - ETA: 0s - loss: 3.1186 - accuracy: 0.22 - ETA: 0s - loss: 3.1074 - accuracy: 0.22 - ETA: 0s - loss: 3.0863 - accuracy: 0.22 - ETA: 0s - loss: 3.0859 - accuracy: 0.22 - 16s 15ms/sample - loss: 3.0916 - accuracy: 0.2297 - val_loss: 3.2376 - val_accuracy: 0.0641\n",
      "Epoch 14/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 2.9836 - accuracy: 0.34 - ETA: 7s - loss: 2.7065 - accuracy: 0.39 - ETA: 6s - loss: 2.7910 - accuracy: 0.34 - ETA: 6s - loss: 2.7805 - accuracy: 0.32 - ETA: 6s - loss: 2.9032 - accuracy: 0.31 - ETA: 5s - loss: 2.8233 - accuracy: 0.29 - ETA: 5s - loss: 2.8041 - accuracy: 0.30 - ETA: 5s - loss: 2.7701 - accuracy: 0.30 - ETA: 5s - loss: 2.7667 - accuracy: 0.29 - ETA: 4s - loss: 2.7817 - accuracy: 0.30 - ETA: 4s - loss: 2.7991 - accuracy: 0.30 - ETA: 4s - loss: 2.7435 - accuracy: 0.29 - ETA: 4s - loss: 2.7147 - accuracy: 0.30 - ETA: 4s - loss: 2.7747 - accuracy: 0.29 - ETA: 3s - loss: 2.8041 - accuracy: 0.28 - ETA: 3s - loss: 2.8241 - accuracy: 0.27 - ETA: 3s - loss: 2.8564 - accuracy: 0.27 - ETA: 3s - loss: 2.8343 - accuracy: 0.26 - ETA: 2s - loss: 2.8206 - accuracy: 0.27 - ETA: 2s - loss: 2.7973 - accuracy: 0.28 - ETA: 2s - loss: 2.8124 - accuracy: 0.28 - ETA: 2s - loss: 2.8054 - accuracy: 0.27 - ETA: 2s - loss: 2.7947 - accuracy: 0.28 - ETA: 1s - loss: 2.7662 - accuracy: 0.28 - ETA: 1s - loss: 2.7683 - accuracy: 0.28 - ETA: 1s - loss: 2.7652 - accuracy: 0.27 - ETA: 1s - loss: 2.7670 - accuracy: 0.27 - ETA: 1s - loss: 2.7682 - accuracy: 0.27 - ETA: 0s - loss: 2.7427 - accuracy: 0.28 - ETA: 0s - loss: 2.7477 - accuracy: 0.28 - ETA: 0s - loss: 2.7352 - accuracy: 0.29 - ETA: 0s - loss: 2.7334 - accuracy: 0.29 - 8s 8ms/sample - loss: 2.7130 - accuracy: 0.2938 - val_loss: 3.6356 - val_accuracy: 0.0291\n",
      "Epoch 15/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 1.9349 - accuracy: 0.40 - ETA: 6s - loss: 2.1905 - accuracy: 0.35 - ETA: 6s - loss: 2.0464 - accuracy: 0.41 - ETA: 6s - loss: 2.1215 - accuracy: 0.42 - ETA: 6s - loss: 2.0494 - accuracy: 0.42 - ETA: 5s - loss: 2.0285 - accuracy: 0.45 - ETA: 5s - loss: 2.1400 - accuracy: 0.42 - ETA: 5s - loss: 2.1909 - accuracy: 0.42 - ETA: 5s - loss: 2.2047 - accuracy: 0.41 - ETA: 4s - loss: 2.1882 - accuracy: 0.41 - ETA: 4s - loss: 2.2018 - accuracy: 0.40 - ETA: 4s - loss: 2.2777 - accuracy: 0.39 - ETA: 4s - loss: 2.2579 - accuracy: 0.38 - ETA: 4s - loss: 2.3076 - accuracy: 0.38 - ETA: 3s - loss: 2.3189 - accuracy: 0.38 - ETA: 3s - loss: 2.3460 - accuracy: 0.37 - ETA: 3s - loss: 2.3237 - accuracy: 0.37 - ETA: 3s - loss: 2.3222 - accuracy: 0.38 - ETA: 2s - loss: 2.3049 - accuracy: 0.38 - ETA: 2s - loss: 2.2861 - accuracy: 0.39 - ETA: 2s - loss: 2.2458 - accuracy: 0.40 - ETA: 2s - loss: 2.2400 - accuracy: 0.40 - ETA: 2s - loss: 2.2642 - accuracy: 0.39 - ETA: 1s - loss: 2.2727 - accuracy: 0.39 - ETA: 1s - loss: 2.2617 - accuracy: 0.39 - ETA: 1s - loss: 2.2560 - accuracy: 0.39 - ETA: 1s - loss: 2.2291 - accuracy: 0.39 - ETA: 1s - loss: 2.2249 - accuracy: 0.39 - ETA: 0s - loss: 2.2342 - accuracy: 0.38 - ETA: 0s - loss: 2.2387 - accuracy: 0.38 - ETA: 0s - loss: 2.2360 - accuracy: 0.39 - ETA: 0s - loss: 2.2601 - accuracy: 0.39 - 17s 16ms/sample - loss: 2.2821 - accuracy: 0.3876 - val_loss: 3.4370 - val_accuracy: 0.0913\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 3.4059 - accuracy: 0.18 - ETA: 6s - loss: 3.4327 - accuracy: 0.21 - ETA: 6s - loss: 3.2661 - accuracy: 0.19 - ETA: 6s - loss: 3.1669 - accuracy: 0.22 - ETA: 6s - loss: 3.1540 - accuracy: 0.26 - ETA: 5s - loss: 3.3380 - accuracy: 0.26 - ETA: 5s - loss: 3.1845 - accuracy: 0.28 - ETA: 5s - loss: 3.0373 - accuracy: 0.30 - ETA: 5s - loss: 2.9750 - accuracy: 0.30 - ETA: 4s - loss: 2.9612 - accuracy: 0.32 - ETA: 4s - loss: 2.9472 - accuracy: 0.32 - ETA: 4s - loss: 2.8526 - accuracy: 0.32 - ETA: 4s - loss: 2.8133 - accuracy: 0.32 - ETA: 4s - loss: 2.8095 - accuracy: 0.32 - ETA: 3s - loss: 2.7409 - accuracy: 0.32 - ETA: 3s - loss: 2.7636 - accuracy: 0.33 - ETA: 3s - loss: 2.7506 - accuracy: 0.34 - ETA: 3s - loss: 2.7327 - accuracy: 0.33 - ETA: 2s - loss: 2.6861 - accuracy: 0.34 - ETA: 2s - loss: 2.6573 - accuracy: 0.35 - ETA: 2s - loss: 2.6377 - accuracy: 0.34 - ETA: 2s - loss: 2.6446 - accuracy: 0.34 - ETA: 2s - loss: 2.6160 - accuracy: 0.35 - ETA: 1s - loss: 2.6495 - accuracy: 0.34 - ETA: 1s - loss: 2.6243 - accuracy: 0.34 - ETA: 1s - loss: 2.6172 - accuracy: 0.35 - ETA: 1s - loss: 2.6352 - accuracy: 0.34 - ETA: 1s - loss: 2.6438 - accuracy: 0.35 - ETA: 0s - loss: 2.6217 - accuracy: 0.34 - ETA: 0s - loss: 2.6510 - accuracy: 0.35 - ETA: 0s - loss: 2.6253 - accuracy: 0.35 - ETA: 0s - loss: 2.6232 - accuracy: 0.36 - 15s 15ms/sample - loss: 2.6362 - accuracy: 0.3579 - val_loss: 3.4422 - val_accuracy: 0.1515\n",
      "Epoch 17/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 3.2013 - accuracy: 0.28 - ETA: 6s - loss: 2.8686 - accuracy: 0.32 - ETA: 6s - loss: 2.6499 - accuracy: 0.35 - ETA: 6s - loss: 2.3203 - accuracy: 0.42 - ETA: 6s - loss: 2.3253 - accuracy: 0.44 - ETA: 5s - loss: 2.3132 - accuracy: 0.42 - ETA: 5s - loss: 2.1714 - accuracy: 0.45 - ETA: 5s - loss: 2.2367 - accuracy: 0.45 - ETA: 5s - loss: 2.2170 - accuracy: 0.45 - ETA: 4s - loss: 2.1568 - accuracy: 0.45 - ETA: 4s - loss: 2.1786 - accuracy: 0.45 - ETA: 4s - loss: 2.1219 - accuracy: 0.44 - ETA: 4s - loss: 2.1261 - accuracy: 0.44 - ETA: 4s - loss: 2.0685 - accuracy: 0.45 - ETA: 3s - loss: 2.0877 - accuracy: 0.45 - ETA: 3s - loss: 2.1198 - accuracy: 0.45 - ETA: 3s - loss: 2.1192 - accuracy: 0.45 - ETA: 3s - loss: 2.1080 - accuracy: 0.46 - ETA: 2s - loss: 2.1035 - accuracy: 0.45 - ETA: 2s - loss: 2.0832 - accuracy: 0.45 - ETA: 2s - loss: 2.0867 - accuracy: 0.46 - ETA: 2s - loss: 2.0935 - accuracy: 0.46 - ETA: 2s - loss: 2.1258 - accuracy: 0.45 - ETA: 1s - loss: 2.1201 - accuracy: 0.46 - ETA: 1s - loss: 2.1188 - accuracy: 0.46 - ETA: 1s - loss: 2.1281 - accuracy: 0.46 - ETA: 1s - loss: 2.1698 - accuracy: 0.45 - ETA: 1s - loss: 2.1837 - accuracy: 0.45 - ETA: 0s - loss: 2.1778 - accuracy: 0.45 - ETA: 0s - loss: 2.1873 - accuracy: 0.44 - ETA: 0s - loss: 2.1758 - accuracy: 0.44 - ETA: 0s - loss: 2.1776 - accuracy: 0.44 - 17s 16ms/sample - loss: 2.1743 - accuracy: 0.4459 - val_loss: 6.4853 - val_accuracy: 0.2485\n",
      "Epoch 18/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 2.0075 - accuracy: 0.37 - ETA: 7s - loss: 2.1188 - accuracy: 0.39 - ETA: 6s - loss: 2.1426 - accuracy: 0.42 - ETA: 6s - loss: 2.1548 - accuracy: 0.42 - ETA: 6s - loss: 1.9579 - accuracy: 0.45 - ETA: 5s - loss: 1.9493 - accuracy: 0.46 - ETA: 5s - loss: 1.9041 - accuracy: 0.46 - ETA: 5s - loss: 1.9123 - accuracy: 0.46 - ETA: 5s - loss: 1.9015 - accuracy: 0.46 - ETA: 5s - loss: 1.8650 - accuracy: 0.46 - ETA: 4s - loss: 1.9429 - accuracy: 0.47 - ETA: 4s - loss: 1.9570 - accuracy: 0.48 - ETA: 4s - loss: 1.9263 - accuracy: 0.49 - ETA: 4s - loss: 1.9031 - accuracy: 0.49 - ETA: 3s - loss: 1.9388 - accuracy: 0.48 - ETA: 3s - loss: 1.8855 - accuracy: 0.50 - ETA: 3s - loss: 1.8471 - accuracy: 0.50 - ETA: 3s - loss: 1.8633 - accuracy: 0.51 - ETA: 2s - loss: 1.8785 - accuracy: 0.50 - ETA: 2s - loss: 1.8898 - accuracy: 0.50 - ETA: 2s - loss: 1.8998 - accuracy: 0.49 - ETA: 2s - loss: 1.9333 - accuracy: 0.49 - ETA: 2s - loss: 1.9407 - accuracy: 0.48 - ETA: 1s - loss: 1.9585 - accuracy: 0.48 - ETA: 1s - loss: 1.9645 - accuracy: 0.48 - ETA: 1s - loss: 1.9616 - accuracy: 0.48 - ETA: 1s - loss: 1.9672 - accuracy: 0.48 - ETA: 1s - loss: 1.9608 - accuracy: 0.49 - ETA: 0s - loss: 1.9408 - accuracy: 0.49 - ETA: 0s - loss: 1.9420 - accuracy: 0.49 - ETA: 0s - loss: 1.9633 - accuracy: 0.49 - ETA: 0s - loss: 1.9544 - accuracy: 0.48 - 8s 8ms/sample - loss: 1.9650 - accuracy: 0.4890 - val_loss: 3.2795 - val_accuracy: 0.2330\n",
      "Epoch 19/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 2.4733 - accuracy: 0.34 - ETA: 6s - loss: 4.5030 - accuracy: 0.40 - ETA: 6s - loss: 3.8077 - accuracy: 0.36 - ETA: 6s - loss: 4.1449 - accuracy: 0.35 - ETA: 6s - loss: 4.3129 - accuracy: 0.35 - ETA: 5s - loss: 3.9007 - accuracy: 0.36 - ETA: 5s - loss: 3.6737 - accuracy: 0.38 - ETA: 5s - loss: 3.4516 - accuracy: 0.40 - ETA: 5s - loss: 3.3091 - accuracy: 0.41 - ETA: 4s - loss: 3.1178 - accuracy: 0.43 - ETA: 4s - loss: 3.0092 - accuracy: 0.44 - ETA: 4s - loss: 3.0817 - accuracy: 0.45 - ETA: 4s - loss: 2.9522 - accuracy: 0.46 - ETA: 4s - loss: 2.8775 - accuracy: 0.47 - ETA: 3s - loss: 2.8988 - accuracy: 0.48 - ETA: 3s - loss: 2.8057 - accuracy: 0.49 - ETA: 3s - loss: 2.7381 - accuracy: 0.49 - ETA: 3s - loss: 2.8086 - accuracy: 0.50 - ETA: 2s - loss: 2.8417 - accuracy: 0.50 - ETA: 2s - loss: 2.7582 - accuracy: 0.50 - ETA: 2s - loss: 2.8530 - accuracy: 0.50 - ETA: 2s - loss: 2.8338 - accuracy: 0.50 - ETA: 2s - loss: 2.7588 - accuracy: 0.51 - ETA: 1s - loss: 2.7157 - accuracy: 0.51 - ETA: 1s - loss: 2.6854 - accuracy: 0.51 - ETA: 1s - loss: 2.6419 - accuracy: 0.52 - ETA: 1s - loss: 2.5873 - accuracy: 0.52 - ETA: 1s - loss: 2.5664 - accuracy: 0.52 - ETA: 0s - loss: 2.5322 - accuracy: 0.52 - ETA: 0s - loss: 2.4931 - accuracy: 0.52 - ETA: 0s - loss: 2.4634 - accuracy: 0.52 - ETA: 0s - loss: 2.4831 - accuracy: 0.52 - 8s 8ms/sample - loss: 2.4721 - accuracy: 0.5282 - val_loss: 4.1655 - val_accuracy: 0.1379\n",
      "Epoch 20/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 2.2893 - accuracy: 0.50 - ETA: 6s - loss: 2.1964 - accuracy: 0.56 - ETA: 6s - loss: 1.9130 - accuracy: 0.55 - ETA: 6s - loss: 2.0057 - accuracy: 0.53 - ETA: 6s - loss: 1.9153 - accuracy: 0.57 - ETA: 5s - loss: 1.8965 - accuracy: 0.58 - ETA: 5s - loss: 1.9169 - accuracy: 0.58 - ETA: 5s - loss: 1.9218 - accuracy: 0.57 - ETA: 5s - loss: 2.1876 - accuracy: 0.55 - ETA: 4s - loss: 2.1886 - accuracy: 0.54 - ETA: 4s - loss: 2.2155 - accuracy: 0.55 - ETA: 4s - loss: 2.2352 - accuracy: 0.54 - ETA: 4s - loss: 2.2345 - accuracy: 0.52 - ETA: 4s - loss: 2.1960 - accuracy: 0.52 - ETA: 3s - loss: 2.1941 - accuracy: 0.53 - ETA: 3s - loss: 2.1983 - accuracy: 0.52 - ETA: 3s - loss: 2.1694 - accuracy: 0.53 - ETA: 3s - loss: 2.1454 - accuracy: 0.52 - ETA: 2s - loss: 2.0981 - accuracy: 0.52 - ETA: 2s - loss: 2.0964 - accuracy: 0.52 - ETA: 2s - loss: 2.0992 - accuracy: 0.52 - ETA: 2s - loss: 2.1028 - accuracy: 0.51 - ETA: 2s - loss: 2.0848 - accuracy: 0.52 - ETA: 1s - loss: 2.1904 - accuracy: 0.52 - ETA: 1s - loss: 2.2272 - accuracy: 0.51 - ETA: 1s - loss: 2.2038 - accuracy: 0.51 - ETA: 1s - loss: 2.1599 - accuracy: 0.52 - ETA: 1s - loss: 2.1236 - accuracy: 0.52 - ETA: 0s - loss: 2.1083 - accuracy: 0.52 - ETA: 0s - loss: 2.0679 - accuracy: 0.52 - ETA: 0s - loss: 2.0634 - accuracy: 0.52 - ETA: 0s - loss: 2.0806 - accuracy: 0.52 - 8s 8ms/sample - loss: 2.0712 - accuracy: 0.5225 - val_loss: 3.2427 - val_accuracy: 0.2330\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 6s - loss: 1.7346 - accuracy: 0.46 - ETA: 6s - loss: 1.8177 - accuracy: 0.53 - ETA: 6s - loss: 1.9161 - accuracy: 0.51 - ETA: 6s - loss: 2.0076 - accuracy: 0.56 - ETA: 6s - loss: 1.8432 - accuracy: 0.56 - ETA: 5s - loss: 1.7999 - accuracy: 0.55 - ETA: 5s - loss: 1.8164 - accuracy: 0.55 - ETA: 5s - loss: 1.8222 - accuracy: 0.53 - ETA: 5s - loss: 1.7793 - accuracy: 0.56 - ETA: 4s - loss: 1.8182 - accuracy: 0.56 - ETA: 4s - loss: 1.8303 - accuracy: 0.57 - ETA: 4s - loss: 1.8584 - accuracy: 0.57 - ETA: 4s - loss: 1.8195 - accuracy: 0.57 - ETA: 4s - loss: 1.8315 - accuracy: 0.56 - ETA: 3s - loss: 1.8669 - accuracy: 0.56 - ETA: 3s - loss: 1.8514 - accuracy: 0.55 - ETA: 3s - loss: 1.8255 - accuracy: 0.56 - ETA: 3s - loss: 1.7975 - accuracy: 0.56 - ETA: 2s - loss: 1.8255 - accuracy: 0.56 - ETA: 2s - loss: 1.8017 - accuracy: 0.56 - ETA: 2s - loss: 1.8048 - accuracy: 0.55 - ETA: 2s - loss: 1.7839 - accuracy: 0.55 - ETA: 2s - loss: 1.7856 - accuracy: 0.55 - ETA: 1s - loss: 1.8230 - accuracy: 0.54 - ETA: 1s - loss: 1.8566 - accuracy: 0.53 - ETA: 1s - loss: 1.8982 - accuracy: 0.53 - ETA: 1s - loss: 1.8825 - accuracy: 0.54 - ETA: 1s - loss: 1.8973 - accuracy: 0.54 - ETA: 0s - loss: 1.8926 - accuracy: 0.54 - ETA: 0s - loss: 1.9056 - accuracy: 0.53 - ETA: 0s - loss: 1.8989 - accuracy: 0.54 - ETA: 0s - loss: 1.8972 - accuracy: 0.54 - 16s 15ms/sample - loss: 1.9239 - accuracy: 0.5388 - val_loss: 4.2242 - val_accuracy: 0.3146\n",
      "Epoch 22/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 2.9414 - accuracy: 0.59 - ETA: 6s - loss: 2.1480 - accuracy: 0.60 - ETA: 6s - loss: 2.0051 - accuracy: 0.56 - ETA: 6s - loss: 1.9565 - accuracy: 0.55 - ETA: 6s - loss: 1.9084 - accuracy: 0.53 - ETA: 5s - loss: 1.7496 - accuracy: 0.57 - ETA: 5s - loss: 1.8078 - accuracy: 0.57 - ETA: 5s - loss: 1.8519 - accuracy: 0.57 - ETA: 5s - loss: 1.8636 - accuracy: 0.57 - ETA: 4s - loss: 1.8067 - accuracy: 0.58 - ETA: 4s - loss: 1.7264 - accuracy: 0.58 - ETA: 4s - loss: 1.7596 - accuracy: 0.58 - ETA: 4s - loss: 1.7765 - accuracy: 0.57 - ETA: 4s - loss: 1.8216 - accuracy: 0.57 - ETA: 3s - loss: 1.8094 - accuracy: 0.56 - ETA: 3s - loss: 1.8433 - accuracy: 0.56 - ETA: 3s - loss: 2.0040 - accuracy: 0.56 - ETA: 3s - loss: 1.9971 - accuracy: 0.56 - ETA: 2s - loss: 2.0137 - accuracy: 0.55 - ETA: 2s - loss: 1.9866 - accuracy: 0.55 - ETA: 2s - loss: 1.9865 - accuracy: 0.55 - ETA: 2s - loss: 1.9791 - accuracy: 0.56 - ETA: 2s - loss: 1.9836 - accuracy: 0.56 - ETA: 1s - loss: 1.9461 - accuracy: 0.56 - ETA: 1s - loss: 1.9360 - accuracy: 0.57 - ETA: 1s - loss: 1.9298 - accuracy: 0.57 - ETA: 1s - loss: 1.8942 - accuracy: 0.57 - ETA: 1s - loss: 1.8770 - accuracy: 0.57 - ETA: 0s - loss: 1.8903 - accuracy: 0.57 - ETA: 0s - loss: 1.8557 - accuracy: 0.58 - ETA: 0s - loss: 1.8436 - accuracy: 0.58 - ETA: 0s - loss: 1.8719 - accuracy: 0.58 - 8s 8ms/sample - loss: 1.8861 - accuracy: 0.5856 - val_loss: 4.7041 - val_accuracy: 0.1340\n",
      "Epoch 23/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 1.8742 - accuracy: 0.46 - ETA: 6s - loss: 1.4860 - accuracy: 0.56 - ETA: 6s - loss: 1.6696 - accuracy: 0.56 - ETA: 6s - loss: 1.6698 - accuracy: 0.57 - ETA: 6s - loss: 1.8262 - accuracy: 0.57 - ETA: 5s - loss: 1.8463 - accuracy: 0.56 - ETA: 5s - loss: 2.0060 - accuracy: 0.57 - ETA: 5s - loss: 2.1715 - accuracy: 0.55 - ETA: 5s - loss: 2.0775 - accuracy: 0.55 - ETA: 4s - loss: 2.0570 - accuracy: 0.55 - ETA: 4s - loss: 2.0233 - accuracy: 0.56 - ETA: 4s - loss: 1.9861 - accuracy: 0.56 - ETA: 4s - loss: 2.0206 - accuracy: 0.56 - ETA: 4s - loss: 1.9533 - accuracy: 0.56 - ETA: 3s - loss: 1.9509 - accuracy: 0.56 - ETA: 3s - loss: 1.9554 - accuracy: 0.57 - ETA: 3s - loss: 1.9086 - accuracy: 0.57 - ETA: 3s - loss: 1.9009 - accuracy: 0.57 - ETA: 3s - loss: 1.9097 - accuracy: 0.57 - ETA: 2s - loss: 2.0482 - accuracy: 0.55 - ETA: 2s - loss: 2.1355 - accuracy: 0.54 - ETA: 2s - loss: 2.1990 - accuracy: 0.53 - ETA: 2s - loss: 2.1891 - accuracy: 0.53 - ETA: 1s - loss: 2.2147 - accuracy: 0.52 - ETA: 1s - loss: 2.2258 - accuracy: 0.52 - ETA: 1s - loss: 2.2267 - accuracy: 0.52 - ETA: 1s - loss: 2.2248 - accuracy: 0.52 - ETA: 1s - loss: 2.2102 - accuracy: 0.52 - ETA: 0s - loss: 2.1932 - accuracy: 0.52 - ETA: 0s - loss: 2.1778 - accuracy: 0.52 - ETA: 0s - loss: 2.1788 - accuracy: 0.52 - ETA: 0s - loss: 2.1746 - accuracy: 0.53 - 8s 8ms/sample - loss: 2.1826 - accuracy: 0.5263 - val_loss: 19.6404 - val_accuracy: 0.0602\n",
      "Epoch 24/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 2.6526 - accuracy: 0.56 - ETA: 6s - loss: 2.3299 - accuracy: 0.50 - ETA: 6s - loss: 2.2914 - accuracy: 0.51 - ETA: 6s - loss: 2.3530 - accuracy: 0.52 - ETA: 6s - loss: 2.1805 - accuracy: 0.53 - ETA: 5s - loss: 2.1887 - accuracy: 0.53 - ETA: 5s - loss: 2.1819 - accuracy: 0.51 - ETA: 5s - loss: 2.0357 - accuracy: 0.53 - ETA: 5s - loss: 2.1074 - accuracy: 0.53 - ETA: 4s - loss: 2.0931 - accuracy: 0.52 - ETA: 4s - loss: 2.0496 - accuracy: 0.51 - ETA: 4s - loss: 1.9592 - accuracy: 0.53 - ETA: 4s - loss: 1.9420 - accuracy: 0.54 - ETA: 4s - loss: 1.9278 - accuracy: 0.54 - ETA: 3s - loss: 1.8654 - accuracy: 0.55 - ETA: 3s - loss: 1.8671 - accuracy: 0.55 - ETA: 3s - loss: 1.8380 - accuracy: 0.55 - ETA: 3s - loss: 1.8383 - accuracy: 0.56 - ETA: 3s - loss: 1.8586 - accuracy: 0.56 - ETA: 2s - loss: 1.8779 - accuracy: 0.57 - ETA: 2s - loss: 1.8643 - accuracy: 0.57 - ETA: 2s - loss: 1.8691 - accuracy: 0.57 - ETA: 2s - loss: 1.9107 - accuracy: 0.56 - ETA: 1s - loss: 1.9278 - accuracy: 0.56 - ETA: 1s - loss: 1.9331 - accuracy: 0.56 - ETA: 1s - loss: 1.9143 - accuracy: 0.56 - ETA: 1s - loss: 1.9249 - accuracy: 0.56 - ETA: 1s - loss: 1.9046 - accuracy: 0.57 - ETA: 0s - loss: 1.8697 - accuracy: 0.57 - ETA: 0s - loss: 1.8291 - accuracy: 0.58 - ETA: 0s - loss: 1.8188 - accuracy: 0.58 - ETA: 0s - loss: 1.8080 - accuracy: 0.59 - 8s 8ms/sample - loss: 1.8311 - accuracy: 0.5895 - val_loss: 3.7753 - val_accuracy: 0.2117\n",
      "Epoch 25/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 1.3422 - accuracy: 0.62 - ETA: 6s - loss: 1.4878 - accuracy: 0.53 - ETA: 6s - loss: 1.7648 - accuracy: 0.54 - ETA: 6s - loss: 1.7108 - accuracy: 0.58 - ETA: 6s - loss: 1.6235 - accuracy: 0.57 - ETA: 5s - loss: 1.5560 - accuracy: 0.59 - ETA: 5s - loss: 1.4981 - accuracy: 0.60 - ETA: 5s - loss: 1.4933 - accuracy: 0.60 - ETA: 5s - loss: 1.4782 - accuracy: 0.61 - ETA: 4s - loss: 1.4582 - accuracy: 0.60 - ETA: 4s - loss: 1.4535 - accuracy: 0.61 - ETA: 4s - loss: 1.4576 - accuracy: 0.61 - ETA: 4s - loss: 1.4203 - accuracy: 0.63 - ETA: 4s - loss: 1.4162 - accuracy: 0.63 - ETA: 3s - loss: 1.4398 - accuracy: 0.62 - ETA: 3s - loss: 1.4389 - accuracy: 0.63 - ETA: 3s - loss: 1.4134 - accuracy: 0.62 - ETA: 3s - loss: 1.4467 - accuracy: 0.62 - ETA: 3s - loss: 1.4435 - accuracy: 0.62 - ETA: 2s - loss: 1.4390 - accuracy: 0.63 - ETA: 2s - loss: 1.4705 - accuracy: 0.62 - ETA: 2s - loss: 1.4576 - accuracy: 0.63 - ETA: 2s - loss: 1.4878 - accuracy: 0.63 - ETA: 1s - loss: 1.5066 - accuracy: 0.63 - ETA: 1s - loss: 1.4980 - accuracy: 0.63 - ETA: 1s - loss: 1.4941 - accuracy: 0.63 - ETA: 1s - loss: 1.5285 - accuracy: 0.63 - ETA: 1s - loss: 1.5312 - accuracy: 0.62 - ETA: 0s - loss: 1.5363 - accuracy: 0.62 - ETA: 0s - loss: 1.5469 - accuracy: 0.62 - ETA: 0s - loss: 1.5925 - accuracy: 0.62 - ETA: 0s - loss: 1.6166 - accuracy: 0.62 - 8s 8ms/sample - loss: 1.6121 - accuracy: 0.6258 - val_loss: 9.5337 - val_accuracy: 0.3107\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 1.6559 - accuracy: 0.56 - ETA: 6s - loss: 1.6328 - accuracy: 0.57 - ETA: 6s - loss: 1.5433 - accuracy: 0.59 - ETA: 6s - loss: 1.4278 - accuracy: 0.60 - ETA: 6s - loss: 1.4686 - accuracy: 0.61 - ETA: 5s - loss: 1.3818 - accuracy: 0.62 - ETA: 5s - loss: 1.3588 - accuracy: 0.62 - ETA: 5s - loss: 1.3856 - accuracy: 0.63 - ETA: 5s - loss: 1.4485 - accuracy: 0.62 - ETA: 4s - loss: 1.3817 - accuracy: 0.64 - ETA: 4s - loss: 1.4160 - accuracy: 0.65 - ETA: 4s - loss: 1.5232 - accuracy: 0.64 - ETA: 4s - loss: 1.5691 - accuracy: 0.63 - ETA: 4s - loss: 1.5819 - accuracy: 0.62 - ETA: 3s - loss: 1.6105 - accuracy: 0.62 - ETA: 3s - loss: 1.5943 - accuracy: 0.61 - ETA: 3s - loss: 1.5768 - accuracy: 0.62 - ETA: 3s - loss: 1.5735 - accuracy: 0.62 - ETA: 3s - loss: 1.7089 - accuracy: 0.62 - ETA: 2s - loss: 1.7073 - accuracy: 0.62 - ETA: 2s - loss: 1.7232 - accuracy: 0.62 - ETA: 2s - loss: 1.7233 - accuracy: 0.62 - ETA: 2s - loss: 1.6774 - accuracy: 0.63 - ETA: 1s - loss: 1.6728 - accuracy: 0.63 - ETA: 1s - loss: 1.6652 - accuracy: 0.63 - ETA: 1s - loss: 1.6616 - accuracy: 0.63 - ETA: 1s - loss: 1.6468 - accuracy: 0.64 - ETA: 1s - loss: 1.6514 - accuracy: 0.64 - ETA: 0s - loss: 1.6445 - accuracy: 0.64 - ETA: 0s - loss: 1.6294 - accuracy: 0.64 - ETA: 0s - loss: 1.6198 - accuracy: 0.64 - ETA: 0s - loss: 1.6266 - accuracy: 0.64 - 8s 8ms/sample - loss: 1.6334 - accuracy: 0.6450 - val_loss: 9.5703 - val_accuracy: 0.1942\n",
      "Epoch 27/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 2.1820 - accuracy: 0.62 - ETA: 6s - loss: 1.6017 - accuracy: 0.68 - ETA: 6s - loss: 1.4170 - accuracy: 0.68 - ETA: 6s - loss: 1.5371 - accuracy: 0.65 - ETA: 6s - loss: 1.4760 - accuracy: 0.66 - ETA: 5s - loss: 1.5499 - accuracy: 0.66 - ETA: 5s - loss: 2.5962 - accuracy: 0.66 - ETA: 5s - loss: 2.4225 - accuracy: 0.64 - ETA: 5s - loss: 2.3080 - accuracy: 0.64 - ETA: 4s - loss: 2.2038 - accuracy: 0.65 - ETA: 4s - loss: 2.1225 - accuracy: 0.65 - ETA: 4s - loss: 2.1007 - accuracy: 0.66 - ETA: 4s - loss: 2.0245 - accuracy: 0.67 - ETA: 4s - loss: 1.9370 - accuracy: 0.67 - ETA: 3s - loss: 1.8902 - accuracy: 0.68 - ETA: 3s - loss: 1.8205 - accuracy: 0.69 - ETA: 3s - loss: 1.8100 - accuracy: 0.68 - ETA: 3s - loss: 1.7935 - accuracy: 0.68 - ETA: 2s - loss: 1.7541 - accuracy: 0.69 - ETA: 2s - loss: 1.7111 - accuracy: 0.69 - ETA: 2s - loss: 1.7123 - accuracy: 0.69 - ETA: 2s - loss: 1.6776 - accuracy: 0.70 - ETA: 2s - loss: 1.6723 - accuracy: 0.70 - ETA: 1s - loss: 1.6409 - accuracy: 0.70 - ETA: 1s - loss: 1.9600 - accuracy: 0.70 - ETA: 1s - loss: 1.9560 - accuracy: 0.69 - ETA: 1s - loss: 1.9922 - accuracy: 0.69 - ETA: 1s - loss: 1.9915 - accuracy: 0.68 - ETA: 0s - loss: 1.9457 - accuracy: 0.69 - ETA: 0s - loss: 1.9370 - accuracy: 0.69 - ETA: 0s - loss: 1.8961 - accuracy: 0.69 - ETA: 0s - loss: 1.8803 - accuracy: 0.69 - 8s 8ms/sample - loss: 1.8757 - accuracy: 0.6947 - val_loss: 11.0396 - val_accuracy: 0.0524\n",
      "Epoch 28/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 1.2251 - accuracy: 0.71 - ETA: 6s - loss: 1.0014 - accuracy: 0.78 - ETA: 6s - loss: 1.1502 - accuracy: 0.78 - ETA: 6s - loss: 1.0087 - accuracy: 0.78 - ETA: 6s - loss: 0.9439 - accuracy: 0.78 - ETA: 5s - loss: 0.9324 - accuracy: 0.78 - ETA: 5s - loss: 0.9842 - accuracy: 0.79 - ETA: 5s - loss: 1.0256 - accuracy: 0.78 - ETA: 5s - loss: 1.0679 - accuracy: 0.77 - ETA: 4s - loss: 1.1050 - accuracy: 0.75 - ETA: 4s - loss: 1.1254 - accuracy: 0.75 - ETA: 4s - loss: 1.0808 - accuracy: 0.76 - ETA: 4s - loss: 1.0885 - accuracy: 0.75 - ETA: 4s - loss: 1.0340 - accuracy: 0.77 - ETA: 3s - loss: 1.0770 - accuracy: 0.75 - ETA: 3s - loss: 1.0458 - accuracy: 0.75 - ETA: 3s - loss: 1.0252 - accuracy: 0.75 - ETA: 3s - loss: 1.0282 - accuracy: 0.75 - ETA: 3s - loss: 1.0783 - accuracy: 0.74 - ETA: 2s - loss: 1.0974 - accuracy: 0.74 - ETA: 2s - loss: 1.1010 - accuracy: 0.74 - ETA: 2s - loss: 1.1023 - accuracy: 0.74 - ETA: 2s - loss: 1.1190 - accuracy: 0.73 - ETA: 1s - loss: 1.1108 - accuracy: 0.74 - ETA: 1s - loss: 1.1206 - accuracy: 0.74 - ETA: 1s - loss: 1.1001 - accuracy: 0.74 - ETA: 1s - loss: 1.0951 - accuracy: 0.74 - ETA: 1s - loss: 1.0928 - accuracy: 0.74 - ETA: 0s - loss: 1.0809 - accuracy: 0.74 - ETA: 0s - loss: 1.0694 - accuracy: 0.74 - ETA: 0s - loss: 1.0853 - accuracy: 0.74 - ETA: 0s - loss: 1.0683 - accuracy: 0.75 - 8s 8ms/sample - loss: 1.0839 - accuracy: 0.7483 - val_loss: 7.3688 - val_accuracy: 0.1068\n",
      "Epoch 29/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 0.9561 - accuracy: 0.78 - ETA: 6s - loss: 0.8598 - accuracy: 0.79 - ETA: 6s - loss: 0.9022 - accuracy: 0.79 - ETA: 6s - loss: 0.7714 - accuracy: 0.81 - ETA: 6s - loss: 0.7754 - accuracy: 0.79 - ETA: 5s - loss: 0.7124 - accuracy: 0.80 - ETA: 5s - loss: 0.8883 - accuracy: 0.79 - ETA: 5s - loss: 0.9873 - accuracy: 0.76 - ETA: 5s - loss: 1.0080 - accuracy: 0.74 - ETA: 4s - loss: 1.0878 - accuracy: 0.72 - ETA: 4s - loss: 1.1149 - accuracy: 0.72 - ETA: 4s - loss: 1.1171 - accuracy: 0.72 - ETA: 4s - loss: 1.1350 - accuracy: 0.72 - ETA: 4s - loss: 1.1540 - accuracy: 0.72 - ETA: 3s - loss: 1.1569 - accuracy: 0.72 - ETA: 3s - loss: 1.6698 - accuracy: 0.71 - ETA: 3s - loss: 1.6209 - accuracy: 0.71 - ETA: 3s - loss: 1.6007 - accuracy: 0.71 - ETA: 2s - loss: 1.6007 - accuracy: 0.71 - ETA: 2s - loss: 1.5767 - accuracy: 0.71 - ETA: 2s - loss: 1.5692 - accuracy: 0.71 - ETA: 2s - loss: 1.5498 - accuracy: 0.71 - ETA: 2s - loss: 1.5533 - accuracy: 0.71 - ETA: 1s - loss: 1.5227 - accuracy: 0.71 - ETA: 1s - loss: 1.5045 - accuracy: 0.71 - ETA: 1s - loss: 1.4636 - accuracy: 0.72 - ETA: 1s - loss: 1.4454 - accuracy: 0.72 - ETA: 1s - loss: 1.4068 - accuracy: 0.72 - ETA: 0s - loss: 1.4216 - accuracy: 0.72 - ETA: 0s - loss: 1.4229 - accuracy: 0.71 - ETA: 0s - loss: 1.4723 - accuracy: 0.71 - ETA: 0s - loss: 1.4744 - accuracy: 0.71 - 8s 8ms/sample - loss: 1.4784 - accuracy: 0.7148 - val_loss: 9.9615 - val_accuracy: 0.0621\n",
      "Epoch 30/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 1.6919 - accuracy: 0.43 - ETA: 6s - loss: 1.2268 - accuracy: 0.67 - ETA: 6s - loss: 1.2115 - accuracy: 0.68 - ETA: 6s - loss: 1.1443 - accuracy: 0.72 - ETA: 5s - loss: 1.1815 - accuracy: 0.71 - ETA: 5s - loss: 1.1382 - accuracy: 0.70 - ETA: 5s - loss: 1.0695 - accuracy: 0.73 - ETA: 5s - loss: 1.0159 - accuracy: 0.73 - ETA: 5s - loss: 0.9895 - accuracy: 0.73 - ETA: 4s - loss: 0.9594 - accuracy: 0.74 - ETA: 4s - loss: 0.9456 - accuracy: 0.74 - ETA: 4s - loss: 0.9016 - accuracy: 0.75 - ETA: 4s - loss: 0.9227 - accuracy: 0.75 - ETA: 4s - loss: 0.8896 - accuracy: 0.76 - ETA: 3s - loss: 0.9034 - accuracy: 0.75 - ETA: 3s - loss: 0.9227 - accuracy: 0.75 - ETA: 3s - loss: 0.9048 - accuracy: 0.76 - ETA: 3s - loss: 0.9335 - accuracy: 0.76 - ETA: 2s - loss: 0.9509 - accuracy: 0.76 - ETA: 2s - loss: 0.9943 - accuracy: 0.75 - ETA: 2s - loss: 1.0212 - accuracy: 0.75 - ETA: 2s - loss: 1.0470 - accuracy: 0.74 - ETA: 2s - loss: 1.1640 - accuracy: 0.73 - ETA: 1s - loss: 1.1843 - accuracy: 0.73 - ETA: 1s - loss: 1.1739 - accuracy: 0.73 - ETA: 1s - loss: 1.1800 - accuracy: 0.72 - ETA: 1s - loss: 1.1950 - accuracy: 0.72 - ETA: 1s - loss: 1.1778 - accuracy: 0.72 - ETA: 0s - loss: 1.2284 - accuracy: 0.72 - ETA: 0s - loss: 1.2190 - accuracy: 0.72 - ETA: 0s - loss: 1.2066 - accuracy: 0.72 - ETA: 0s - loss: 1.2060 - accuracy: 0.72 - 20s 19ms/sample - loss: 1.3740 - accuracy: 0.7206 - val_loss: 5.1861 - val_accuracy: 0.4699\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 1.0253 - accuracy: 0.71 - ETA: 7s - loss: 0.9263 - accuracy: 0.71 - ETA: 6s - loss: 1.3219 - accuracy: 0.67 - ETA: 6s - loss: 1.5538 - accuracy: 0.66 - ETA: 6s - loss: 1.4145 - accuracy: 0.67 - ETA: 5s - loss: 1.3881 - accuracy: 0.69 - ETA: 5s - loss: 1.3833 - accuracy: 0.68 - ETA: 5s - loss: 2.1379 - accuracy: 0.67 - ETA: 5s - loss: 1.9983 - accuracy: 0.69 - ETA: 4s - loss: 1.9702 - accuracy: 0.70 - ETA: 4s - loss: 1.8694 - accuracy: 0.70 - ETA: 4s - loss: 1.7968 - accuracy: 0.71 - ETA: 4s - loss: 1.7606 - accuracy: 0.71 - ETA: 4s - loss: 1.7295 - accuracy: 0.71 - ETA: 3s - loss: 1.6794 - accuracy: 0.71 - ETA: 3s - loss: 1.9782 - accuracy: 0.70 - ETA: 3s - loss: 1.9073 - accuracy: 0.70 - ETA: 3s - loss: 1.8640 - accuracy: 0.71 - ETA: 2s - loss: 1.8589 - accuracy: 0.72 - ETA: 2s - loss: 2.0627 - accuracy: 0.72 - ETA: 2s - loss: 1.9983 - accuracy: 0.72 - ETA: 2s - loss: 1.9819 - accuracy: 0.72 - ETA: 2s - loss: 1.9527 - accuracy: 0.72 - ETA: 1s - loss: 1.9167 - accuracy: 0.72 - ETA: 1s - loss: 1.8778 - accuracy: 0.73 - ETA: 1s - loss: 1.8610 - accuracy: 0.73 - ETA: 1s - loss: 1.8328 - accuracy: 0.73 - ETA: 1s - loss: 1.7994 - accuracy: 0.73 - ETA: 0s - loss: 1.7739 - accuracy: 0.74 - ETA: 0s - loss: 1.7332 - accuracy: 0.74 - ETA: 0s - loss: 1.7249 - accuracy: 0.73 - ETA: 0s - loss: 1.6918 - accuracy: 0.74 - 8s 8ms/sample - loss: 1.6807 - accuracy: 0.7416 - val_loss: 3.5231 - val_accuracy: 0.3786\n",
      "Epoch 32/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 1.3000 - accuracy: 0.65 - ETA: 6s - loss: 1.0479 - accuracy: 0.76 - ETA: 6s - loss: 1.0561 - accuracy: 0.79 - ETA: 6s - loss: 1.0241 - accuracy: 0.77 - ETA: 6s - loss: 0.9154 - accuracy: 0.80 - ETA: 5s - loss: 0.8667 - accuracy: 0.79 - ETA: 5s - loss: 1.0110 - accuracy: 0.76 - ETA: 5s - loss: 1.0480 - accuracy: 0.76 - ETA: 5s - loss: 1.0784 - accuracy: 0.76 - ETA: 4s - loss: 1.0792 - accuracy: 0.75 - ETA: 4s - loss: 1.0938 - accuracy: 0.75 - ETA: 4s - loss: 1.0769 - accuracy: 0.75 - ETA: 4s - loss: 1.1081 - accuracy: 0.75 - ETA: 4s - loss: 1.1004 - accuracy: 0.75 - ETA: 3s - loss: 1.1083 - accuracy: 0.75 - ETA: 3s - loss: 1.1002 - accuracy: 0.75 - ETA: 3s - loss: 1.0943 - accuracy: 0.75 - ETA: 3s - loss: 1.0672 - accuracy: 0.75 - ETA: 2s - loss: 1.0607 - accuracy: 0.75 - ETA: 2s - loss: 1.0493 - accuracy: 0.75 - ETA: 2s - loss: 1.0577 - accuracy: 0.75 - ETA: 2s - loss: 1.0622 - accuracy: 0.75 - ETA: 2s - loss: 1.0567 - accuracy: 0.75 - ETA: 1s - loss: 1.0393 - accuracy: 0.76 - ETA: 1s - loss: 1.0225 - accuracy: 0.76 - ETA: 1s - loss: 1.0187 - accuracy: 0.76 - ETA: 1s - loss: 1.0154 - accuracy: 0.77 - ETA: 1s - loss: 1.0343 - accuracy: 0.77 - ETA: 0s - loss: 1.0257 - accuracy: 0.77 - ETA: 0s - loss: 1.0542 - accuracy: 0.77 - ETA: 0s - loss: 1.0458 - accuracy: 0.76 - ETA: 0s - loss: 1.0619 - accuracy: 0.76 - 14s 13ms/sample - loss: 1.0854 - accuracy: 0.7598 - val_loss: 2.5713 - val_accuracy: 0.5320\n",
      "Epoch 33/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 1.7721 - accuracy: 0.62 - ETA: 6s - loss: 1.4790 - accuracy: 0.64 - ETA: 6s - loss: 1.2584 - accuracy: 0.68 - ETA: 6s - loss: 1.2458 - accuracy: 0.73 - ETA: 6s - loss: 1.1970 - accuracy: 0.74 - ETA: 5s - loss: 1.0901 - accuracy: 0.75 - ETA: 5s - loss: 1.0802 - accuracy: 0.76 - ETA: 5s - loss: 1.1297 - accuracy: 0.75 - ETA: 5s - loss: 1.1578 - accuracy: 0.75 - ETA: 4s - loss: 1.1317 - accuracy: 0.75 - ETA: 4s - loss: 1.0632 - accuracy: 0.76 - ETA: 4s - loss: 1.0253 - accuracy: 0.77 - ETA: 4s - loss: 1.0276 - accuracy: 0.77 - ETA: 4s - loss: 1.0185 - accuracy: 0.77 - ETA: 3s - loss: 1.0293 - accuracy: 0.77 - ETA: 3s - loss: 0.9850 - accuracy: 0.77 - ETA: 3s - loss: 0.9546 - accuracy: 0.78 - ETA: 3s - loss: 0.9678 - accuracy: 0.78 - ETA: 2s - loss: 0.9492 - accuracy: 0.78 - ETA: 2s - loss: 0.9316 - accuracy: 0.79 - ETA: 2s - loss: 0.9027 - accuracy: 0.79 - ETA: 2s - loss: 0.8989 - accuracy: 0.80 - ETA: 2s - loss: 0.9170 - accuracy: 0.79 - ETA: 1s - loss: 0.9334 - accuracy: 0.79 - ETA: 1s - loss: 0.9131 - accuracy: 0.80 - ETA: 1s - loss: 0.9166 - accuracy: 0.79 - ETA: 1s - loss: 0.9285 - accuracy: 0.79 - ETA: 1s - loss: 0.9058 - accuracy: 0.79 - ETA: 0s - loss: 0.8993 - accuracy: 0.79 - ETA: 0s - loss: 0.9103 - accuracy: 0.80 - ETA: 0s - loss: 0.9139 - accuracy: 0.80 - ETA: 0s - loss: 0.9036 - accuracy: 0.80 - 13s 13ms/sample - loss: 0.9065 - accuracy: 0.8029 - val_loss: 1.6747 - val_accuracy: 0.6893\n",
      "Epoch 34/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 0.0753 - accuracy: 1.00 - ETA: 6s - loss: 0.2949 - accuracy: 0.95 - ETA: 6s - loss: 0.3717 - accuracy: 0.91 - ETA: 6s - loss: 0.4466 - accuracy: 0.89 - ETA: 5s - loss: 0.5654 - accuracy: 0.89 - ETA: 5s - loss: 0.5690 - accuracy: 0.89 - ETA: 5s - loss: 0.5349 - accuracy: 0.88 - ETA: 5s - loss: 0.5139 - accuracy: 0.88 - ETA: 5s - loss: 0.5593 - accuracy: 0.88 - ETA: 4s - loss: 0.5605 - accuracy: 0.88 - ETA: 4s - loss: 0.5738 - accuracy: 0.88 - ETA: 4s - loss: 0.6303 - accuracy: 0.87 - ETA: 4s - loss: 0.6644 - accuracy: 0.86 - ETA: 4s - loss: 0.6792 - accuracy: 0.85 - ETA: 3s - loss: 0.6749 - accuracy: 0.86 - ETA: 3s - loss: 0.6528 - accuracy: 0.86 - ETA: 3s - loss: 0.6592 - accuracy: 0.86 - ETA: 3s - loss: 0.6760 - accuracy: 0.86 - ETA: 2s - loss: 0.6980 - accuracy: 0.86 - ETA: 2s - loss: 0.7263 - accuracy: 0.85 - ETA: 2s - loss: 0.7704 - accuracy: 0.84 - ETA: 2s - loss: 0.7931 - accuracy: 0.84 - ETA: 2s - loss: 0.7848 - accuracy: 0.83 - ETA: 1s - loss: 0.7818 - accuracy: 0.83 - ETA: 1s - loss: 0.8238 - accuracy: 0.83 - ETA: 1s - loss: 0.8166 - accuracy: 0.83 - ETA: 1s - loss: 0.8173 - accuracy: 0.83 - ETA: 1s - loss: 0.8109 - accuracy: 0.83 - ETA: 0s - loss: 0.7875 - accuracy: 0.83 - ETA: 0s - loss: 0.7669 - accuracy: 0.84 - ETA: 0s - loss: 0.7603 - accuracy: 0.84 - ETA: 0s - loss: 0.7605 - accuracy: 0.84 - 8s 7ms/sample - loss: 0.7753 - accuracy: 0.8402 - val_loss: 9.2683 - val_accuracy: 0.3087\n",
      "Epoch 35/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 1.4892 - accuracy: 0.56 - ETA: 6s - loss: 1.5012 - accuracy: 0.67 - ETA: 6s - loss: 1.3580 - accuracy: 0.71 - ETA: 6s - loss: 1.1341 - accuracy: 0.76 - ETA: 5s - loss: 1.1401 - accuracy: 0.76 - ETA: 5s - loss: 1.1339 - accuracy: 0.77 - ETA: 5s - loss: 1.0164 - accuracy: 0.79 - ETA: 5s - loss: 1.0072 - accuracy: 0.80 - ETA: 5s - loss: 0.9565 - accuracy: 0.81 - ETA: 4s - loss: 0.8999 - accuracy: 0.81 - ETA: 4s - loss: 0.8915 - accuracy: 0.81 - ETA: 4s - loss: 0.9209 - accuracy: 0.81 - ETA: 4s - loss: 0.9031 - accuracy: 0.81 - ETA: 4s - loss: 0.8812 - accuracy: 0.81 - ETA: 3s - loss: 0.8801 - accuracy: 0.81 - ETA: 3s - loss: 0.8701 - accuracy: 0.81 - ETA: 3s - loss: 0.8309 - accuracy: 0.82 - ETA: 3s - loss: 0.8352 - accuracy: 0.81 - ETA: 2s - loss: 0.8240 - accuracy: 0.82 - ETA: 2s - loss: 0.8276 - accuracy: 0.82 - ETA: 2s - loss: 0.8144 - accuracy: 0.82 - ETA: 2s - loss: 0.8159 - accuracy: 0.83 - ETA: 2s - loss: 0.8387 - accuracy: 0.83 - ETA: 1s - loss: 0.8367 - accuracy: 0.82 - ETA: 1s - loss: 0.8267 - accuracy: 0.83 - ETA: 1s - loss: 0.8184 - accuracy: 0.83 - ETA: 1s - loss: 0.8185 - accuracy: 0.84 - ETA: 1s - loss: 0.8212 - accuracy: 0.84 - ETA: 0s - loss: 0.8220 - accuracy: 0.84 - ETA: 0s - loss: 0.8559 - accuracy: 0.84 - ETA: 0s - loss: 0.8427 - accuracy: 0.84 - ETA: 0s - loss: 0.8424 - accuracy: 0.84 - 8s 8ms/sample - loss: 0.8419 - accuracy: 0.8411 - val_loss: 3.9006 - val_accuracy: 0.3592\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 6s - loss: 0.7679 - accuracy: 0.90 - ETA: 6s - loss: 0.4809 - accuracy: 0.92 - ETA: 6s - loss: 0.4862 - accuracy: 0.91 - ETA: 6s - loss: 0.3888 - accuracy: 0.93 - ETA: 6s - loss: 0.3576 - accuracy: 0.93 - ETA: 5s - loss: 0.3161 - accuracy: 0.93 - ETA: 5s - loss: 0.3574 - accuracy: 0.91 - ETA: 5s - loss: 0.4008 - accuracy: 0.92 - ETA: 5s - loss: 0.3949 - accuracy: 0.91 - ETA: 4s - loss: 0.4499 - accuracy: 0.91 - ETA: 4s - loss: 0.4834 - accuracy: 0.90 - ETA: 4s - loss: 0.5086 - accuracy: 0.90 - ETA: 4s - loss: 0.5592 - accuracy: 0.90 - ETA: 4s - loss: 0.5351 - accuracy: 0.90 - ETA: 3s - loss: 0.5069 - accuracy: 0.91 - ETA: 3s - loss: 0.4885 - accuracy: 0.90 - ETA: 3s - loss: 0.5033 - accuracy: 0.90 - ETA: 3s - loss: 0.4987 - accuracy: 0.90 - ETA: 2s - loss: 0.4855 - accuracy: 0.90 - ETA: 2s - loss: 0.5214 - accuracy: 0.90 - ETA: 2s - loss: 0.5594 - accuracy: 0.89 - ETA: 2s - loss: 0.5673 - accuracy: 0.89 - ETA: 2s - loss: 0.6110 - accuracy: 0.88 - ETA: 1s - loss: 0.5961 - accuracy: 0.88 - ETA: 1s - loss: 0.6036 - accuracy: 0.88 - ETA: 1s - loss: 0.5865 - accuracy: 0.88 - ETA: 1s - loss: 0.5735 - accuracy: 0.89 - ETA: 1s - loss: 0.5718 - accuracy: 0.88 - ETA: 0s - loss: 0.5870 - accuracy: 0.88 - ETA: 0s - loss: 0.5886 - accuracy: 0.88 - ETA: 0s - loss: 0.5943 - accuracy: 0.88 - ETA: 0s - loss: 0.5806 - accuracy: 0.88 - 8s 8ms/sample - loss: 0.5842 - accuracy: 0.8861 - val_loss: 6.3465 - val_accuracy: 0.6796\n",
      "Epoch 37/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 2.0067 - accuracy: 0.65 - ETA: 6s - loss: 1.3426 - accuracy: 0.75 - ETA: 6s - loss: 1.2020 - accuracy: 0.79 - ETA: 6s - loss: 1.0226 - accuracy: 0.81 - ETA: 6s - loss: 1.0982 - accuracy: 0.80 - ETA: 5s - loss: 0.9760 - accuracy: 0.82 - ETA: 5s - loss: 0.9107 - accuracy: 0.84 - ETA: 5s - loss: 0.9444 - accuracy: 0.83 - ETA: 5s - loss: 0.8976 - accuracy: 0.84 - ETA: 4s - loss: 0.8252 - accuracy: 0.85 - ETA: 4s - loss: 0.8728 - accuracy: 0.84 - ETA: 4s - loss: 0.8754 - accuracy: 0.83 - ETA: 4s - loss: 0.8535 - accuracy: 0.84 - ETA: 4s - loss: 0.8710 - accuracy: 0.84 - ETA: 3s - loss: 0.8240 - accuracy: 0.85 - ETA: 3s - loss: 0.8250 - accuracy: 0.85 - ETA: 3s - loss: 0.8229 - accuracy: 0.85 - ETA: 3s - loss: 0.8182 - accuracy: 0.85 - ETA: 2s - loss: 0.8125 - accuracy: 0.85 - ETA: 2s - loss: 0.7967 - accuracy: 0.86 - ETA: 2s - loss: 0.8093 - accuracy: 0.86 - ETA: 2s - loss: 0.8103 - accuracy: 0.86 - ETA: 2s - loss: 0.8278 - accuracy: 0.85 - ETA: 1s - loss: 0.8196 - accuracy: 0.85 - ETA: 1s - loss: 0.7945 - accuracy: 0.85 - ETA: 1s - loss: 0.7979 - accuracy: 0.86 - ETA: 1s - loss: 0.8090 - accuracy: 0.85 - ETA: 1s - loss: 0.7870 - accuracy: 0.86 - ETA: 0s - loss: 0.7777 - accuracy: 0.86 - ETA: 0s - loss: 0.7674 - accuracy: 0.86 - ETA: 0s - loss: 0.7489 - accuracy: 0.86 - ETA: 0s - loss: 0.7531 - accuracy: 0.86 - 12s 12ms/sample - loss: 0.7852 - accuracy: 0.8651 - val_loss: 20.5303 - val_accuracy: 0.6913\n",
      "Epoch 38/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 0.7112 - accuracy: 0.81 - ETA: 7s - loss: 0.6070 - accuracy: 0.87 - ETA: 6s - loss: 0.6571 - accuracy: 0.88 - ETA: 6s - loss: 0.5677 - accuracy: 0.89 - ETA: 6s - loss: 0.7613 - accuracy: 0.89 - ETA: 5s - loss: 0.6926 - accuracy: 0.90 - ETA: 5s - loss: 0.6135 - accuracy: 0.91 - ETA: 5s - loss: 0.6236 - accuracy: 0.89 - ETA: 5s - loss: 0.6547 - accuracy: 0.88 - ETA: 4s - loss: 0.6303 - accuracy: 0.88 - ETA: 4s - loss: 0.6379 - accuracy: 0.87 - ETA: 4s - loss: 0.6328 - accuracy: 0.87 - ETA: 4s - loss: 0.6040 - accuracy: 0.88 - ETA: 4s - loss: 0.5722 - accuracy: 0.88 - ETA: 3s - loss: 0.5747 - accuracy: 0.88 - ETA: 3s - loss: 0.6018 - accuracy: 0.87 - ETA: 3s - loss: 0.6241 - accuracy: 0.87 - ETA: 3s - loss: 0.6072 - accuracy: 0.87 - ETA: 2s - loss: 0.5987 - accuracy: 0.87 - ETA: 2s - loss: 0.6186 - accuracy: 0.87 - ETA: 2s - loss: 0.6457 - accuracy: 0.87 - ETA: 2s - loss: 0.6343 - accuracy: 0.87 - ETA: 2s - loss: 0.6273 - accuracy: 0.87 - ETA: 1s - loss: 0.6446 - accuracy: 0.87 - ETA: 1s - loss: 0.6383 - accuracy: 0.87 - ETA: 1s - loss: 0.6342 - accuracy: 0.87 - ETA: 1s - loss: 0.6167 - accuracy: 0.87 - ETA: 1s - loss: 0.6602 - accuracy: 0.87 - ETA: 0s - loss: 0.6497 - accuracy: 0.87 - ETA: 0s - loss: 0.6394 - accuracy: 0.87 - ETA: 0s - loss: 0.6378 - accuracy: 0.87 - ETA: 0s - loss: 0.6463 - accuracy: 0.87 - 8s 8ms/sample - loss: 0.6516 - accuracy: 0.8775 - val_loss: 61.9241 - val_accuracy: 0.6078\n",
      "Epoch 39/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 0.5382 - accuracy: 0.84 - ETA: 6s - loss: 0.7586 - accuracy: 0.85 - ETA: 6s - loss: 0.8533 - accuracy: 0.82 - ETA: 6s - loss: 0.8413 - accuracy: 0.83 - ETA: 5s - loss: 0.6992 - accuracy: 0.86 - ETA: 5s - loss: 0.6881 - accuracy: 0.85 - ETA: 5s - loss: 0.5951 - accuracy: 0.87 - ETA: 5s - loss: 0.6212 - accuracy: 0.88 - ETA: 5s - loss: 0.6518 - accuracy: 0.88 - ETA: 4s - loss: 0.6641 - accuracy: 0.88 - ETA: 4s - loss: 0.6214 - accuracy: 0.89 - ETA: 4s - loss: 0.6210 - accuracy: 0.89 - ETA: 4s - loss: 0.6139 - accuracy: 0.89 - ETA: 4s - loss: 0.6077 - accuracy: 0.90 - ETA: 3s - loss: 0.6061 - accuracy: 0.90 - ETA: 3s - loss: 0.5971 - accuracy: 0.90 - ETA: 3s - loss: 0.5707 - accuracy: 0.90 - ETA: 3s - loss: 0.5520 - accuracy: 0.90 - ETA: 2s - loss: 0.5554 - accuracy: 0.90 - ETA: 2s - loss: 0.5638 - accuracy: 0.89 - ETA: 2s - loss: 0.6146 - accuracy: 0.88 - ETA: 2s - loss: 0.5973 - accuracy: 0.88 - ETA: 2s - loss: 0.6258 - accuracy: 0.88 - ETA: 1s - loss: 0.6271 - accuracy: 0.88 - ETA: 1s - loss: 0.6141 - accuracy: 0.88 - ETA: 1s - loss: 0.6298 - accuracy: 0.87 - ETA: 1s - loss: 0.6301 - accuracy: 0.87 - ETA: 1s - loss: 0.6192 - accuracy: 0.87 - ETA: 0s - loss: 0.6295 - accuracy: 0.87 - ETA: 0s - loss: 0.6220 - accuracy: 0.87 - ETA: 0s - loss: 0.6172 - accuracy: 0.88 - ETA: 0s - loss: 0.6035 - accuracy: 0.88 - 8s 8ms/sample - loss: 0.6035 - accuracy: 0.8852 - val_loss: 2.0867 - val_accuracy: 0.5553\n",
      "Epoch 40/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 0.6439 - accuracy: 0.81 - ETA: 6s - loss: 0.5892 - accuracy: 0.89 - ETA: 6s - loss: 0.5916 - accuracy: 0.89 - ETA: 6s - loss: 0.6364 - accuracy: 0.90 - ETA: 5s - loss: 0.5725 - accuracy: 0.91 - ETA: 5s - loss: 0.6373 - accuracy: 0.89 - ETA: 5s - loss: 0.6635 - accuracy: 0.89 - ETA: 5s - loss: 0.6353 - accuracy: 0.89 - ETA: 5s - loss: 0.6120 - accuracy: 0.89 - ETA: 4s - loss: 0.6303 - accuracy: 0.89 - ETA: 4s - loss: 0.6844 - accuracy: 0.89 - ETA: 4s - loss: 1.3011 - accuracy: 0.88 - ETA: 4s - loss: 1.2556 - accuracy: 0.87 - ETA: 4s - loss: 1.2061 - accuracy: 0.87 - ETA: 3s - loss: 1.1731 - accuracy: 0.86 - ETA: 3s - loss: 1.1328 - accuracy: 0.86 - ETA: 3s - loss: 1.0734 - accuracy: 0.87 - ETA: 3s - loss: 1.0591 - accuracy: 0.87 - ETA: 2s - loss: 1.0469 - accuracy: 0.87 - ETA: 2s - loss: 1.0256 - accuracy: 0.87 - ETA: 2s - loss: 0.9832 - accuracy: 0.87 - ETA: 2s - loss: 0.9539 - accuracy: 0.88 - ETA: 2s - loss: 0.9598 - accuracy: 0.87 - ETA: 1s - loss: 0.9515 - accuracy: 0.87 - ETA: 1s - loss: 0.9370 - accuracy: 0.87 - ETA: 1s - loss: 0.9082 - accuracy: 0.87 - ETA: 1s - loss: 0.8782 - accuracy: 0.88 - ETA: 1s - loss: 0.8503 - accuracy: 0.88 - ETA: 0s - loss: 0.8411 - accuracy: 0.88 - ETA: 0s - loss: 0.8378 - accuracy: 0.88 - ETA: 0s - loss: 0.8126 - accuracy: 0.88 - ETA: 0s - loss: 0.7880 - accuracy: 0.89 - 13s 12ms/sample - loss: 0.7977 - accuracy: 0.8928 - val_loss: 10.7104 - val_accuracy: 0.8214\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 0.4311 - accuracy: 0.96 - ETA: 6s - loss: 0.6343 - accuracy: 0.95 - ETA: 6s - loss: 0.4655 - accuracy: 0.94 - ETA: 6s - loss: 0.4383 - accuracy: 0.92 - ETA: 5s - loss: 0.4129 - accuracy: 0.92 - ETA: 5s - loss: 0.4078 - accuracy: 0.91 - ETA: 5s - loss: 0.5202 - accuracy: 0.91 - ETA: 5s - loss: 0.5926 - accuracy: 0.90 - ETA: 5s - loss: 0.6064 - accuracy: 0.90 - ETA: 4s - loss: 0.6082 - accuracy: 0.90 - ETA: 4s - loss: 0.7372 - accuracy: 0.89 - ETA: 4s - loss: 0.7330 - accuracy: 0.89 - ETA: 4s - loss: 0.7486 - accuracy: 0.88 - ETA: 4s - loss: 0.7083 - accuracy: 0.89 - ETA: 3s - loss: 0.7145 - accuracy: 0.88 - ETA: 3s - loss: 0.7272 - accuracy: 0.89 - ETA: 3s - loss: 0.7006 - accuracy: 0.88 - ETA: 3s - loss: 0.7066 - accuracy: 0.88 - ETA: 2s - loss: 0.7043 - accuracy: 0.88 - ETA: 2s - loss: 0.7173 - accuracy: 0.89 - ETA: 2s - loss: 0.6993 - accuracy: 0.89 - ETA: 2s - loss: 0.7029 - accuracy: 0.89 - ETA: 2s - loss: 0.6936 - accuracy: 0.89 - ETA: 1s - loss: 0.7039 - accuracy: 0.89 - ETA: 1s - loss: 0.6886 - accuracy: 0.89 - ETA: 1s - loss: 0.6739 - accuracy: 0.89 - ETA: 1s - loss: 0.6618 - accuracy: 0.89 - ETA: 1s - loss: 0.6565 - accuracy: 0.89 - ETA: 0s - loss: 0.6853 - accuracy: 0.89 - ETA: 0s - loss: 0.6820 - accuracy: 0.89 - ETA: 0s - loss: 0.6633 - accuracy: 0.90 - ETA: 0s - loss: 0.6525 - accuracy: 0.89 - 8s 8ms/sample - loss: 0.6504 - accuracy: 0.8986 - val_loss: 56.3427 - val_accuracy: 0.6874\n",
      "Epoch 42/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 0.2320 - accuracy: 0.90 - ETA: 6s - loss: 0.2801 - accuracy: 0.92 - ETA: 6s - loss: 0.4991 - accuracy: 0.89 - ETA: 6s - loss: 0.6256 - accuracy: 0.89 - ETA: 5s - loss: 0.5985 - accuracy: 0.90 - ETA: 5s - loss: 0.5989 - accuracy: 0.89 - ETA: 5s - loss: 0.5469 - accuracy: 0.90 - ETA: 5s - loss: 0.5027 - accuracy: 0.90 - ETA: 5s - loss: 0.5361 - accuracy: 0.90 - ETA: 4s - loss: 0.5019 - accuracy: 0.90 - ETA: 4s - loss: 0.5394 - accuracy: 0.90 - ETA: 4s - loss: 0.5174 - accuracy: 0.90 - ETA: 4s - loss: 0.5162 - accuracy: 0.91 - ETA: 4s - loss: 0.4938 - accuracy: 0.91 - ETA: 3s - loss: 0.4667 - accuracy: 0.91 - ETA: 3s - loss: 0.7518 - accuracy: 0.91 - ETA: 3s - loss: 0.7272 - accuracy: 0.90 - ETA: 3s - loss: 0.7372 - accuracy: 0.90 - ETA: 2s - loss: 0.7314 - accuracy: 0.90 - ETA: 2s - loss: 0.6967 - accuracy: 0.91 - ETA: 2s - loss: 0.6921 - accuracy: 0.90 - ETA: 2s - loss: 0.8357 - accuracy: 0.91 - ETA: 2s - loss: 0.8250 - accuracy: 0.91 - ETA: 1s - loss: 0.9283 - accuracy: 0.91 - ETA: 1s - loss: 0.9127 - accuracy: 0.91 - ETA: 1s - loss: 0.9018 - accuracy: 0.90 - ETA: 1s - loss: 0.8740 - accuracy: 0.91 - ETA: 1s - loss: 0.8582 - accuracy: 0.91 - ETA: 0s - loss: 0.8321 - accuracy: 0.91 - ETA: 0s - loss: 0.8283 - accuracy: 0.91 - ETA: 0s - loss: 0.8159 - accuracy: 0.91 - ETA: 0s - loss: 0.8076 - accuracy: 0.91 - 8s 8ms/sample - loss: 0.7931 - accuracy: 0.9215 - val_loss: 1.1201 - val_accuracy: 0.7068\n",
      "Epoch 43/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 0.0643 - accuracy: 0.96 - ETA: 6s - loss: 0.0613 - accuracy: 0.96 - ETA: 6s - loss: 0.1586 - accuracy: 0.96 - ETA: 6s - loss: 0.3309 - accuracy: 0.96 - ETA: 6s - loss: 0.2908 - accuracy: 0.97 - ETA: 5s - loss: 0.3771 - accuracy: 0.92 - ETA: 5s - loss: 0.4374 - accuracy: 0.91 - ETA: 5s - loss: 0.5178 - accuracy: 0.91 - ETA: 5s - loss: 0.4709 - accuracy: 0.91 - ETA: 4s - loss: 0.4700 - accuracy: 0.90 - ETA: 4s - loss: 0.5467 - accuracy: 0.90 - ETA: 4s - loss: 0.5462 - accuracy: 0.90 - ETA: 4s - loss: 0.5730 - accuracy: 0.90 - ETA: 4s - loss: 0.6069 - accuracy: 0.89 - ETA: 3s - loss: 0.6321 - accuracy: 0.89 - ETA: 3s - loss: 0.6127 - accuracy: 0.89 - ETA: 3s - loss: 0.6066 - accuracy: 0.89 - ETA: 3s - loss: 0.6052 - accuracy: 0.90 - ETA: 2s - loss: 0.6153 - accuracy: 0.90 - ETA: 2s - loss: 0.5944 - accuracy: 0.90 - ETA: 2s - loss: 0.5708 - accuracy: 0.90 - ETA: 2s - loss: 0.5728 - accuracy: 0.90 - ETA: 2s - loss: 0.5574 - accuracy: 0.91 - ETA: 1s - loss: 0.5579 - accuracy: 0.91 - ETA: 1s - loss: 0.5583 - accuracy: 0.91 - ETA: 1s - loss: 0.5423 - accuracy: 0.91 - ETA: 1s - loss: 0.5316 - accuracy: 0.91 - ETA: 1s - loss: 0.5384 - accuracy: 0.91 - ETA: 0s - loss: 0.5461 - accuracy: 0.91 - ETA: 0s - loss: 0.5295 - accuracy: 0.92 - ETA: 0s - loss: 0.5138 - accuracy: 0.92 - ETA: 0s - loss: 0.5004 - accuracy: 0.92 - 8s 8ms/sample - loss: 0.4971 - accuracy: 0.9254 - val_loss: 18.2129 - val_accuracy: 0.8175\n",
      "Epoch 44/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 0.2318 - accuracy: 0.96 - ETA: 6s - loss: 0.1504 - accuracy: 0.96 - ETA: 6s - loss: 0.1656 - accuracy: 0.94 - ETA: 6s - loss: 0.1342 - accuracy: 0.96 - ETA: 6s - loss: 0.1837 - accuracy: 0.95 - ETA: 5s - loss: 0.3367 - accuracy: 0.94 - ETA: 5s - loss: 0.3219 - accuracy: 0.94 - ETA: 5s - loss: 0.3115 - accuracy: 0.94 - ETA: 5s - loss: 0.2860 - accuracy: 0.94 - ETA: 4s - loss: 0.3154 - accuracy: 0.94 - ETA: 4s - loss: 0.3612 - accuracy: 0.94 - ETA: 4s - loss: 0.3994 - accuracy: 0.94 - ETA: 4s - loss: 0.3733 - accuracy: 0.94 - ETA: 4s - loss: 0.3735 - accuracy: 0.94 - ETA: 3s - loss: 0.4182 - accuracy: 0.94 - ETA: 3s - loss: 0.4465 - accuracy: 0.94 - ETA: 3s - loss: 0.4335 - accuracy: 0.94 - ETA: 3s - loss: 0.4150 - accuracy: 0.94 - ETA: 2s - loss: 0.4308 - accuracy: 0.94 - ETA: 2s - loss: 0.4323 - accuracy: 0.94 - ETA: 2s - loss: 0.4537 - accuracy: 0.94 - ETA: 2s - loss: 0.4644 - accuracy: 0.94 - ETA: 2s - loss: 0.4715 - accuracy: 0.94 - ETA: 1s - loss: 0.4580 - accuracy: 0.94 - ETA: 1s - loss: 0.4592 - accuracy: 0.94 - ETA: 1s - loss: 0.4499 - accuracy: 0.94 - ETA: 1s - loss: 0.4460 - accuracy: 0.94 - ETA: 1s - loss: 0.4624 - accuracy: 0.94 - ETA: 0s - loss: 0.4576 - accuracy: 0.93 - ETA: 0s - loss: 0.4627 - accuracy: 0.93 - ETA: 0s - loss: 0.4499 - accuracy: 0.94 - ETA: 0s - loss: 0.4530 - accuracy: 0.93 - 8s 8ms/sample - loss: 0.4658 - accuracy: 0.9378 - val_loss: 0.8746 - val_accuracy: 0.7748\n",
      "Epoch 45/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 0.0261 - accuracy: 1.00 - ETA: 6s - loss: 0.0330 - accuracy: 1.00 - ETA: 6s - loss: 0.2106 - accuracy: 0.96 - ETA: 6s - loss: 0.3490 - accuracy: 0.95 - ETA: 6s - loss: 0.3203 - accuracy: 0.95 - ETA: 5s - loss: 0.3220 - accuracy: 0.94 - ETA: 5s - loss: 0.3721 - accuracy: 0.95 - ETA: 5s - loss: 0.4529 - accuracy: 0.94 - ETA: 5s - loss: 0.4813 - accuracy: 0.94 - ETA: 4s - loss: 0.4392 - accuracy: 0.94 - ETA: 4s - loss: 0.4376 - accuracy: 0.94 - ETA: 4s - loss: 0.4277 - accuracy: 0.94 - ETA: 4s - loss: 0.4341 - accuracy: 0.94 - ETA: 4s - loss: 0.4977 - accuracy: 0.93 - ETA: 3s - loss: 0.5216 - accuracy: 0.92 - ETA: 3s - loss: 0.5015 - accuracy: 0.92 - ETA: 3s - loss: 0.5296 - accuracy: 0.92 - ETA: 3s - loss: 0.5145 - accuracy: 0.92 - ETA: 2s - loss: 0.4991 - accuracy: 0.92 - ETA: 2s - loss: 0.4877 - accuracy: 0.92 - ETA: 2s - loss: 0.4955 - accuracy: 0.92 - ETA: 2s - loss: 0.4941 - accuracy: 0.92 - ETA: 2s - loss: 0.5100 - accuracy: 0.92 - ETA: 1s - loss: 0.4974 - accuracy: 0.92 - ETA: 1s - loss: 0.5081 - accuracy: 0.92 - ETA: 1s - loss: 0.4907 - accuracy: 0.92 - ETA: 1s - loss: 0.4814 - accuracy: 0.92 - ETA: 1s - loss: 0.4850 - accuracy: 0.92 - ETA: 0s - loss: 0.4767 - accuracy: 0.93 - ETA: 0s - loss: 0.4812 - accuracy: 0.93 - ETA: 0s - loss: 0.4904 - accuracy: 0.93 - ETA: 0s - loss: 0.4789 - accuracy: 0.93 - 13s 12ms/sample - loss: 0.4704 - accuracy: 0.9340 - val_loss: 1.1402 - val_accuracy: 0.8796\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 7s - loss: 0.0130 - accuracy: 1.00 - ETA: 7s - loss: 0.3501 - accuracy: 0.96 - ETA: 6s - loss: 0.4277 - accuracy: 0.96 - ETA: 6s - loss: 0.5123 - accuracy: 0.95 - ETA: 6s - loss: 0.4278 - accuracy: 0.95 - ETA: 5s - loss: 0.3665 - accuracy: 0.95 - ETA: 5s - loss: 0.3436 - accuracy: 0.95 - ETA: 5s - loss: 0.3879 - accuracy: 0.95 - ETA: 5s - loss: 0.3534 - accuracy: 0.95 - ETA: 5s - loss: 0.3783 - accuracy: 0.95 - ETA: 4s - loss: 0.4124 - accuracy: 0.95 - ETA: 4s - loss: 0.4352 - accuracy: 0.95 - ETA: 4s - loss: 0.4210 - accuracy: 0.95 - ETA: 4s - loss: 0.4506 - accuracy: 0.95 - ETA: 3s - loss: 0.4323 - accuracy: 0.95 - ETA: 3s - loss: 0.4488 - accuracy: 0.95 - ETA: 3s - loss: 0.4644 - accuracy: 0.95 - ETA: 3s - loss: 0.4758 - accuracy: 0.95 - ETA: 2s - loss: 0.4586 - accuracy: 0.95 - ETA: 2s - loss: 0.4889 - accuracy: 0.95 - ETA: 2s - loss: 0.4703 - accuracy: 0.95 - ETA: 2s - loss: 0.4627 - accuracy: 0.95 - ETA: 2s - loss: 0.4742 - accuracy: 0.95 - ETA: 1s - loss: 0.4563 - accuracy: 0.95 - ETA: 1s - loss: 0.4481 - accuracy: 0.95 - ETA: 1s - loss: 0.4601 - accuracy: 0.95 - ETA: 1s - loss: 0.4438 - accuracy: 0.95 - ETA: 1s - loss: 0.4355 - accuracy: 0.95 - ETA: 0s - loss: 0.4402 - accuracy: 0.95 - ETA: 0s - loss: 0.4508 - accuracy: 0.95 - ETA: 0s - loss: 0.4400 - accuracy: 0.95 - ETA: 0s - loss: 0.4269 - accuracy: 0.95 - 12s 12ms/sample - loss: 0.4229 - accuracy: 0.9560 - val_loss: 4.5454 - val_accuracy: 0.8854\n",
      "Epoch 47/50\n",
      "1045/1045 [==============================] - ETA: 7s - loss: 0.8510 - accuracy: 0.96 - ETA: 6s - loss: 0.4812 - accuracy: 0.95 - ETA: 6s - loss: 0.4246 - accuracy: 0.95 - ETA: 6s - loss: 0.3804 - accuracy: 0.94 - ETA: 6s - loss: 0.7234 - accuracy: 0.91 - ETA: 5s - loss: 0.8901 - accuracy: 0.88 - ETA: 5s - loss: 0.9292 - accuracy: 0.87 - ETA: 5s - loss: 0.9465 - accuracy: 0.87 - ETA: 5s - loss: 0.9869 - accuracy: 0.87 - ETA: 4s - loss: 0.9237 - accuracy: 0.88 - ETA: 4s - loss: 0.8434 - accuracy: 0.89 - ETA: 4s - loss: 0.7976 - accuracy: 0.88 - ETA: 4s - loss: 0.7686 - accuracy: 0.88 - ETA: 4s - loss: 0.7535 - accuracy: 0.88 - ETA: 3s - loss: 0.7082 - accuracy: 0.89 - ETA: 3s - loss: 0.7045 - accuracy: 0.89 - ETA: 3s - loss: 0.6816 - accuracy: 0.89 - ETA: 3s - loss: 0.6840 - accuracy: 0.89 - ETA: 2s - loss: 0.6592 - accuracy: 0.88 - ETA: 2s - loss: 0.6585 - accuracy: 0.89 - ETA: 2s - loss: 0.6774 - accuracy: 0.88 - ETA: 2s - loss: 0.6848 - accuracy: 0.88 - ETA: 2s - loss: 0.6635 - accuracy: 0.89 - ETA: 1s - loss: 0.8130 - accuracy: 0.88 - ETA: 1s - loss: 0.7953 - accuracy: 0.88 - ETA: 1s - loss: 0.7686 - accuracy: 0.89 - ETA: 1s - loss: 0.8558 - accuracy: 0.89 - ETA: 1s - loss: 0.8447 - accuracy: 0.88 - ETA: 0s - loss: 0.8377 - accuracy: 0.89 - ETA: 0s - loss: 0.8325 - accuracy: 0.89 - ETA: 0s - loss: 0.8261 - accuracy: 0.89 - ETA: 0s - loss: 0.8063 - accuracy: 0.89 - 8s 8ms/sample - loss: 0.8011 - accuracy: 0.8957 - val_loss: 1.0093 - val_accuracy: 0.8039\n",
      "Epoch 48/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 1.0757 - accuracy: 0.87 - ETA: 6s - loss: 0.8348 - accuracy: 0.89 - ETA: 6s - loss: 0.8700 - accuracy: 0.89 - ETA: 6s - loss: 0.6709 - accuracy: 0.91 - ETA: 5s - loss: 0.5408 - accuracy: 0.93 - ETA: 5s - loss: 0.5310 - accuracy: 0.92 - ETA: 5s - loss: 0.5840 - accuracy: 0.92 - ETA: 5s - loss: 0.5828 - accuracy: 0.92 - ETA: 5s - loss: 0.6259 - accuracy: 0.92 - ETA: 4s - loss: 0.6060 - accuracy: 0.92 - ETA: 4s - loss: 0.5691 - accuracy: 0.92 - ETA: 4s - loss: 0.5578 - accuracy: 0.92 - ETA: 4s - loss: 0.5744 - accuracy: 0.92 - ETA: 4s - loss: 0.5625 - accuracy: 0.92 - ETA: 3s - loss: 0.5299 - accuracy: 0.92 - ETA: 3s - loss: 0.5369 - accuracy: 0.93 - ETA: 3s - loss: 0.5103 - accuracy: 0.93 - ETA: 3s - loss: 0.5464 - accuracy: 0.92 - ETA: 2s - loss: 0.5378 - accuracy: 0.92 - ETA: 2s - loss: 0.5768 - accuracy: 0.92 - ETA: 2s - loss: 0.5929 - accuracy: 0.92 - ETA: 2s - loss: 0.5689 - accuracy: 0.93 - ETA: 2s - loss: 0.5539 - accuracy: 0.93 - ETA: 1s - loss: 0.5639 - accuracy: 0.93 - ETA: 1s - loss: 0.5467 - accuracy: 0.93 - ETA: 1s - loss: 0.5363 - accuracy: 0.92 - ETA: 1s - loss: 0.5494 - accuracy: 0.92 - ETA: 1s - loss: 0.5476 - accuracy: 0.92 - ETA: 0s - loss: 0.5530 - accuracy: 0.92 - ETA: 0s - loss: 0.5705 - accuracy: 0.92 - ETA: 0s - loss: 0.5645 - accuracy: 0.92 - ETA: 0s - loss: 0.5619 - accuracy: 0.92 - 8s 8ms/sample - loss: 0.5664 - accuracy: 0.9254 - val_loss: 1.2534 - val_accuracy: 0.7845\n",
      "Epoch 49/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 0.0241 - accuracy: 1.00 - ETA: 6s - loss: 0.2999 - accuracy: 0.96 - ETA: 6s - loss: 0.4033 - accuracy: 0.94 - ETA: 6s - loss: 0.4185 - accuracy: 0.95 - ETA: 5s - loss: 0.4729 - accuracy: 0.93 - ETA: 5s - loss: 0.4491 - accuracy: 0.93 - ETA: 5s - loss: 0.5006 - accuracy: 0.92 - ETA: 5s - loss: 0.5081 - accuracy: 0.92 - ETA: 5s - loss: 0.5338 - accuracy: 0.92 - ETA: 4s - loss: 0.5466 - accuracy: 0.92 - ETA: 4s - loss: 0.5472 - accuracy: 0.93 - ETA: 4s - loss: 0.5584 - accuracy: 0.93 - ETA: 4s - loss: 0.5830 - accuracy: 0.93 - ETA: 4s - loss: 0.5676 - accuracy: 0.92 - ETA: 3s - loss: 0.5656 - accuracy: 0.92 - ETA: 3s - loss: 0.5534 - accuracy: 0.92 - ETA: 3s - loss: 0.5220 - accuracy: 0.93 - ETA: 3s - loss: 0.5429 - accuracy: 0.92 - ETA: 2s - loss: 0.5421 - accuracy: 0.92 - ETA: 2s - loss: 0.5570 - accuracy: 0.92 - ETA: 2s - loss: 0.5328 - accuracy: 0.93 - ETA: 2s - loss: 0.5188 - accuracy: 0.93 - ETA: 2s - loss: 0.5129 - accuracy: 0.92 - ETA: 1s - loss: 0.5309 - accuracy: 0.92 - ETA: 1s - loss: 0.5385 - accuracy: 0.92 - ETA: 1s - loss: 0.5423 - accuracy: 0.92 - ETA: 1s - loss: 0.5592 - accuracy: 0.92 - ETA: 1s - loss: 0.5554 - accuracy: 0.92 - ETA: 0s - loss: 0.5647 - accuracy: 0.92 - ETA: 0s - loss: 0.6184 - accuracy: 0.92 - ETA: 0s - loss: 0.6042 - accuracy: 0.92 - ETA: 0s - loss: 0.6024 - accuracy: 0.92 - 8s 8ms/sample - loss: 0.6060 - accuracy: 0.9215 - val_loss: 2.6523 - val_accuracy: 0.8641\n",
      "Epoch 50/50\n",
      "1045/1045 [==============================] - ETA: 6s - loss: 0.4496 - accuracy: 0.93 - ETA: 6s - loss: 0.4349 - accuracy: 0.93 - ETA: 6s - loss: 0.4124 - accuracy: 0.94 - ETA: 6s - loss: 0.4598 - accuracy: 0.94 - ETA: 6s - loss: 0.3707 - accuracy: 0.95 - ETA: 5s - loss: 0.3977 - accuracy: 0.94 - ETA: 5s - loss: 0.4265 - accuracy: 0.94 - ETA: 5s - loss: 0.4493 - accuracy: 0.94 - ETA: 5s - loss: 0.4623 - accuracy: 0.94 - ETA: 4s - loss: 0.4909 - accuracy: 0.94 - ETA: 4s - loss: 0.4722 - accuracy: 0.93 - ETA: 4s - loss: 0.4392 - accuracy: 0.93 - ETA: 4s - loss: 0.4321 - accuracy: 0.93 - ETA: 4s - loss: 0.4386 - accuracy: 0.93 - ETA: 3s - loss: 0.4678 - accuracy: 0.93 - ETA: 3s - loss: 0.4601 - accuracy: 0.93 - ETA: 3s - loss: 0.4603 - accuracy: 0.93 - ETA: 3s - loss: 0.4545 - accuracy: 0.94 - ETA: 3s - loss: 0.4664 - accuracy: 0.94 - ETA: 2s - loss: 0.4731 - accuracy: 0.94 - ETA: 2s - loss: 0.4913 - accuracy: 0.93 - ETA: 2s - loss: 0.5077 - accuracy: 0.93 - ETA: 2s - loss: 0.5029 - accuracy: 0.92 - ETA: 1s - loss: 0.5258 - accuracy: 0.92 - ETA: 1s - loss: 0.5286 - accuracy: 0.92 - ETA: 1s - loss: 0.5323 - accuracy: 0.92 - ETA: 1s - loss: 0.5350 - accuracy: 0.92 - ETA: 1s - loss: 0.5290 - accuracy: 0.92 - ETA: 0s - loss: 0.5429 - accuracy: 0.92 - ETA: 0s - loss: 0.5395 - accuracy: 0.92 - ETA: 0s - loss: 0.5391 - accuracy: 0.92 - ETA: 0s - loss: 0.5324 - accuracy: 0.92 - 13s 12ms/sample - loss: 0.5375 - accuracy: 0.9292 - val_loss: 3.1547 - val_accuracy: 0.8874\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 134e5287f4314cd3a241d63ec5298bfd</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8873786330223083</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv3_depth: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv4_depth: 23</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: rmsprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-pooling: avg</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-version: next</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1045 samples, validate on 515 samples\n",
      "Epoch 1/50\n",
      "1045/1045 [==============================] - ETA: 3:28 - loss: 5.5351 - accuracy: 0.09 - ETA: 1:42 - loss: 5.1062 - accuracy: 0.07 - ETA: 1:06 - loss: 5.2682 - accuracy: 0.07 - ETA: 49s - loss: 5.5263 - accuracy: 0.0781 - ETA: 38s - loss: 5.5785 - accuracy: 0.075 - ETA: 31s - loss: 5.5996 - accuracy: 0.078 - ETA: 26s - loss: 5.5283 - accuracy: 0.093 - ETA: 22s - loss: 5.5718 - accuracy: 0.097 - ETA: 19s - loss: 5.5636 - accuracy: 0.100 - ETA: 16s - loss: 5.7183 - accuracy: 0.100 - ETA: 14s - loss: 5.8061 - accuracy: 0.093 - ETA: 13s - loss: 5.7693 - accuracy: 0.099 - ETA: 11s - loss: 5.7479 - accuracy: 0.101 - ETA: 10s - loss: 5.7005 - accuracy: 0.098 - ETA: 9s - loss: 5.7219 - accuracy: 0.095 - ETA: 8s - loss: 5.7774 - accuracy: 0.09 - ETA: 7s - loss: 5.7470 - accuracy: 0.09 - ETA: 6s - loss: 5.7295 - accuracy: 0.10 - ETA: 5s - loss: 5.6721 - accuracy: 0.10 - ETA: 5s - loss: 5.6203 - accuracy: 0.11 - ETA: 4s - loss: 5.5920 - accuracy: 0.11 - ETA: 4s - loss: 5.5551 - accuracy: 0.11 - ETA: 3s - loss: 5.4798 - accuracy: 0.11 - ETA: 3s - loss: 5.4178 - accuracy: 0.12 - ETA: 2s - loss: 5.3635 - accuracy: 0.12 - ETA: 2s - loss: 5.3296 - accuracy: 0.12 - ETA: 1s - loss: 5.2859 - accuracy: 0.12 - ETA: 1s - loss: 5.2565 - accuracy: 0.12 - ETA: 1s - loss: 5.1884 - accuracy: 0.13 - ETA: 0s - loss: 5.1335 - accuracy: 0.13 - ETA: 0s - loss: 5.0993 - accuracy: 0.14 - ETA: 0s - loss: 5.0505 - accuracy: 0.14 - 16s 16ms/sample - loss: 5.0145 - accuracy: 0.1464 - val_loss: 3.3346 - val_accuracy: 0.0350\n",
      "Epoch 2/50\n",
      "1045/1045 [==============================] - ETA: 2s - loss: 2.6435 - accuracy: 0.34 - ETA: 2s - loss: 2.7857 - accuracy: 0.32 - ETA: 2s - loss: 2.9294 - accuracy: 0.33 - ETA: 2s - loss: 3.1352 - accuracy: 0.36 - ETA: 2s - loss: 2.9848 - accuracy: 0.39 - ETA: 2s - loss: 2.8311 - accuracy: 0.40 - ETA: 2s - loss: 2.7198 - accuracy: 0.40 - ETA: 2s - loss: 2.6602 - accuracy: 0.41 - ETA: 2s - loss: 2.6052 - accuracy: 0.39 - ETA: 2s - loss: 2.6322 - accuracy: 0.40 - ETA: 2s - loss: 2.6007 - accuracy: 0.41 - ETA: 1s - loss: 2.6479 - accuracy: 0.41 - ETA: 1s - loss: 2.6333 - accuracy: 0.41 - ETA: 1s - loss: 2.7037 - accuracy: 0.41 - ETA: 1s - loss: 2.6979 - accuracy: 0.41 - ETA: 1s - loss: 2.6680 - accuracy: 0.41 - ETA: 1s - loss: 2.6365 - accuracy: 0.41 - ETA: 1s - loss: 2.5739 - accuracy: 0.42 - ETA: 1s - loss: 2.5380 - accuracy: 0.42 - ETA: 1s - loss: 2.5236 - accuracy: 0.42 - ETA: 1s - loss: 2.5113 - accuracy: 0.43 - ETA: 1s - loss: 2.4977 - accuracy: 0.43 - ETA: 0s - loss: 2.4294 - accuracy: 0.44 - ETA: 0s - loss: 2.4221 - accuracy: 0.44 - ETA: 0s - loss: 2.3751 - accuracy: 0.45 - ETA: 0s - loss: 2.3526 - accuracy: 0.45 - ETA: 0s - loss: 2.3319 - accuracy: 0.45 - ETA: 0s - loss: 2.3128 - accuracy: 0.46 - ETA: 0s - loss: 2.3139 - accuracy: 0.46 - ETA: 0s - loss: 2.2912 - accuracy: 0.46 - ETA: 0s - loss: 2.2743 - accuracy: 0.46 - ETA: 0s - loss: 2.2487 - accuracy: 0.47 - 4s 3ms/sample - loss: 2.2530 - accuracy: 0.4718 - val_loss: 3.5313 - val_accuracy: 0.0311\n",
      "Epoch 3/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.8851 - accuracy: 0.78 - ETA: 3s - loss: 1.0399 - accuracy: 0.70 - ETA: 2s - loss: 1.0760 - accuracy: 0.71 - ETA: 2s - loss: 1.3671 - accuracy: 0.64 - ETA: 2s - loss: 1.4195 - accuracy: 0.66 - ETA: 2s - loss: 1.3508 - accuracy: 0.67 - ETA: 2s - loss: 1.2909 - accuracy: 0.67 - ETA: 2s - loss: 1.2862 - accuracy: 0.66 - ETA: 2s - loss: 1.3059 - accuracy: 0.67 - ETA: 2s - loss: 1.3317 - accuracy: 0.68 - ETA: 2s - loss: 1.3049 - accuracy: 0.68 - ETA: 2s - loss: 1.3192 - accuracy: 0.67 - ETA: 1s - loss: 1.2904 - accuracy: 0.68 - ETA: 1s - loss: 1.3012 - accuracy: 0.67 - ETA: 1s - loss: 1.3259 - accuracy: 0.67 - ETA: 1s - loss: 1.2884 - accuracy: 0.68 - ETA: 1s - loss: 1.3283 - accuracy: 0.67 - ETA: 1s - loss: 1.3404 - accuracy: 0.67 - ETA: 1s - loss: 1.3477 - accuracy: 0.67 - ETA: 1s - loss: 1.3556 - accuracy: 0.67 - ETA: 1s - loss: 1.3622 - accuracy: 0.67 - ETA: 1s - loss: 1.3478 - accuracy: 0.67 - ETA: 0s - loss: 1.3870 - accuracy: 0.67 - ETA: 0s - loss: 1.3966 - accuracy: 0.67 - ETA: 0s - loss: 1.4126 - accuracy: 0.66 - ETA: 0s - loss: 1.4651 - accuracy: 0.66 - ETA: 0s - loss: 1.4626 - accuracy: 0.66 - ETA: 0s - loss: 1.4447 - accuracy: 0.66 - ETA: 0s - loss: 1.4295 - accuracy: 0.66 - ETA: 0s - loss: 1.4243 - accuracy: 0.67 - ETA: 0s - loss: 1.4221 - accuracy: 0.66 - ETA: 0s - loss: 1.4442 - accuracy: 0.66 - 7s 7ms/sample - loss: 1.4377 - accuracy: 0.6641 - val_loss: 3.9115 - val_accuracy: 0.0427\n",
      "Epoch 4/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.7074 - accuracy: 0.68 - ETA: 2s - loss: 0.9476 - accuracy: 0.67 - ETA: 2s - loss: 0.9886 - accuracy: 0.67 - ETA: 2s - loss: 0.9976 - accuracy: 0.68 - ETA: 2s - loss: 0.9340 - accuracy: 0.70 - ETA: 2s - loss: 0.9154 - accuracy: 0.71 - ETA: 2s - loss: 1.0265 - accuracy: 0.72 - ETA: 2s - loss: 1.0851 - accuracy: 0.72 - ETA: 2s - loss: 1.0851 - accuracy: 0.72 - ETA: 2s - loss: 1.0724 - accuracy: 0.72 - ETA: 2s - loss: 1.0185 - accuracy: 0.73 - ETA: 1s - loss: 1.0176 - accuracy: 0.73 - ETA: 1s - loss: 0.9970 - accuracy: 0.74 - ETA: 1s - loss: 1.0131 - accuracy: 0.73 - ETA: 1s - loss: 0.9663 - accuracy: 0.74 - ETA: 1s - loss: 0.9449 - accuracy: 0.74 - ETA: 1s - loss: 0.9150 - accuracy: 0.75 - ETA: 1s - loss: 0.9547 - accuracy: 0.75 - ETA: 1s - loss: 0.9815 - accuracy: 0.74 - ETA: 1s - loss: 1.0199 - accuracy: 0.74 - ETA: 1s - loss: 0.9960 - accuracy: 0.74 - ETA: 1s - loss: 0.9788 - accuracy: 0.75 - ETA: 0s - loss: 1.0099 - accuracy: 0.74 - ETA: 0s - loss: 1.0361 - accuracy: 0.73 - ETA: 0s - loss: 1.0204 - accuracy: 0.73 - ETA: 0s - loss: 1.0074 - accuracy: 0.73 - ETA: 0s - loss: 0.9974 - accuracy: 0.73 - ETA: 0s - loss: 0.9887 - accuracy: 0.74 - ETA: 0s - loss: 0.9750 - accuracy: 0.74 - ETA: 0s - loss: 0.9773 - accuracy: 0.74 - ETA: 0s - loss: 0.9698 - accuracy: 0.74 - ETA: 0s - loss: 0.9564 - accuracy: 0.74 - 4s 3ms/sample - loss: 0.9511 - accuracy: 0.7435 - val_loss: 4.7948 - val_accuracy: 0.0311\n",
      "Epoch 5/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.2697 - accuracy: 0.90 - ETA: 2s - loss: 0.6692 - accuracy: 0.90 - ETA: 2s - loss: 0.8378 - accuracy: 0.85 - ETA: 2s - loss: 0.8696 - accuracy: 0.84 - ETA: 2s - loss: 0.7972 - accuracy: 0.85 - ETA: 2s - loss: 0.7580 - accuracy: 0.85 - ETA: 2s - loss: 0.7557 - accuracy: 0.85 - ETA: 2s - loss: 0.7811 - accuracy: 0.83 - ETA: 2s - loss: 0.8120 - accuracy: 0.81 - ETA: 2s - loss: 0.8316 - accuracy: 0.81 - ETA: 2s - loss: 0.8854 - accuracy: 0.80 - ETA: 1s - loss: 0.9200 - accuracy: 0.80 - ETA: 1s - loss: 0.9102 - accuracy: 0.80 - ETA: 1s - loss: 0.9105 - accuracy: 0.79 - ETA: 1s - loss: 0.9044 - accuracy: 0.79 - ETA: 1s - loss: 0.8634 - accuracy: 0.80 - ETA: 1s - loss: 0.8426 - accuracy: 0.80 - ETA: 1s - loss: 0.8138 - accuracy: 0.80 - ETA: 1s - loss: 0.8203 - accuracy: 0.80 - ETA: 1s - loss: 0.8476 - accuracy: 0.80 - ETA: 1s - loss: 0.8437 - accuracy: 0.80 - ETA: 1s - loss: 0.8420 - accuracy: 0.80 - ETA: 0s - loss: 0.8319 - accuracy: 0.80 - ETA: 0s - loss: 0.8494 - accuracy: 0.80 - ETA: 0s - loss: 0.8630 - accuracy: 0.79 - ETA: 0s - loss: 0.8871 - accuracy: 0.79 - ETA: 0s - loss: 0.8885 - accuracy: 0.79 - ETA: 0s - loss: 0.8994 - accuracy: 0.79 - ETA: 0s - loss: 0.9072 - accuracy: 0.79 - ETA: 0s - loss: 0.8925 - accuracy: 0.79 - ETA: 0s - loss: 0.8856 - accuracy: 0.79 - ETA: 0s - loss: 0.8843 - accuracy: 0.79 - 7s 7ms/sample - loss: 0.8808 - accuracy: 0.7933 - val_loss: 4.4474 - val_accuracy: 0.0602\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 3s - loss: 0.4894 - accuracy: 0.87 - ETA: 3s - loss: 0.4690 - accuracy: 0.84 - ETA: 3s - loss: 0.4907 - accuracy: 0.86 - ETA: 2s - loss: 0.5021 - accuracy: 0.88 - ETA: 2s - loss: 0.5596 - accuracy: 0.87 - ETA: 2s - loss: 0.5075 - accuracy: 0.88 - ETA: 2s - loss: 0.4735 - accuracy: 0.89 - ETA: 2s - loss: 0.4894 - accuracy: 0.88 - ETA: 2s - loss: 0.5137 - accuracy: 0.88 - ETA: 2s - loss: 0.4995 - accuracy: 0.87 - ETA: 2s - loss: 0.5168 - accuracy: 0.87 - ETA: 2s - loss: 0.5113 - accuracy: 0.87 - ETA: 1s - loss: 0.5366 - accuracy: 0.86 - ETA: 1s - loss: 0.5499 - accuracy: 0.86 - ETA: 1s - loss: 0.6008 - accuracy: 0.86 - ETA: 1s - loss: 0.5993 - accuracy: 0.85 - ETA: 1s - loss: 0.6208 - accuracy: 0.85 - ETA: 1s - loss: 0.6464 - accuracy: 0.84 - ETA: 1s - loss: 0.6584 - accuracy: 0.84 - ETA: 1s - loss: 0.6416 - accuracy: 0.84 - ETA: 1s - loss: 0.6654 - accuracy: 0.84 - ETA: 1s - loss: 0.6925 - accuracy: 0.83 - ETA: 0s - loss: 0.6851 - accuracy: 0.83 - ETA: 0s - loss: 0.6951 - accuracy: 0.83 - ETA: 0s - loss: 0.6887 - accuracy: 0.83 - ETA: 0s - loss: 0.6841 - accuracy: 0.83 - ETA: 0s - loss: 0.7032 - accuracy: 0.83 - ETA: 0s - loss: 0.7004 - accuracy: 0.83 - ETA: 0s - loss: 0.6870 - accuracy: 0.83 - ETA: 0s - loss: 0.6851 - accuracy: 0.83 - ETA: 0s - loss: 0.7031 - accuracy: 0.83 - ETA: 0s - loss: 0.7386 - accuracy: 0.82 - 4s 3ms/sample - loss: 0.7354 - accuracy: 0.8249 - val_loss: 7.2711 - val_accuracy: 0.0330\n",
      "Epoch 7/50\n",
      "1045/1045 [==============================] - ETA: 2s - loss: 0.2579 - accuracy: 0.87 - ETA: 2s - loss: 0.5159 - accuracy: 0.82 - ETA: 2s - loss: 0.4404 - accuracy: 0.84 - ETA: 2s - loss: 0.4422 - accuracy: 0.85 - ETA: 2s - loss: 0.5706 - accuracy: 0.81 - ETA: 2s - loss: 0.4866 - accuracy: 0.84 - ETA: 2s - loss: 0.5455 - accuracy: 0.83 - ETA: 2s - loss: 0.5243 - accuracy: 0.83 - ETA: 2s - loss: 0.5377 - accuracy: 0.82 - ETA: 2s - loss: 0.5150 - accuracy: 0.82 - ETA: 2s - loss: 0.5202 - accuracy: 0.83 - ETA: 1s - loss: 0.5972 - accuracy: 0.83 - ETA: 1s - loss: 0.6083 - accuracy: 0.83 - ETA: 1s - loss: 0.6009 - accuracy: 0.83 - ETA: 1s - loss: 0.6148 - accuracy: 0.83 - ETA: 1s - loss: 0.5920 - accuracy: 0.83 - ETA: 1s - loss: 0.5760 - accuracy: 0.84 - ETA: 1s - loss: 0.5672 - accuracy: 0.83 - ETA: 1s - loss: 0.5758 - accuracy: 0.83 - ETA: 1s - loss: 0.5958 - accuracy: 0.82 - ETA: 1s - loss: 0.5879 - accuracy: 0.83 - ETA: 1s - loss: 0.5849 - accuracy: 0.83 - ETA: 0s - loss: 0.5781 - accuracy: 0.83 - ETA: 0s - loss: 0.5700 - accuracy: 0.83 - ETA: 0s - loss: 0.5721 - accuracy: 0.83 - ETA: 0s - loss: 0.5707 - accuracy: 0.83 - ETA: 0s - loss: 0.5555 - accuracy: 0.84 - ETA: 0s - loss: 0.5602 - accuracy: 0.84 - ETA: 0s - loss: 0.5893 - accuracy: 0.83 - ETA: 0s - loss: 0.5796 - accuracy: 0.83 - ETA: 0s - loss: 0.5760 - accuracy: 0.83 - ETA: 0s - loss: 0.5690 - accuracy: 0.84 - 4s 3ms/sample - loss: 0.5647 - accuracy: 0.8421 - val_loss: 6.5459 - val_accuracy: 0.0408\n",
      "Epoch 8/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.7032 - accuracy: 0.81 - ETA: 2s - loss: 0.5227 - accuracy: 0.82 - ETA: 2s - loss: 0.6661 - accuracy: 0.82 - ETA: 2s - loss: 0.8940 - accuracy: 0.77 - ETA: 2s - loss: 0.9176 - accuracy: 0.80 - ETA: 2s - loss: 0.8341 - accuracy: 0.81 - ETA: 2s - loss: 0.8617 - accuracy: 0.81 - ETA: 2s - loss: 0.8289 - accuracy: 0.80 - ETA: 2s - loss: 0.8257 - accuracy: 0.81 - ETA: 2s - loss: 0.9110 - accuracy: 0.80 - ETA: 2s - loss: 0.8670 - accuracy: 0.80 - ETA: 1s - loss: 0.9208 - accuracy: 0.80 - ETA: 1s - loss: 0.9037 - accuracy: 0.80 - ETA: 1s - loss: 0.9065 - accuracy: 0.80 - ETA: 1s - loss: 0.9373 - accuracy: 0.80 - ETA: 1s - loss: 0.8951 - accuracy: 0.81 - ETA: 1s - loss: 0.8552 - accuracy: 0.81 - ETA: 1s - loss: 0.8415 - accuracy: 0.81 - ETA: 1s - loss: 0.8417 - accuracy: 0.81 - ETA: 1s - loss: 0.8627 - accuracy: 0.81 - ETA: 1s - loss: 0.8645 - accuracy: 0.81 - ETA: 1s - loss: 0.8509 - accuracy: 0.81 - ETA: 0s - loss: 0.8269 - accuracy: 0.81 - ETA: 0s - loss: 0.7957 - accuracy: 0.82 - ETA: 0s - loss: 0.7824 - accuracy: 0.82 - ETA: 0s - loss: 0.7649 - accuracy: 0.82 - ETA: 0s - loss: 0.7514 - accuracy: 0.82 - ETA: 0s - loss: 0.7327 - accuracy: 0.83 - ETA: 0s - loss: 0.7260 - accuracy: 0.82 - ETA: 0s - loss: 0.7231 - accuracy: 0.83 - ETA: 0s - loss: 0.7116 - accuracy: 0.83 - ETA: 0s - loss: 0.7115 - accuracy: 0.83 - 4s 3ms/sample - loss: 0.7158 - accuracy: 0.8297 - val_loss: 9.7230 - val_accuracy: 0.0602\n",
      "Epoch 9/50\n",
      "1045/1045 [==============================] - ETA: 2s - loss: 0.5424 - accuracy: 0.81 - ETA: 2s - loss: 0.3806 - accuracy: 0.85 - ETA: 2s - loss: 0.2866 - accuracy: 0.88 - ETA: 2s - loss: 0.2654 - accuracy: 0.89 - ETA: 2s - loss: 0.3682 - accuracy: 0.88 - ETA: 2s - loss: 0.3229 - accuracy: 0.90 - ETA: 2s - loss: 0.3376 - accuracy: 0.89 - ETA: 2s - loss: 0.3275 - accuracy: 0.90 - ETA: 2s - loss: 0.3255 - accuracy: 0.89 - ETA: 2s - loss: 0.3557 - accuracy: 0.88 - ETA: 2s - loss: 0.3956 - accuracy: 0.87 - ETA: 1s - loss: 0.4098 - accuracy: 0.87 - ETA: 1s - loss: 0.4017 - accuracy: 0.87 - ETA: 1s - loss: 0.3970 - accuracy: 0.87 - ETA: 1s - loss: 0.3983 - accuracy: 0.87 - ETA: 1s - loss: 0.4189 - accuracy: 0.87 - ETA: 1s - loss: 0.4308 - accuracy: 0.86 - ETA: 1s - loss: 0.4358 - accuracy: 0.86 - ETA: 1s - loss: 0.4502 - accuracy: 0.86 - ETA: 1s - loss: 0.4804 - accuracy: 0.85 - ETA: 1s - loss: 0.5322 - accuracy: 0.85 - ETA: 1s - loss: 0.5180 - accuracy: 0.85 - ETA: 0s - loss: 0.5281 - accuracy: 0.85 - ETA: 0s - loss: 0.5126 - accuracy: 0.85 - ETA: 0s - loss: 0.5415 - accuracy: 0.85 - ETA: 0s - loss: 0.5337 - accuracy: 0.85 - ETA: 0s - loss: 0.5353 - accuracy: 0.85 - ETA: 0s - loss: 0.5235 - accuracy: 0.85 - ETA: 0s - loss: 0.5238 - accuracy: 0.85 - ETA: 0s - loss: 0.5197 - accuracy: 0.85 - ETA: 0s - loss: 0.5160 - accuracy: 0.85 - ETA: 0s - loss: 0.5248 - accuracy: 0.85 - 4s 3ms/sample - loss: 0.5190 - accuracy: 0.8555 - val_loss: 9.7000 - val_accuracy: 0.0466\n",
      "Epoch 10/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.1636 - accuracy: 0.93 - ETA: 3s - loss: 0.4727 - accuracy: 0.89 - ETA: 2s - loss: 0.3867 - accuracy: 0.89 - ETA: 2s - loss: 0.3630 - accuracy: 0.89 - ETA: 2s - loss: 0.4057 - accuracy: 0.90 - ETA: 2s - loss: 0.3864 - accuracy: 0.90 - ETA: 2s - loss: 0.3877 - accuracy: 0.90 - ETA: 2s - loss: 0.4044 - accuracy: 0.90 - ETA: 2s - loss: 0.3694 - accuracy: 0.90 - ETA: 2s - loss: 0.3893 - accuracy: 0.90 - ETA: 2s - loss: 0.4162 - accuracy: 0.90 - ETA: 2s - loss: 0.3963 - accuracy: 0.90 - ETA: 1s - loss: 0.3781 - accuracy: 0.90 - ETA: 1s - loss: 0.3525 - accuracy: 0.91 - ETA: 1s - loss: 0.3418 - accuracy: 0.91 - ETA: 1s - loss: 0.3708 - accuracy: 0.91 - ETA: 1s - loss: 0.3681 - accuracy: 0.90 - ETA: 1s - loss: 0.3940 - accuracy: 0.90 - ETA: 1s - loss: 0.4306 - accuracy: 0.89 - ETA: 1s - loss: 0.4115 - accuracy: 0.90 - ETA: 1s - loss: 0.4031 - accuracy: 0.90 - ETA: 1s - loss: 0.3980 - accuracy: 0.90 - ETA: 0s - loss: 0.3916 - accuracy: 0.90 - ETA: 0s - loss: 0.3827 - accuracy: 0.90 - ETA: 0s - loss: 0.4003 - accuracy: 0.90 - ETA: 0s - loss: 0.4014 - accuracy: 0.90 - ETA: 0s - loss: 0.4069 - accuracy: 0.89 - ETA: 0s - loss: 0.4003 - accuracy: 0.89 - ETA: 0s - loss: 0.3939 - accuracy: 0.90 - ETA: 0s - loss: 0.3955 - accuracy: 0.89 - ETA: 0s - loss: 0.3968 - accuracy: 0.89 - ETA: 0s - loss: 0.4005 - accuracy: 0.89 - 4s 3ms/sample - loss: 0.3957 - accuracy: 0.8919 - val_loss: 8.5050 - val_accuracy: 0.0524\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 3s - loss: 0.8730 - accuracy: 0.87 - ETA: 3s - loss: 0.5310 - accuracy: 0.90 - ETA: 2s - loss: 0.4081 - accuracy: 0.91 - ETA: 2s - loss: 0.4299 - accuracy: 0.89 - ETA: 2s - loss: 0.4088 - accuracy: 0.90 - ETA: 2s - loss: 0.3691 - accuracy: 0.90 - ETA: 2s - loss: 0.3603 - accuracy: 0.90 - ETA: 2s - loss: 0.3350 - accuracy: 0.91 - ETA: 2s - loss: 0.3050 - accuracy: 0.91 - ETA: 2s - loss: 0.3506 - accuracy: 0.91 - ETA: 2s - loss: 0.3275 - accuracy: 0.91 - ETA: 1s - loss: 0.3123 - accuracy: 0.91 - ETA: 1s - loss: 0.3011 - accuracy: 0.91 - ETA: 1s - loss: 0.3162 - accuracy: 0.91 - ETA: 1s - loss: 0.3017 - accuracy: 0.91 - ETA: 1s - loss: 0.3009 - accuracy: 0.91 - ETA: 1s - loss: 0.2968 - accuracy: 0.91 - ETA: 1s - loss: 0.2962 - accuracy: 0.91 - ETA: 1s - loss: 0.2872 - accuracy: 0.91 - ETA: 1s - loss: 0.2871 - accuracy: 0.91 - ETA: 1s - loss: 0.3025 - accuracy: 0.91 - ETA: 1s - loss: 0.2952 - accuracy: 0.91 - ETA: 0s - loss: 0.2918 - accuracy: 0.91 - ETA: 0s - loss: 0.2908 - accuracy: 0.91 - ETA: 0s - loss: 0.2905 - accuracy: 0.91 - ETA: 0s - loss: 0.2958 - accuracy: 0.90 - ETA: 0s - loss: 0.2871 - accuracy: 0.91 - ETA: 0s - loss: 0.2794 - accuracy: 0.91 - ETA: 0s - loss: 0.2900 - accuracy: 0.90 - ETA: 0s - loss: 0.2907 - accuracy: 0.91 - ETA: 0s - loss: 0.2880 - accuracy: 0.91 - ETA: 0s - loss: 0.2850 - accuracy: 0.91 - 8s 8ms/sample - loss: 0.2804 - accuracy: 0.9129 - val_loss: 9.5038 - val_accuracy: 0.0990\n",
      "Epoch 12/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0675 - accuracy: 0.96 - ETA: 2s - loss: 0.1004 - accuracy: 0.95 - ETA: 2s - loss: 0.2378 - accuracy: 0.93 - ETA: 2s - loss: 0.2058 - accuracy: 0.94 - ETA: 2s - loss: 0.2376 - accuracy: 0.93 - ETA: 2s - loss: 0.2218 - accuracy: 0.93 - ETA: 2s - loss: 0.2139 - accuracy: 0.94 - ETA: 2s - loss: 0.2166 - accuracy: 0.94 - ETA: 2s - loss: 0.2177 - accuracy: 0.93 - ETA: 2s - loss: 0.2217 - accuracy: 0.93 - ETA: 2s - loss: 0.2048 - accuracy: 0.93 - ETA: 1s - loss: 0.1977 - accuracy: 0.93 - ETA: 1s - loss: 0.1840 - accuracy: 0.94 - ETA: 1s - loss: 0.1993 - accuracy: 0.94 - ETA: 1s - loss: 0.1915 - accuracy: 0.94 - ETA: 1s - loss: 0.2064 - accuracy: 0.93 - ETA: 1s - loss: 0.2012 - accuracy: 0.93 - ETA: 1s - loss: 0.1915 - accuracy: 0.94 - ETA: 1s - loss: 0.1879 - accuracy: 0.94 - ETA: 1s - loss: 0.1813 - accuracy: 0.94 - ETA: 1s - loss: 0.1788 - accuracy: 0.94 - ETA: 1s - loss: 0.1794 - accuracy: 0.94 - ETA: 0s - loss: 0.1838 - accuracy: 0.94 - ETA: 0s - loss: 0.1870 - accuracy: 0.94 - ETA: 0s - loss: 0.1804 - accuracy: 0.94 - ETA: 0s - loss: 0.1759 - accuracy: 0.94 - ETA: 0s - loss: 0.1884 - accuracy: 0.94 - ETA: 0s - loss: 0.1885 - accuracy: 0.94 - ETA: 0s - loss: 0.1851 - accuracy: 0.94 - ETA: 0s - loss: 0.1829 - accuracy: 0.94 - ETA: 0s - loss: 0.1850 - accuracy: 0.94 - ETA: 0s - loss: 0.1966 - accuracy: 0.94 - 4s 3ms/sample - loss: 0.2011 - accuracy: 0.9397 - val_loss: 7.6096 - val_accuracy: 0.0913\n",
      "Epoch 13/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.2336 - accuracy: 0.87 - ETA: 2s - loss: 0.1578 - accuracy: 0.92 - ETA: 2s - loss: 0.1317 - accuracy: 0.93 - ETA: 2s - loss: 0.1053 - accuracy: 0.95 - ETA: 2s - loss: 0.1407 - accuracy: 0.95 - ETA: 2s - loss: 0.1307 - accuracy: 0.95 - ETA: 2s - loss: 0.1461 - accuracy: 0.95 - ETA: 2s - loss: 0.1451 - accuracy: 0.95 - ETA: 2s - loss: 0.1510 - accuracy: 0.94 - ETA: 2s - loss: 0.1583 - accuracy: 0.94 - ETA: 2s - loss: 0.1598 - accuracy: 0.94 - ETA: 1s - loss: 0.1825 - accuracy: 0.93 - ETA: 1s - loss: 0.1998 - accuracy: 0.93 - ETA: 1s - loss: 0.1981 - accuracy: 0.93 - ETA: 1s - loss: 0.1874 - accuracy: 0.93 - ETA: 1s - loss: 0.1782 - accuracy: 0.93 - ETA: 1s - loss: 0.1886 - accuracy: 0.93 - ETA: 1s - loss: 0.2037 - accuracy: 0.92 - ETA: 1s - loss: 0.1940 - accuracy: 0.93 - ETA: 1s - loss: 0.2100 - accuracy: 0.93 - ETA: 1s - loss: 0.2030 - accuracy: 0.93 - ETA: 1s - loss: 0.1944 - accuracy: 0.93 - ETA: 0s - loss: 0.1890 - accuracy: 0.93 - ETA: 0s - loss: 0.1864 - accuracy: 0.93 - ETA: 0s - loss: 0.1836 - accuracy: 0.93 - ETA: 0s - loss: 0.1905 - accuracy: 0.93 - ETA: 0s - loss: 0.1994 - accuracy: 0.93 - ETA: 0s - loss: 0.1979 - accuracy: 0.93 - ETA: 0s - loss: 0.1949 - accuracy: 0.93 - ETA: 0s - loss: 0.1993 - accuracy: 0.93 - ETA: 0s - loss: 0.1941 - accuracy: 0.93 - ETA: 0s - loss: 0.1883 - accuracy: 0.94 - 9s 9ms/sample - loss: 0.1899 - accuracy: 0.9397 - val_loss: 2.7648 - val_accuracy: 0.3650\n",
      "Epoch 14/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0273 - accuracy: 1.00 - ETA: 3s - loss: 0.0548 - accuracy: 0.98 - ETA: 2s - loss: 0.0849 - accuracy: 0.95 - ETA: 2s - loss: 0.1064 - accuracy: 0.95 - ETA: 2s - loss: 0.2124 - accuracy: 0.93 - ETA: 2s - loss: 0.2003 - accuracy: 0.93 - ETA: 2s - loss: 0.2072 - accuracy: 0.93 - ETA: 2s - loss: 0.2465 - accuracy: 0.92 - ETA: 2s - loss: 0.2606 - accuracy: 0.93 - ETA: 2s - loss: 0.2745 - accuracy: 0.92 - ETA: 2s - loss: 0.3036 - accuracy: 0.91 - ETA: 1s - loss: 0.2897 - accuracy: 0.91 - ETA: 1s - loss: 0.2856 - accuracy: 0.92 - ETA: 1s - loss: 0.2712 - accuracy: 0.92 - ETA: 1s - loss: 0.2645 - accuracy: 0.92 - ETA: 1s - loss: 0.2498 - accuracy: 0.92 - ETA: 1s - loss: 0.2434 - accuracy: 0.92 - ETA: 1s - loss: 0.2354 - accuracy: 0.93 - ETA: 1s - loss: 0.2313 - accuracy: 0.93 - ETA: 1s - loss: 0.2274 - accuracy: 0.93 - ETA: 1s - loss: 0.2178 - accuracy: 0.93 - ETA: 1s - loss: 0.2088 - accuracy: 0.93 - ETA: 0s - loss: 0.2195 - accuracy: 0.93 - ETA: 0s - loss: 0.2296 - accuracy: 0.93 - ETA: 0s - loss: 0.2251 - accuracy: 0.93 - ETA: 0s - loss: 0.2256 - accuracy: 0.93 - ETA: 0s - loss: 0.2298 - accuracy: 0.93 - ETA: 0s - loss: 0.2506 - accuracy: 0.93 - ETA: 0s - loss: 0.2466 - accuracy: 0.93 - ETA: 0s - loss: 0.2520 - accuracy: 0.93 - ETA: 0s - loss: 0.2528 - accuracy: 0.92 - ETA: 0s - loss: 0.2578 - accuracy: 0.92 - 4s 3ms/sample - loss: 0.2584 - accuracy: 0.9282 - val_loss: 6.6621 - val_accuracy: 0.2136\n",
      "Epoch 15/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.2598 - accuracy: 0.90 - ETA: 2s - loss: 0.1770 - accuracy: 0.93 - ETA: 2s - loss: 0.1687 - accuracy: 0.92 - ETA: 2s - loss: 0.1334 - accuracy: 0.94 - ETA: 2s - loss: 0.1487 - accuracy: 0.95 - ETA: 2s - loss: 0.1690 - accuracy: 0.95 - ETA: 2s - loss: 0.1986 - accuracy: 0.95 - ETA: 2s - loss: 0.1907 - accuracy: 0.95 - ETA: 2s - loss: 0.1835 - accuracy: 0.94 - ETA: 2s - loss: 0.1828 - accuracy: 0.94 - ETA: 2s - loss: 0.2094 - accuracy: 0.93 - ETA: 1s - loss: 0.2286 - accuracy: 0.93 - ETA: 1s - loss: 0.2436 - accuracy: 0.93 - ETA: 1s - loss: 0.2548 - accuracy: 0.93 - ETA: 1s - loss: 0.2436 - accuracy: 0.93 - ETA: 1s - loss: 0.2375 - accuracy: 0.93 - ETA: 1s - loss: 0.2517 - accuracy: 0.93 - ETA: 1s - loss: 0.2566 - accuracy: 0.93 - ETA: 1s - loss: 0.2537 - accuracy: 0.93 - ETA: 1s - loss: 0.2550 - accuracy: 0.93 - ETA: 1s - loss: 0.2433 - accuracy: 0.93 - ETA: 1s - loss: 0.2383 - accuracy: 0.93 - ETA: 0s - loss: 0.2372 - accuracy: 0.94 - ETA: 0s - loss: 0.2333 - accuracy: 0.94 - ETA: 0s - loss: 0.2268 - accuracy: 0.94 - ETA: 0s - loss: 0.2287 - accuracy: 0.94 - ETA: 0s - loss: 0.2319 - accuracy: 0.93 - ETA: 0s - loss: 0.2415 - accuracy: 0.93 - ETA: 0s - loss: 0.2431 - accuracy: 0.93 - ETA: 0s - loss: 0.2422 - accuracy: 0.93 - ETA: 0s - loss: 0.2390 - accuracy: 0.93 - ETA: 0s - loss: 0.2377 - accuracy: 0.93 - 9s 9ms/sample - loss: 0.2409 - accuracy: 0.9368 - val_loss: 2.8307 - val_accuracy: 0.4583\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0076 - accuracy: 1.00 - ETA: 3s - loss: 0.0974 - accuracy: 0.96 - ETA: 2s - loss: 0.1839 - accuracy: 0.96 - ETA: 2s - loss: 0.1943 - accuracy: 0.95 - ETA: 2s - loss: 0.1865 - accuracy: 0.95 - ETA: 2s - loss: 0.1856 - accuracy: 0.94 - ETA: 2s - loss: 0.1805 - accuracy: 0.95 - ETA: 2s - loss: 0.1901 - accuracy: 0.94 - ETA: 2s - loss: 0.2381 - accuracy: 0.93 - ETA: 2s - loss: 0.2172 - accuracy: 0.94 - ETA: 2s - loss: 0.2129 - accuracy: 0.94 - ETA: 1s - loss: 0.2007 - accuracy: 0.94 - ETA: 1s - loss: 0.2170 - accuracy: 0.94 - ETA: 1s - loss: 0.2087 - accuracy: 0.94 - ETA: 1s - loss: 0.2462 - accuracy: 0.93 - ETA: 1s - loss: 0.2577 - accuracy: 0.93 - ETA: 1s - loss: 0.2455 - accuracy: 0.93 - ETA: 1s - loss: 0.2427 - accuracy: 0.93 - ETA: 1s - loss: 0.2355 - accuracy: 0.93 - ETA: 1s - loss: 0.2249 - accuracy: 0.94 - ETA: 1s - loss: 0.2274 - accuracy: 0.93 - ETA: 1s - loss: 0.2390 - accuracy: 0.93 - ETA: 0s - loss: 0.2443 - accuracy: 0.93 - ETA: 0s - loss: 0.2631 - accuracy: 0.93 - ETA: 0s - loss: 0.2546 - accuracy: 0.93 - ETA: 0s - loss: 0.2479 - accuracy: 0.93 - ETA: 0s - loss: 0.2547 - accuracy: 0.93 - ETA: 0s - loss: 0.2556 - accuracy: 0.93 - ETA: 0s - loss: 0.2608 - accuracy: 0.92 - ETA: 0s - loss: 0.2662 - accuracy: 0.92 - ETA: 0s - loss: 0.2704 - accuracy: 0.92 - ETA: 0s - loss: 0.2660 - accuracy: 0.92 - 4s 3ms/sample - loss: 0.2644 - accuracy: 0.9263 - val_loss: 3.7507 - val_accuracy: 0.3650\n",
      "Epoch 17/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.5140 - accuracy: 0.93 - ETA: 2s - loss: 0.4739 - accuracy: 0.90 - ETA: 2s - loss: 0.3445 - accuracy: 0.92 - ETA: 2s - loss: 0.2646 - accuracy: 0.94 - ETA: 2s - loss: 0.2350 - accuracy: 0.95 - ETA: 2s - loss: 0.2281 - accuracy: 0.95 - ETA: 2s - loss: 0.2070 - accuracy: 0.95 - ETA: 2s - loss: 0.3019 - accuracy: 0.93 - ETA: 2s - loss: 0.2829 - accuracy: 0.94 - ETA: 2s - loss: 0.2589 - accuracy: 0.94 - ETA: 2s - loss: 0.2498 - accuracy: 0.94 - ETA: 1s - loss: 0.2429 - accuracy: 0.94 - ETA: 1s - loss: 0.2637 - accuracy: 0.94 - ETA: 1s - loss: 0.2895 - accuracy: 0.93 - ETA: 1s - loss: 0.2784 - accuracy: 0.93 - ETA: 1s - loss: 0.2683 - accuracy: 0.93 - ETA: 1s - loss: 0.2575 - accuracy: 0.93 - ETA: 1s - loss: 0.2537 - accuracy: 0.93 - ETA: 1s - loss: 0.2685 - accuracy: 0.92 - ETA: 1s - loss: 0.2763 - accuracy: 0.92 - ETA: 1s - loss: 0.2925 - accuracy: 0.91 - ETA: 1s - loss: 0.2955 - accuracy: 0.92 - ETA: 0s - loss: 0.2881 - accuracy: 0.92 - ETA: 0s - loss: 0.2905 - accuracy: 0.92 - ETA: 0s - loss: 0.2827 - accuracy: 0.92 - ETA: 0s - loss: 0.2777 - accuracy: 0.92 - ETA: 0s - loss: 0.2778 - accuracy: 0.92 - ETA: 0s - loss: 0.2972 - accuracy: 0.92 - ETA: 0s - loss: 0.3077 - accuracy: 0.91 - ETA: 0s - loss: 0.3236 - accuracy: 0.91 - ETA: 0s - loss: 0.3231 - accuracy: 0.91 - ETA: 0s - loss: 0.3185 - accuracy: 0.91 - 10s 10ms/sample - loss: 0.3145 - accuracy: 0.9120 - val_loss: 1.6443 - val_accuracy: 0.6971\n",
      "Epoch 18/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0920 - accuracy: 0.93 - ETA: 3s - loss: 0.1524 - accuracy: 0.93 - ETA: 2s - loss: 0.1866 - accuracy: 0.94 - ETA: 2s - loss: 0.2666 - accuracy: 0.94 - ETA: 2s - loss: 0.2552 - accuracy: 0.95 - ETA: 2s - loss: 0.2539 - accuracy: 0.93 - ETA: 2s - loss: 0.2526 - accuracy: 0.93 - ETA: 2s - loss: 0.2352 - accuracy: 0.94 - ETA: 2s - loss: 0.2443 - accuracy: 0.94 - ETA: 2s - loss: 0.2527 - accuracy: 0.94 - ETA: 2s - loss: 0.2512 - accuracy: 0.93 - ETA: 1s - loss: 0.2354 - accuracy: 0.94 - ETA: 1s - loss: 0.2396 - accuracy: 0.93 - ETA: 1s - loss: 0.2511 - accuracy: 0.93 - ETA: 1s - loss: 0.2530 - accuracy: 0.93 - ETA: 1s - loss: 0.2486 - accuracy: 0.93 - ETA: 1s - loss: 0.2420 - accuracy: 0.93 - ETA: 1s - loss: 0.2429 - accuracy: 0.93 - ETA: 1s - loss: 0.2318 - accuracy: 0.93 - ETA: 1s - loss: 0.2331 - accuracy: 0.93 - ETA: 1s - loss: 0.2304 - accuracy: 0.93 - ETA: 1s - loss: 0.2204 - accuracy: 0.94 - ETA: 0s - loss: 0.2192 - accuracy: 0.94 - ETA: 0s - loss: 0.2218 - accuracy: 0.93 - ETA: 0s - loss: 0.2172 - accuracy: 0.94 - ETA: 0s - loss: 0.2115 - accuracy: 0.94 - ETA: 0s - loss: 0.2062 - accuracy: 0.94 - ETA: 0s - loss: 0.1997 - accuracy: 0.94 - ETA: 0s - loss: 0.1944 - accuracy: 0.94 - ETA: 0s - loss: 0.1982 - accuracy: 0.94 - ETA: 0s - loss: 0.1950 - accuracy: 0.94 - ETA: 0s - loss: 0.1975 - accuracy: 0.94 - 4s 3ms/sample - loss: 0.1945 - accuracy: 0.9474 - val_loss: 3.1135 - val_accuracy: 0.5456\n",
      "Epoch 19/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0356 - accuracy: 0.96 - ETA: 2s - loss: 0.0400 - accuracy: 0.98 - ETA: 2s - loss: 0.0758 - accuracy: 0.96 - ETA: 2s - loss: 0.1022 - accuracy: 0.95 - ETA: 2s - loss: 0.1132 - accuracy: 0.95 - ETA: 2s - loss: 0.1041 - accuracy: 0.96 - ETA: 2s - loss: 0.0904 - accuracy: 0.96 - ETA: 2s - loss: 0.0892 - accuracy: 0.96 - ETA: 2s - loss: 0.0848 - accuracy: 0.96 - ETA: 2s - loss: 0.0832 - accuracy: 0.96 - ETA: 2s - loss: 0.0824 - accuracy: 0.96 - ETA: 1s - loss: 0.0758 - accuracy: 0.97 - ETA: 1s - loss: 0.0729 - accuracy: 0.97 - ETA: 1s - loss: 0.0693 - accuracy: 0.97 - ETA: 1s - loss: 0.0720 - accuracy: 0.97 - ETA: 1s - loss: 0.0813 - accuracy: 0.97 - ETA: 1s - loss: 0.0808 - accuracy: 0.97 - ETA: 1s - loss: 0.0784 - accuracy: 0.97 - ETA: 1s - loss: 0.0754 - accuracy: 0.97 - ETA: 1s - loss: 0.0736 - accuracy: 0.97 - ETA: 1s - loss: 0.0701 - accuracy: 0.97 - ETA: 1s - loss: 0.0704 - accuracy: 0.97 - ETA: 0s - loss: 0.0678 - accuracy: 0.97 - ETA: 0s - loss: 0.0697 - accuracy: 0.97 - ETA: 0s - loss: 0.0696 - accuracy: 0.97 - ETA: 0s - loss: 0.0701 - accuracy: 0.97 - ETA: 0s - loss: 0.0682 - accuracy: 0.97 - ETA: 0s - loss: 0.0680 - accuracy: 0.97 - ETA: 0s - loss: 0.0790 - accuracy: 0.97 - ETA: 0s - loss: 0.0781 - accuracy: 0.97 - ETA: 0s - loss: 0.0766 - accuracy: 0.97 - ETA: 0s - loss: 0.0748 - accuracy: 0.97 - 11s 11ms/sample - loss: 0.0745 - accuracy: 0.9770 - val_loss: 1.2546 - val_accuracy: 0.7456\n",
      "Epoch 20/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0276 - accuracy: 0.96 - ETA: 3s - loss: 0.0151 - accuracy: 0.98 - ETA: 2s - loss: 0.0121 - accuracy: 0.98 - ETA: 2s - loss: 0.0395 - accuracy: 0.98 - ETA: 2s - loss: 0.0334 - accuracy: 0.98 - ETA: 2s - loss: 0.0386 - accuracy: 0.98 - ETA: 2s - loss: 0.0353 - accuracy: 0.98 - ETA: 2s - loss: 0.0310 - accuracy: 0.98 - ETA: 2s - loss: 0.0366 - accuracy: 0.98 - ETA: 2s - loss: 0.0422 - accuracy: 0.98 - ETA: 2s - loss: 0.0410 - accuracy: 0.98 - ETA: 1s - loss: 0.0411 - accuracy: 0.98 - ETA: 1s - loss: 0.0383 - accuracy: 0.98 - ETA: 1s - loss: 0.0377 - accuracy: 0.98 - ETA: 1s - loss: 0.0359 - accuracy: 0.98 - ETA: 1s - loss: 0.0344 - accuracy: 0.98 - ETA: 1s - loss: 0.0328 - accuracy: 0.98 - ETA: 1s - loss: 0.0344 - accuracy: 0.98 - ETA: 1s - loss: 0.0557 - accuracy: 0.98 - ETA: 1s - loss: 0.0544 - accuracy: 0.98 - ETA: 1s - loss: 0.0530 - accuracy: 0.98 - ETA: 1s - loss: 0.0551 - accuracy: 0.98 - ETA: 0s - loss: 0.0532 - accuracy: 0.98 - ETA: 0s - loss: 0.0511 - accuracy: 0.98 - ETA: 0s - loss: 0.0491 - accuracy: 0.98 - ETA: 0s - loss: 0.0481 - accuracy: 0.98 - ETA: 0s - loss: 0.0470 - accuracy: 0.98 - ETA: 0s - loss: 0.0510 - accuracy: 0.98 - ETA: 0s - loss: 0.0494 - accuracy: 0.98 - ETA: 0s - loss: 0.0494 - accuracy: 0.98 - ETA: 0s - loss: 0.0509 - accuracy: 0.98 - ETA: 0s - loss: 0.0497 - accuracy: 0.98 - 8s 7ms/sample - loss: 0.0553 - accuracy: 0.9856 - val_loss: 0.7325 - val_accuracy: 0.8583\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0438 - accuracy: 0.96 - ETA: 2s - loss: 0.0678 - accuracy: 0.96 - ETA: 2s - loss: 0.0781 - accuracy: 0.95 - ETA: 2s - loss: 0.0591 - accuracy: 0.96 - ETA: 2s - loss: 0.0480 - accuracy: 0.97 - ETA: 2s - loss: 0.0457 - accuracy: 0.97 - ETA: 2s - loss: 0.0940 - accuracy: 0.96 - ETA: 2s - loss: 0.0824 - accuracy: 0.96 - ETA: 2s - loss: 0.0751 - accuracy: 0.97 - ETA: 2s - loss: 0.0678 - accuracy: 0.97 - ETA: 2s - loss: 0.0633 - accuracy: 0.97 - ETA: 1s - loss: 0.0600 - accuracy: 0.97 - ETA: 1s - loss: 0.0565 - accuracy: 0.98 - ETA: 1s - loss: 0.0530 - accuracy: 0.98 - ETA: 1s - loss: 0.0499 - accuracy: 0.98 - ETA: 1s - loss: 0.0531 - accuracy: 0.98 - ETA: 1s - loss: 0.0507 - accuracy: 0.98 - ETA: 1s - loss: 0.0636 - accuracy: 0.97 - ETA: 1s - loss: 0.0607 - accuracy: 0.97 - ETA: 1s - loss: 0.0652 - accuracy: 0.97 - ETA: 1s - loss: 0.0640 - accuracy: 0.97 - ETA: 1s - loss: 0.0612 - accuracy: 0.97 - ETA: 0s - loss: 0.0597 - accuracy: 0.97 - ETA: 0s - loss: 0.0620 - accuracy: 0.97 - ETA: 0s - loss: 0.0655 - accuracy: 0.97 - ETA: 0s - loss: 0.0634 - accuracy: 0.97 - ETA: 0s - loss: 0.0615 - accuracy: 0.97 - ETA: 0s - loss: 0.0594 - accuracy: 0.97 - ETA: 0s - loss: 0.0581 - accuracy: 0.97 - ETA: 0s - loss: 0.0587 - accuracy: 0.97 - ETA: 0s - loss: 0.0578 - accuracy: 0.97 - ETA: 0s - loss: 0.0672 - accuracy: 0.97 - 4s 3ms/sample - loss: 0.0659 - accuracy: 0.9789 - val_loss: 0.9168 - val_accuracy: 0.8194\n",
      "Epoch 22/50\n",
      "1045/1045 [==============================] - ETA: 2s - loss: 0.0030 - accuracy: 1.00 - ETA: 2s - loss: 0.0334 - accuracy: 0.98 - ETA: 2s - loss: 0.0446 - accuracy: 0.97 - ETA: 2s - loss: 0.0337 - accuracy: 0.98 - ETA: 2s - loss: 0.0300 - accuracy: 0.98 - ETA: 2s - loss: 0.0780 - accuracy: 0.98 - ETA: 2s - loss: 0.0745 - accuracy: 0.98 - ETA: 2s - loss: 0.0654 - accuracy: 0.98 - ETA: 2s - loss: 0.0586 - accuracy: 0.98 - ETA: 2s - loss: 0.0549 - accuracy: 0.98 - ETA: 2s - loss: 0.0501 - accuracy: 0.98 - ETA: 1s - loss: 0.0462 - accuracy: 0.98 - ETA: 1s - loss: 0.0530 - accuracy: 0.98 - ETA: 1s - loss: 0.0494 - accuracy: 0.98 - ETA: 1s - loss: 0.0466 - accuracy: 0.98 - ETA: 1s - loss: 0.0568 - accuracy: 0.98 - ETA: 1s - loss: 0.0556 - accuracy: 0.98 - ETA: 1s - loss: 0.0557 - accuracy: 0.98 - ETA: 1s - loss: 0.0995 - accuracy: 0.97 - ETA: 1s - loss: 0.0974 - accuracy: 0.97 - ETA: 1s - loss: 0.1014 - accuracy: 0.97 - ETA: 1s - loss: 0.0970 - accuracy: 0.97 - ETA: 0s - loss: 0.0928 - accuracy: 0.97 - ETA: 0s - loss: 0.0904 - accuracy: 0.97 - ETA: 0s - loss: 0.0879 - accuracy: 0.97 - ETA: 0s - loss: 0.0853 - accuracy: 0.97 - ETA: 0s - loss: 0.0830 - accuracy: 0.98 - ETA: 0s - loss: 0.0826 - accuracy: 0.97 - ETA: 0s - loss: 0.0874 - accuracy: 0.97 - ETA: 0s - loss: 0.0848 - accuracy: 0.97 - ETA: 0s - loss: 0.0824 - accuracy: 0.97 - ETA: 0s - loss: 0.0802 - accuracy: 0.98 - 4s 3ms/sample - loss: 0.0815 - accuracy: 0.9799 - val_loss: 0.8630 - val_accuracy: 0.8330\n",
      "Epoch 23/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0719 - accuracy: 0.96 - ETA: 2s - loss: 0.1961 - accuracy: 0.93 - ETA: 2s - loss: 0.2637 - accuracy: 0.92 - ETA: 2s - loss: 0.2400 - accuracy: 0.93 - ETA: 2s - loss: 0.2038 - accuracy: 0.94 - ETA: 2s - loss: 0.1890 - accuracy: 0.94 - ETA: 2s - loss: 0.1661 - accuracy: 0.95 - ETA: 2s - loss: 0.1575 - accuracy: 0.95 - ETA: 2s - loss: 0.1489 - accuracy: 0.95 - ETA: 2s - loss: 0.1732 - accuracy: 0.95 - ETA: 2s - loss: 0.1601 - accuracy: 0.95 - ETA: 1s - loss: 0.2669 - accuracy: 0.95 - ETA: 1s - loss: 0.2608 - accuracy: 0.95 - ETA: 1s - loss: 0.2591 - accuracy: 0.95 - ETA: 1s - loss: 0.2615 - accuracy: 0.95 - ETA: 1s - loss: 0.2605 - accuracy: 0.95 - ETA: 1s - loss: 0.2534 - accuracy: 0.95 - ETA: 1s - loss: 0.2725 - accuracy: 0.95 - ETA: 1s - loss: 0.2879 - accuracy: 0.94 - ETA: 1s - loss: 0.2744 - accuracy: 0.95 - ETA: 1s - loss: 0.2750 - accuracy: 0.94 - ETA: 1s - loss: 0.2656 - accuracy: 0.94 - ETA: 0s - loss: 0.2809 - accuracy: 0.94 - ETA: 0s - loss: 0.2887 - accuracy: 0.94 - ETA: 0s - loss: 0.3141 - accuracy: 0.94 - ETA: 0s - loss: 0.3124 - accuracy: 0.94 - ETA: 0s - loss: 0.3021 - accuracy: 0.94 - ETA: 0s - loss: 0.2979 - accuracy: 0.94 - ETA: 0s - loss: 0.3086 - accuracy: 0.93 - ETA: 0s - loss: 0.3041 - accuracy: 0.93 - ETA: 0s - loss: 0.3046 - accuracy: 0.93 - ETA: 0s - loss: 0.3248 - accuracy: 0.93 - 4s 3ms/sample - loss: 0.3292 - accuracy: 0.9301 - val_loss: 3.4825 - val_accuracy: 0.6000\n",
      "Epoch 24/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.4536 - accuracy: 0.93 - ETA: 3s - loss: 0.5495 - accuracy: 0.90 - ETA: 3s - loss: 1.0881 - accuracy: 0.84 - ETA: 3s - loss: 0.8339 - accuracy: 0.87 - ETA: 3s - loss: 0.6870 - accuracy: 0.89 - ETA: 2s - loss: 0.6114 - accuracy: 0.89 - ETA: 2s - loss: 0.6026 - accuracy: 0.88 - ETA: 2s - loss: 0.6248 - accuracy: 0.87 - ETA: 2s - loss: 0.6431 - accuracy: 0.87 - ETA: 2s - loss: 0.7797 - accuracy: 0.86 - ETA: 2s - loss: 0.8246 - accuracy: 0.86 - ETA: 2s - loss: 0.7820 - accuracy: 0.87 - ETA: 2s - loss: 0.7941 - accuracy: 0.86 - ETA: 1s - loss: 0.8082 - accuracy: 0.85 - ETA: 1s - loss: 1.0475 - accuracy: 0.83 - ETA: 1s - loss: 1.0829 - accuracy: 0.83 - ETA: 1s - loss: 1.0655 - accuracy: 0.83 - ETA: 1s - loss: 1.0696 - accuracy: 0.83 - ETA: 1s - loss: 1.0512 - accuracy: 0.82 - ETA: 1s - loss: 1.0875 - accuracy: 0.82 - ETA: 1s - loss: 1.0601 - accuracy: 0.82 - ETA: 1s - loss: 1.0447 - accuracy: 0.83 - ETA: 0s - loss: 1.0345 - accuracy: 0.83 - ETA: 0s - loss: 1.0158 - accuracy: 0.83 - ETA: 0s - loss: 0.9971 - accuracy: 0.82 - ETA: 0s - loss: 0.9883 - accuracy: 0.82 - ETA: 0s - loss: 0.9823 - accuracy: 0.82 - ETA: 0s - loss: 0.9680 - accuracy: 0.82 - ETA: 0s - loss: 0.9547 - accuracy: 0.82 - ETA: 0s - loss: 0.9302 - accuracy: 0.82 - ETA: 0s - loss: 0.9210 - accuracy: 0.82 - ETA: 0s - loss: 0.9133 - accuracy: 0.82 - 4s 3ms/sample - loss: 0.9007 - accuracy: 0.8211 - val_loss: 8.0926 - val_accuracy: 0.3010\n",
      "Epoch 25/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 2.1617 - accuracy: 0.71 - ETA: 2s - loss: 1.3597 - accuracy: 0.79 - ETA: 2s - loss: 1.0371 - accuracy: 0.81 - ETA: 2s - loss: 1.0699 - accuracy: 0.80 - ETA: 2s - loss: 0.9832 - accuracy: 0.80 - ETA: 2s - loss: 0.8763 - accuracy: 0.81 - ETA: 2s - loss: 1.0527 - accuracy: 0.80 - ETA: 2s - loss: 1.2931 - accuracy: 0.80 - ETA: 2s - loss: 1.2277 - accuracy: 0.80 - ETA: 2s - loss: 1.1406 - accuracy: 0.82 - ETA: 2s - loss: 1.0783 - accuracy: 0.82 - ETA: 1s - loss: 1.2147 - accuracy: 0.83 - ETA: 1s - loss: 1.2594 - accuracy: 0.82 - ETA: 1s - loss: 1.2524 - accuracy: 0.81 - ETA: 1s - loss: 1.3155 - accuracy: 0.81 - ETA: 1s - loss: 1.2994 - accuracy: 0.80 - ETA: 1s - loss: 1.3177 - accuracy: 0.80 - ETA: 1s - loss: 1.3294 - accuracy: 0.79 - ETA: 1s - loss: 1.3118 - accuracy: 0.79 - ETA: 1s - loss: 1.2912 - accuracy: 0.79 - ETA: 1s - loss: 1.2891 - accuracy: 0.79 - ETA: 1s - loss: 1.3674 - accuracy: 0.78 - ETA: 0s - loss: 1.3663 - accuracy: 0.78 - ETA: 0s - loss: 1.4833 - accuracy: 0.78 - ETA: 0s - loss: 1.5325 - accuracy: 0.78 - ETA: 0s - loss: 1.5184 - accuracy: 0.78 - ETA: 0s - loss: 1.4928 - accuracy: 0.78 - ETA: 0s - loss: 1.5446 - accuracy: 0.78 - ETA: 0s - loss: 1.5404 - accuracy: 0.78 - ETA: 0s - loss: 1.5498 - accuracy: 0.78 - ETA: 0s - loss: 1.5896 - accuracy: 0.77 - ETA: 0s - loss: 1.5871 - accuracy: 0.77 - 4s 4ms/sample - loss: 1.6410 - accuracy: 0.7732 - val_loss: 19.5690 - val_accuracy: 0.0660\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 3s - loss: 0.7767 - accuracy: 0.81 - ETA: 2s - loss: 1.4472 - accuracy: 0.76 - ETA: 2s - loss: 1.3665 - accuracy: 0.72 - ETA: 2s - loss: 1.6896 - accuracy: 0.68 - ETA: 2s - loss: 1.7701 - accuracy: 0.65 - ETA: 2s - loss: 1.9929 - accuracy: 0.66 - ETA: 2s - loss: 2.0833 - accuracy: 0.63 - ETA: 2s - loss: 2.0944 - accuracy: 0.63 - ETA: 2s - loss: 2.1387 - accuracy: 0.62 - ETA: 2s - loss: 2.1615 - accuracy: 0.62 - ETA: 2s - loss: 2.3452 - accuracy: 0.61 - ETA: 2s - loss: 2.3071 - accuracy: 0.61 - ETA: 1s - loss: 2.2273 - accuracy: 0.62 - ETA: 1s - loss: 2.1524 - accuracy: 0.62 - ETA: 1s - loss: 2.0530 - accuracy: 0.63 - ETA: 1s - loss: 2.1039 - accuracy: 0.62 - ETA: 1s - loss: 2.1568 - accuracy: 0.61 - ETA: 1s - loss: 2.1613 - accuracy: 0.61 - ETA: 1s - loss: 2.1197 - accuracy: 0.61 - ETA: 1s - loss: 2.1222 - accuracy: 0.61 - ETA: 1s - loss: 2.0559 - accuracy: 0.62 - ETA: 1s - loss: 2.0462 - accuracy: 0.62 - ETA: 0s - loss: 2.0528 - accuracy: 0.62 - ETA: 0s - loss: 2.0175 - accuracy: 0.62 - ETA: 0s - loss: 2.0075 - accuracy: 0.63 - ETA: 0s - loss: 1.9782 - accuracy: 0.62 - ETA: 0s - loss: 1.9831 - accuracy: 0.62 - ETA: 0s - loss: 1.9597 - accuracy: 0.62 - ETA: 0s - loss: 1.9348 - accuracy: 0.63 - ETA: 0s - loss: 1.8940 - accuracy: 0.63 - ETA: 0s - loss: 1.8814 - accuracy: 0.63 - ETA: 0s - loss: 1.8685 - accuracy: 0.63 - 4s 4ms/sample - loss: 1.8494 - accuracy: 0.6354 - val_loss: 35.5446 - val_accuracy: 0.0621\n",
      "Epoch 27/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.6884 - accuracy: 0.81 - ETA: 3s - loss: 0.6708 - accuracy: 0.82 - ETA: 2s - loss: 0.5924 - accuracy: 0.82 - ETA: 2s - loss: 0.8989 - accuracy: 0.80 - ETA: 2s - loss: 0.8480 - accuracy: 0.81 - ETA: 2s - loss: 0.9414 - accuracy: 0.81 - ETA: 2s - loss: 0.8794 - accuracy: 0.82 - ETA: 2s - loss: 0.8273 - accuracy: 0.82 - ETA: 2s - loss: 0.7692 - accuracy: 0.84 - ETA: 2s - loss: 0.7169 - accuracy: 0.85 - ETA: 2s - loss: 0.7640 - accuracy: 0.84 - ETA: 2s - loss: 0.9249 - accuracy: 0.83 - ETA: 1s - loss: 0.8892 - accuracy: 0.84 - ETA: 1s - loss: 0.8837 - accuracy: 0.83 - ETA: 1s - loss: 0.9156 - accuracy: 0.83 - ETA: 1s - loss: 0.8940 - accuracy: 0.83 - ETA: 1s - loss: 0.8864 - accuracy: 0.83 - ETA: 1s - loss: 0.8729 - accuracy: 0.83 - ETA: 1s - loss: 0.8523 - accuracy: 0.83 - ETA: 1s - loss: 0.8363 - accuracy: 0.84 - ETA: 1s - loss: 0.8873 - accuracy: 0.83 - ETA: 1s - loss: 0.9172 - accuracy: 0.83 - ETA: 0s - loss: 0.9244 - accuracy: 0.83 - ETA: 0s - loss: 0.9156 - accuracy: 0.82 - ETA: 0s - loss: 0.9066 - accuracy: 0.82 - ETA: 0s - loss: 0.9123 - accuracy: 0.82 - ETA: 0s - loss: 0.9309 - accuracy: 0.82 - ETA: 0s - loss: 0.9355 - accuracy: 0.82 - ETA: 0s - loss: 0.9344 - accuracy: 0.82 - ETA: 0s - loss: 0.9370 - accuracy: 0.82 - ETA: 0s - loss: 0.9356 - accuracy: 0.82 - ETA: 0s - loss: 0.9247 - accuracy: 0.82 - 4s 3ms/sample - loss: 0.9271 - accuracy: 0.8211 - val_loss: 36.0201 - val_accuracy: 0.0913\n",
      "Epoch 28/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.8167 - accuracy: 0.84 - ETA: 3s - loss: 0.6537 - accuracy: 0.82 - ETA: 3s - loss: 0.6830 - accuracy: 0.82 - ETA: 2s - loss: 0.7278 - accuracy: 0.82 - ETA: 2s - loss: 1.1204 - accuracy: 0.81 - ETA: 2s - loss: 1.2458 - accuracy: 0.82 - ETA: 2s - loss: 1.6358 - accuracy: 0.81 - ETA: 2s - loss: 1.4993 - accuracy: 0.80 - ETA: 2s - loss: 1.3835 - accuracy: 0.80 - ETA: 2s - loss: 1.4348 - accuracy: 0.79 - ETA: 2s - loss: 1.4204 - accuracy: 0.78 - ETA: 2s - loss: 1.3319 - accuracy: 0.78 - ETA: 2s - loss: 1.3906 - accuracy: 0.78 - ETA: 1s - loss: 1.3667 - accuracy: 0.78 - ETA: 1s - loss: 1.3713 - accuracy: 0.78 - ETA: 1s - loss: 1.3637 - accuracy: 0.78 - ETA: 1s - loss: 1.4205 - accuracy: 0.77 - ETA: 1s - loss: 1.5047 - accuracy: 0.76 - ETA: 1s - loss: 1.6586 - accuracy: 0.75 - ETA: 1s - loss: 1.7656 - accuracy: 0.74 - ETA: 1s - loss: 1.8448 - accuracy: 0.73 - ETA: 1s - loss: 1.8621 - accuracy: 0.72 - ETA: 0s - loss: 1.8992 - accuracy: 0.71 - ETA: 0s - loss: 1.9257 - accuracy: 0.70 - ETA: 0s - loss: 1.9581 - accuracy: 0.70 - ETA: 0s - loss: 1.9656 - accuracy: 0.69 - ETA: 0s - loss: 2.0289 - accuracy: 0.68 - ETA: 0s - loss: 2.0293 - accuracy: 0.67 - ETA: 0s - loss: 2.0087 - accuracy: 0.67 - ETA: 0s - loss: 1.9936 - accuracy: 0.66 - ETA: 0s - loss: 2.0642 - accuracy: 0.65 - ETA: 0s - loss: 2.0687 - accuracy: 0.65 - 4s 4ms/sample - loss: 2.0691 - accuracy: 0.6507 - val_loss: 208.9444 - val_accuracy: 0.0641\n",
      "Epoch 29/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 3.0290 - accuracy: 0.59 - ETA: 3s - loss: 2.0030 - accuracy: 0.64 - ETA: 2s - loss: 1.7434 - accuracy: 0.65 - ETA: 2s - loss: 1.8293 - accuracy: 0.62 - ETA: 2s - loss: 1.6819 - accuracy: 0.63 - ETA: 2s - loss: 1.7153 - accuracy: 0.64 - ETA: 2s - loss: 1.6794 - accuracy: 0.62 - ETA: 2s - loss: 1.5721 - accuracy: 0.63 - ETA: 2s - loss: 1.5213 - accuracy: 0.63 - ETA: 2s - loss: 1.4290 - accuracy: 0.65 - ETA: 2s - loss: 1.4122 - accuracy: 0.66 - ETA: 2s - loss: 1.3973 - accuracy: 0.67 - ETA: 1s - loss: 1.3401 - accuracy: 0.67 - ETA: 1s - loss: 1.3135 - accuracy: 0.68 - ETA: 1s - loss: 1.2967 - accuracy: 0.68 - ETA: 1s - loss: 1.2812 - accuracy: 0.68 - ETA: 1s - loss: 1.2480 - accuracy: 0.69 - ETA: 1s - loss: 1.2234 - accuracy: 0.69 - ETA: 1s - loss: 1.2104 - accuracy: 0.70 - ETA: 1s - loss: 1.1788 - accuracy: 0.71 - ETA: 1s - loss: 1.1698 - accuracy: 0.70 - ETA: 1s - loss: 1.1409 - accuracy: 0.71 - ETA: 0s - loss: 1.1257 - accuracy: 0.71 - ETA: 0s - loss: 1.1164 - accuracy: 0.71 - ETA: 0s - loss: 1.1319 - accuracy: 0.71 - ETA: 0s - loss: 1.1101 - accuracy: 0.72 - ETA: 0s - loss: 1.0918 - accuracy: 0.72 - ETA: 0s - loss: 1.0647 - accuracy: 0.72 - ETA: 0s - loss: 1.0431 - accuracy: 0.73 - ETA: 0s - loss: 1.0474 - accuracy: 0.73 - ETA: 0s - loss: 1.0482 - accuracy: 0.73 - ETA: 0s - loss: 1.0283 - accuracy: 0.73 - 4s 4ms/sample - loss: 1.0346 - accuracy: 0.7340 - val_loss: 10.4062 - val_accuracy: 0.1126\n",
      "Epoch 30/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.9616 - accuracy: 0.81 - ETA: 2s - loss: 0.7588 - accuracy: 0.85 - ETA: 2s - loss: 0.5851 - accuracy: 0.87 - ETA: 2s - loss: 0.6038 - accuracy: 0.85 - ETA: 2s - loss: 0.6105 - accuracy: 0.83 - ETA: 2s - loss: 0.5425 - accuracy: 0.84 - ETA: 2s - loss: 0.5093 - accuracy: 0.85 - ETA: 2s - loss: 0.5099 - accuracy: 0.85 - ETA: 2s - loss: 0.5322 - accuracy: 0.84 - ETA: 2s - loss: 0.5118 - accuracy: 0.85 - ETA: 2s - loss: 0.5143 - accuracy: 0.84 - ETA: 2s - loss: 0.5555 - accuracy: 0.84 - ETA: 1s - loss: 0.5455 - accuracy: 0.85 - ETA: 1s - loss: 0.5334 - accuracy: 0.85 - ETA: 1s - loss: 0.5347 - accuracy: 0.85 - ETA: 1s - loss: 0.5304 - accuracy: 0.85 - ETA: 1s - loss: 0.5139 - accuracy: 0.85 - ETA: 1s - loss: 0.5023 - accuracy: 0.85 - ETA: 1s - loss: 0.5338 - accuracy: 0.86 - ETA: 1s - loss: 0.5264 - accuracy: 0.86 - ETA: 1s - loss: 0.5635 - accuracy: 0.86 - ETA: 1s - loss: 0.5684 - accuracy: 0.86 - ETA: 0s - loss: 0.5556 - accuracy: 0.86 - ETA: 0s - loss: 0.5474 - accuracy: 0.86 - ETA: 0s - loss: 0.5351 - accuracy: 0.87 - ETA: 0s - loss: 0.5260 - accuracy: 0.87 - ETA: 0s - loss: 0.5119 - accuracy: 0.87 - ETA: 0s - loss: 0.5205 - accuracy: 0.87 - ETA: 0s - loss: 0.5491 - accuracy: 0.87 - ETA: 0s - loss: 0.5453 - accuracy: 0.87 - ETA: 0s - loss: 0.5925 - accuracy: 0.87 - ETA: 0s - loss: 0.5965 - accuracy: 0.87 - 4s 3ms/sample - loss: 0.5903 - accuracy: 0.8718 - val_loss: 8.6004 - val_accuracy: 0.1476\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 3s - loss: 1.6413 - accuracy: 0.93 - ETA: 3s - loss: 1.8173 - accuracy: 0.93 - ETA: 2s - loss: 1.7586 - accuracy: 0.91 - ETA: 2s - loss: 1.3658 - accuracy: 0.92 - ETA: 2s - loss: 1.2943 - accuracy: 0.91 - ETA: 2s - loss: 1.1995 - accuracy: 0.90 - ETA: 2s - loss: 1.0578 - accuracy: 0.89 - ETA: 2s - loss: 0.9596 - accuracy: 0.90 - ETA: 2s - loss: 0.8804 - accuracy: 0.90 - ETA: 2s - loss: 0.8308 - accuracy: 0.90 - ETA: 2s - loss: 0.7732 - accuracy: 0.91 - ETA: 2s - loss: 0.7168 - accuracy: 0.91 - ETA: 1s - loss: 0.7445 - accuracy: 0.92 - ETA: 1s - loss: 0.7326 - accuracy: 0.91 - ETA: 1s - loss: 0.7272 - accuracy: 0.91 - ETA: 1s - loss: 0.6888 - accuracy: 0.92 - ETA: 1s - loss: 0.6621 - accuracy: 0.92 - ETA: 1s - loss: 0.6398 - accuracy: 0.92 - ETA: 1s - loss: 0.6490 - accuracy: 0.92 - ETA: 1s - loss: 0.6713 - accuracy: 0.92 - ETA: 1s - loss: 0.6619 - accuracy: 0.91 - ETA: 1s - loss: 0.6394 - accuracy: 0.91 - ETA: 0s - loss: 0.6154 - accuracy: 0.92 - ETA: 0s - loss: 0.6065 - accuracy: 0.91 - ETA: 0s - loss: 0.5880 - accuracy: 0.92 - ETA: 0s - loss: 0.5747 - accuracy: 0.91 - ETA: 0s - loss: 0.5626 - accuracy: 0.92 - ETA: 0s - loss: 0.5472 - accuracy: 0.92 - ETA: 0s - loss: 0.5349 - accuracy: 0.92 - ETA: 0s - loss: 0.5236 - accuracy: 0.92 - ETA: 0s - loss: 0.5198 - accuracy: 0.91 - ETA: 0s - loss: 0.5236 - accuracy: 0.91 - 4s 3ms/sample - loss: 0.5341 - accuracy: 0.9158 - val_loss: 6.8032 - val_accuracy: 0.2117\n",
      "Epoch 32/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.2848 - accuracy: 0.90 - ETA: 2s - loss: 0.2018 - accuracy: 0.93 - ETA: 2s - loss: 0.2260 - accuracy: 0.93 - ETA: 2s - loss: 0.2638 - accuracy: 0.90 - ETA: 2s - loss: 0.2999 - accuracy: 0.90 - ETA: 2s - loss: 0.2810 - accuracy: 0.91 - ETA: 2s - loss: 0.2505 - accuracy: 0.92 - ETA: 2s - loss: 0.2391 - accuracy: 0.92 - ETA: 2s - loss: 0.2505 - accuracy: 0.93 - ETA: 2s - loss: 0.3544 - accuracy: 0.92 - ETA: 2s - loss: 0.4098 - accuracy: 0.92 - ETA: 2s - loss: 0.4051 - accuracy: 0.92 - ETA: 1s - loss: 0.3849 - accuracy: 0.92 - ETA: 1s - loss: 0.3632 - accuracy: 0.92 - ETA: 1s - loss: 0.3624 - accuracy: 0.92 - ETA: 1s - loss: 0.3799 - accuracy: 0.91 - ETA: 1s - loss: 0.4780 - accuracy: 0.91 - ETA: 1s - loss: 0.4597 - accuracy: 0.91 - ETA: 1s - loss: 0.4482 - accuracy: 0.91 - ETA: 1s - loss: 0.4431 - accuracy: 0.91 - ETA: 1s - loss: 0.4273 - accuracy: 0.91 - ETA: 1s - loss: 0.4114 - accuracy: 0.91 - ETA: 0s - loss: 0.3982 - accuracy: 0.91 - ETA: 0s - loss: 0.3924 - accuracy: 0.91 - ETA: 0s - loss: 0.4068 - accuracy: 0.91 - ETA: 0s - loss: 0.3986 - accuracy: 0.91 - ETA: 0s - loss: 0.3890 - accuracy: 0.91 - ETA: 0s - loss: 0.3826 - accuracy: 0.91 - ETA: 0s - loss: 0.3740 - accuracy: 0.92 - ETA: 0s - loss: 0.3762 - accuracy: 0.92 - ETA: 0s - loss: 0.3704 - accuracy: 0.92 - ETA: 0s - loss: 0.3674 - accuracy: 0.92 - 4s 3ms/sample - loss: 0.3619 - accuracy: 0.9234 - val_loss: 6.3490 - val_accuracy: 0.2854\n",
      "Epoch 33/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.3435 - accuracy: 0.87 - ETA: 2s - loss: 0.1923 - accuracy: 0.93 - ETA: 2s - loss: 0.1434 - accuracy: 0.95 - ETA: 2s - loss: 0.1539 - accuracy: 0.95 - ETA: 2s - loss: 0.1489 - accuracy: 0.95 - ETA: 2s - loss: 0.1714 - accuracy: 0.95 - ETA: 2s - loss: 0.1748 - accuracy: 0.94 - ETA: 2s - loss: 0.2624 - accuracy: 0.92 - ETA: 2s - loss: 0.2452 - accuracy: 0.93 - ETA: 2s - loss: 0.2388 - accuracy: 0.93 - ETA: 2s - loss: 0.2201 - accuracy: 0.93 - ETA: 2s - loss: 0.2092 - accuracy: 0.93 - ETA: 1s - loss: 0.2045 - accuracy: 0.93 - ETA: 1s - loss: 0.2067 - accuracy: 0.93 - ETA: 1s - loss: 0.2000 - accuracy: 0.93 - ETA: 1s - loss: 0.1976 - accuracy: 0.93 - ETA: 1s - loss: 0.2023 - accuracy: 0.93 - ETA: 1s - loss: 0.2118 - accuracy: 0.93 - ETA: 1s - loss: 0.2035 - accuracy: 0.94 - ETA: 1s - loss: 0.2010 - accuracy: 0.94 - ETA: 1s - loss: 0.1969 - accuracy: 0.94 - ETA: 1s - loss: 0.1896 - accuracy: 0.94 - ETA: 0s - loss: 0.1914 - accuracy: 0.94 - ETA: 0s - loss: 0.1947 - accuracy: 0.94 - ETA: 0s - loss: 0.2214 - accuracy: 0.93 - ETA: 0s - loss: 0.2307 - accuracy: 0.93 - ETA: 0s - loss: 0.2408 - accuracy: 0.93 - ETA: 0s - loss: 0.2356 - accuracy: 0.93 - ETA: 0s - loss: 0.2293 - accuracy: 0.93 - ETA: 0s - loss: 0.2250 - accuracy: 0.93 - ETA: 0s - loss: 0.2180 - accuracy: 0.94 - ETA: 0s - loss: 0.2145 - accuracy: 0.94 - 4s 3ms/sample - loss: 0.2105 - accuracy: 0.9426 - val_loss: 3.0322 - val_accuracy: 0.5049\n",
      "Epoch 34/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.2800 - accuracy: 0.90 - ETA: 2s - loss: 0.3256 - accuracy: 0.87 - ETA: 2s - loss: 0.2326 - accuracy: 0.91 - ETA: 2s - loss: 0.2691 - accuracy: 0.90 - ETA: 2s - loss: 0.2409 - accuracy: 0.91 - ETA: 2s - loss: 0.2257 - accuracy: 0.92 - ETA: 2s - loss: 0.2045 - accuracy: 0.92 - ETA: 2s - loss: 0.1883 - accuracy: 0.93 - ETA: 2s - loss: 0.2906 - accuracy: 0.94 - ETA: 2s - loss: 0.2675 - accuracy: 0.94 - ETA: 2s - loss: 0.3183 - accuracy: 0.94 - ETA: 1s - loss: 0.4377 - accuracy: 0.91 - ETA: 1s - loss: 0.4921 - accuracy: 0.90 - ETA: 1s - loss: 0.5334 - accuracy: 0.88 - ETA: 1s - loss: 0.5458 - accuracy: 0.88 - ETA: 1s - loss: 0.5442 - accuracy: 0.87 - ETA: 1s - loss: 0.5450 - accuracy: 0.87 - ETA: 1s - loss: 0.5588 - accuracy: 0.87 - ETA: 1s - loss: 0.5798 - accuracy: 0.87 - ETA: 1s - loss: 0.6109 - accuracy: 0.86 - ETA: 1s - loss: 0.7007 - accuracy: 0.85 - ETA: 1s - loss: 0.7178 - accuracy: 0.84 - ETA: 0s - loss: 0.7033 - accuracy: 0.84 - ETA: 0s - loss: 0.7086 - accuracy: 0.84 - ETA: 0s - loss: 0.6957 - accuracy: 0.84 - ETA: 0s - loss: 0.6814 - accuracy: 0.84 - ETA: 0s - loss: 0.6886 - accuracy: 0.83 - ETA: 0s - loss: 0.6779 - accuracy: 0.84 - ETA: 0s - loss: 0.6601 - accuracy: 0.84 - ETA: 0s - loss: 0.6452 - accuracy: 0.84 - ETA: 0s - loss: 0.6297 - accuracy: 0.85 - ETA: 0s - loss: 0.6194 - accuracy: 0.85 - 4s 3ms/sample - loss: 0.6143 - accuracy: 0.8517 - val_loss: 91.5607 - val_accuracy: 0.0796\n",
      "Epoch 35/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.4633 - accuracy: 0.81 - ETA: 3s - loss: 0.7310 - accuracy: 0.76 - ETA: 2s - loss: 0.5833 - accuracy: 0.80 - ETA: 2s - loss: 0.4955 - accuracy: 0.82 - ETA: 2s - loss: 0.4892 - accuracy: 0.83 - ETA: 2s - loss: 0.4595 - accuracy: 0.84 - ETA: 2s - loss: 0.4498 - accuracy: 0.85 - ETA: 2s - loss: 0.4095 - accuracy: 0.86 - ETA: 2s - loss: 0.6047 - accuracy: 0.86 - ETA: 2s - loss: 0.5678 - accuracy: 0.87 - ETA: 2s - loss: 0.5781 - accuracy: 0.86 - ETA: 2s - loss: 0.5639 - accuracy: 0.86 - ETA: 1s - loss: 0.5678 - accuracy: 0.86 - ETA: 1s - loss: 0.5802 - accuracy: 0.85 - ETA: 1s - loss: 0.5662 - accuracy: 0.85 - ETA: 1s - loss: 0.5766 - accuracy: 0.85 - ETA: 1s - loss: 0.5551 - accuracy: 0.86 - ETA: 1s - loss: 0.5860 - accuracy: 0.86 - ETA: 1s - loss: 0.5784 - accuracy: 0.86 - ETA: 1s - loss: 0.5644 - accuracy: 0.86 - ETA: 1s - loss: 0.5799 - accuracy: 0.86 - ETA: 1s - loss: 0.5696 - accuracy: 0.86 - ETA: 0s - loss: 0.6375 - accuracy: 0.86 - ETA: 0s - loss: 0.6414 - accuracy: 0.86 - ETA: 0s - loss: 0.6609 - accuracy: 0.86 - ETA: 0s - loss: 0.7072 - accuracy: 0.87 - ETA: 0s - loss: 0.7118 - accuracy: 0.86 - ETA: 0s - loss: 0.7093 - accuracy: 0.86 - ETA: 0s - loss: 0.7039 - accuracy: 0.86 - ETA: 0s - loss: 0.6993 - accuracy: 0.86 - ETA: 0s - loss: 0.6914 - accuracy: 0.86 - ETA: 0s - loss: 0.6878 - accuracy: 0.86 - 4s 3ms/sample - loss: 0.7357 - accuracy: 0.8632 - val_loss: 25.6013 - val_accuracy: 0.2427\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0892 - accuracy: 1.00 - ETA: 3s - loss: 0.6477 - accuracy: 0.92 - ETA: 2s - loss: 0.4837 - accuracy: 0.92 - ETA: 2s - loss: 0.5075 - accuracy: 0.90 - ETA: 2s - loss: 0.4548 - accuracy: 0.91 - ETA: 2s - loss: 0.4317 - accuracy: 0.91 - ETA: 2s - loss: 0.4241 - accuracy: 0.91 - ETA: 2s - loss: 0.4276 - accuracy: 0.90 - ETA: 2s - loss: 0.4063 - accuracy: 0.90 - ETA: 2s - loss: 0.4004 - accuracy: 0.90 - ETA: 2s - loss: 0.3874 - accuracy: 0.90 - ETA: 2s - loss: 0.3635 - accuracy: 0.90 - ETA: 1s - loss: 0.4642 - accuracy: 0.90 - ETA: 1s - loss: 0.4734 - accuracy: 0.90 - ETA: 1s - loss: 0.4609 - accuracy: 0.90 - ETA: 1s - loss: 0.4513 - accuracy: 0.90 - ETA: 1s - loss: 0.4341 - accuracy: 0.90 - ETA: 1s - loss: 0.4629 - accuracy: 0.90 - ETA: 1s - loss: 0.4512 - accuracy: 0.90 - ETA: 1s - loss: 0.4796 - accuracy: 0.89 - ETA: 1s - loss: 0.4696 - accuracy: 0.89 - ETA: 1s - loss: 0.4530 - accuracy: 0.89 - ETA: 0s - loss: 0.4760 - accuracy: 0.90 - ETA: 0s - loss: 0.4636 - accuracy: 0.90 - ETA: 0s - loss: 0.4668 - accuracy: 0.90 - ETA: 0s - loss: 0.4631 - accuracy: 0.90 - ETA: 0s - loss: 0.4543 - accuracy: 0.90 - ETA: 0s - loss: 0.4431 - accuracy: 0.90 - ETA: 0s - loss: 0.4287 - accuracy: 0.90 - ETA: 0s - loss: 0.4268 - accuracy: 0.90 - ETA: 0s - loss: 0.4190 - accuracy: 0.90 - ETA: 0s - loss: 0.4160 - accuracy: 0.90 - 4s 3ms/sample - loss: 0.4083 - accuracy: 0.9091 - val_loss: 1.4434 - val_accuracy: 0.6583\n",
      "Epoch 37/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.1725 - accuracy: 0.96 - ETA: 2s - loss: 0.1113 - accuracy: 0.98 - ETA: 2s - loss: 0.1398 - accuracy: 0.97 - ETA: 2s - loss: 0.1896 - accuracy: 0.96 - ETA: 2s - loss: 0.1793 - accuracy: 0.96 - ETA: 2s - loss: 0.1538 - accuracy: 0.97 - ETA: 2s - loss: 0.1493 - accuracy: 0.97 - ETA: 2s - loss: 0.1483 - accuracy: 0.96 - ETA: 2s - loss: 0.1422 - accuracy: 0.96 - ETA: 2s - loss: 0.1524 - accuracy: 0.96 - ETA: 2s - loss: 0.1510 - accuracy: 0.96 - ETA: 2s - loss: 0.1391 - accuracy: 0.96 - ETA: 1s - loss: 0.1311 - accuracy: 0.96 - ETA: 1s - loss: 0.1248 - accuracy: 0.96 - ETA: 1s - loss: 0.1246 - accuracy: 0.96 - ETA: 1s - loss: 0.1383 - accuracy: 0.96 - ETA: 1s - loss: 0.1337 - accuracy: 0.96 - ETA: 1s - loss: 0.1308 - accuracy: 0.96 - ETA: 1s - loss: 0.1257 - accuracy: 0.97 - ETA: 1s - loss: 0.1226 - accuracy: 0.97 - ETA: 1s - loss: 0.1236 - accuracy: 0.96 - ETA: 1s - loss: 0.1241 - accuracy: 0.96 - ETA: 0s - loss: 0.1377 - accuracy: 0.96 - ETA: 0s - loss: 0.1370 - accuracy: 0.96 - ETA: 0s - loss: 0.1456 - accuracy: 0.95 - ETA: 0s - loss: 0.1483 - accuracy: 0.95 - ETA: 0s - loss: 0.1437 - accuracy: 0.96 - ETA: 0s - loss: 0.1387 - accuracy: 0.96 - ETA: 0s - loss: 0.1345 - accuracy: 0.96 - ETA: 0s - loss: 0.1342 - accuracy: 0.96 - ETA: 0s - loss: 0.1318 - accuracy: 0.96 - ETA: 0s - loss: 0.1323 - accuracy: 0.96 - 4s 4ms/sample - loss: 0.1323 - accuracy: 0.9617 - val_loss: 0.7217 - val_accuracy: 0.8330\n",
      "Epoch 38/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.3221 - accuracy: 0.93 - ETA: 2s - loss: 0.1780 - accuracy: 0.96 - ETA: 2s - loss: 0.1665 - accuracy: 0.96 - ETA: 2s - loss: 0.1497 - accuracy: 0.96 - ETA: 2s - loss: 0.1755 - accuracy: 0.96 - ETA: 2s - loss: 0.2493 - accuracy: 0.95 - ETA: 2s - loss: 0.2287 - accuracy: 0.95 - ETA: 2s - loss: 0.2010 - accuracy: 0.96 - ETA: 2s - loss: 0.1796 - accuracy: 0.96 - ETA: 2s - loss: 0.1687 - accuracy: 0.96 - ETA: 2s - loss: 0.1922 - accuracy: 0.96 - ETA: 2s - loss: 0.1835 - accuracy: 0.96 - ETA: 1s - loss: 0.1815 - accuracy: 0.96 - ETA: 1s - loss: 0.1704 - accuracy: 0.96 - ETA: 1s - loss: 0.1920 - accuracy: 0.96 - ETA: 1s - loss: 0.1915 - accuracy: 0.96 - ETA: 1s - loss: 0.1821 - accuracy: 0.96 - ETA: 1s - loss: 0.1956 - accuracy: 0.96 - ETA: 1s - loss: 0.1895 - accuracy: 0.96 - ETA: 1s - loss: 0.1860 - accuracy: 0.96 - ETA: 1s - loss: 0.1807 - accuracy: 0.96 - ETA: 1s - loss: 0.1786 - accuracy: 0.96 - ETA: 0s - loss: 0.1803 - accuracy: 0.95 - ETA: 0s - loss: 0.1749 - accuracy: 0.96 - ETA: 0s - loss: 0.1681 - accuracy: 0.96 - ETA: 0s - loss: 0.1629 - accuracy: 0.96 - ETA: 0s - loss: 0.1597 - accuracy: 0.96 - ETA: 0s - loss: 0.1546 - accuracy: 0.96 - ETA: 0s - loss: 0.1524 - accuracy: 0.96 - ETA: 0s - loss: 0.1604 - accuracy: 0.96 - ETA: 0s - loss: 0.1555 - accuracy: 0.96 - ETA: 0s - loss: 0.1549 - accuracy: 0.96 - 4s 3ms/sample - loss: 0.1527 - accuracy: 0.9646 - val_loss: 0.8180 - val_accuracy: 0.8058\n",
      "Epoch 39/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.1989 - accuracy: 0.90 - ETA: 2s - loss: 0.1110 - accuracy: 0.95 - ETA: 2s - loss: 0.1442 - accuracy: 0.95 - ETA: 2s - loss: 0.1201 - accuracy: 0.96 - ETA: 2s - loss: 0.1274 - accuracy: 0.96 - ETA: 2s - loss: 0.1282 - accuracy: 0.96 - ETA: 2s - loss: 0.1275 - accuracy: 0.96 - ETA: 2s - loss: 0.1164 - accuracy: 0.96 - ETA: 2s - loss: 0.1120 - accuracy: 0.97 - ETA: 2s - loss: 0.1209 - accuracy: 0.96 - ETA: 2s - loss: 0.1152 - accuracy: 0.97 - ETA: 1s - loss: 0.1159 - accuracy: 0.97 - ETA: 1s - loss: 0.1101 - accuracy: 0.97 - ETA: 1s - loss: 0.1026 - accuracy: 0.97 - ETA: 1s - loss: 0.0974 - accuracy: 0.97 - ETA: 1s - loss: 0.1273 - accuracy: 0.97 - ETA: 1s - loss: 0.1200 - accuracy: 0.97 - ETA: 1s - loss: 0.1150 - accuracy: 0.97 - ETA: 1s - loss: 0.1156 - accuracy: 0.97 - ETA: 1s - loss: 0.1146 - accuracy: 0.97 - ETA: 1s - loss: 0.1140 - accuracy: 0.97 - ETA: 1s - loss: 0.1248 - accuracy: 0.97 - ETA: 0s - loss: 0.1344 - accuracy: 0.97 - ETA: 0s - loss: 0.1302 - accuracy: 0.97 - ETA: 0s - loss: 0.1277 - accuracy: 0.97 - ETA: 0s - loss: 0.1249 - accuracy: 0.97 - ETA: 0s - loss: 0.1244 - accuracy: 0.96 - ETA: 0s - loss: 0.1209 - accuracy: 0.97 - ETA: 0s - loss: 0.1169 - accuracy: 0.97 - ETA: 0s - loss: 0.1151 - accuracy: 0.97 - ETA: 0s - loss: 0.1187 - accuracy: 0.96 - ETA: 0s - loss: 0.1194 - accuracy: 0.96 - 4s 3ms/sample - loss: 0.1202 - accuracy: 0.9694 - val_loss: 0.6331 - val_accuracy: 0.8291\n",
      "Epoch 40/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.1485 - accuracy: 0.93 - ETA: 3s - loss: 0.0876 - accuracy: 0.96 - ETA: 2s - loss: 0.0609 - accuracy: 0.97 - ETA: 2s - loss: 0.3609 - accuracy: 0.96 - ETA: 2s - loss: 0.3861 - accuracy: 0.95 - ETA: 2s - loss: 0.4550 - accuracy: 0.95 - ETA: 2s - loss: 0.4267 - accuracy: 0.95 - ETA: 2s - loss: 0.3760 - accuracy: 0.96 - ETA: 2s - loss: 0.3423 - accuracy: 0.96 - ETA: 2s - loss: 0.3306 - accuracy: 0.96 - ETA: 2s - loss: 0.3699 - accuracy: 0.95 - ETA: 2s - loss: 0.3414 - accuracy: 0.96 - ETA: 1s - loss: 0.3250 - accuracy: 0.95 - ETA: 1s - loss: 0.3134 - accuracy: 0.95 - ETA: 1s - loss: 0.3684 - accuracy: 0.95 - ETA: 1s - loss: 0.3658 - accuracy: 0.94 - ETA: 1s - loss: 0.3630 - accuracy: 0.94 - ETA: 1s - loss: 0.3484 - accuracy: 0.94 - ETA: 1s - loss: 0.3857 - accuracy: 0.94 - ETA: 1s - loss: 0.3783 - accuracy: 0.94 - ETA: 1s - loss: 0.3845 - accuracy: 0.93 - ETA: 1s - loss: 0.4079 - accuracy: 0.93 - ETA: 0s - loss: 0.4039 - accuracy: 0.93 - ETA: 0s - loss: 0.4034 - accuracy: 0.92 - ETA: 0s - loss: 0.4164 - accuracy: 0.92 - ETA: 0s - loss: 0.4073 - accuracy: 0.92 - ETA: 0s - loss: 0.4017 - accuracy: 0.92 - ETA: 0s - loss: 0.4741 - accuracy: 0.91 - ETA: 0s - loss: 0.4768 - accuracy: 0.91 - ETA: 0s - loss: 0.4648 - accuracy: 0.91 - ETA: 0s - loss: 0.4585 - accuracy: 0.91 - ETA: 0s - loss: 0.4525 - accuracy: 0.91 - 4s 3ms/sample - loss: 0.4724 - accuracy: 0.9072 - val_loss: 9.8629 - val_accuracy: 0.3534\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 3s - loss: 0.3028 - accuracy: 0.84 - ETA: 2s - loss: 0.1742 - accuracy: 0.92 - ETA: 2s - loss: 0.2580 - accuracy: 0.90 - ETA: 2s - loss: 0.2914 - accuracy: 0.90 - ETA: 2s - loss: 0.2655 - accuracy: 0.90 - ETA: 2s - loss: 0.6480 - accuracy: 0.89 - ETA: 2s - loss: 0.5853 - accuracy: 0.90 - ETA: 2s - loss: 0.5659 - accuracy: 0.90 - ETA: 2s - loss: 0.5512 - accuracy: 0.90 - ETA: 2s - loss: 0.5669 - accuracy: 0.89 - ETA: 2s - loss: 0.5324 - accuracy: 0.89 - ETA: 2s - loss: 0.5064 - accuracy: 0.89 - ETA: 1s - loss: 0.4803 - accuracy: 0.90 - ETA: 1s - loss: 0.4613 - accuracy: 0.90 - ETA: 1s - loss: 0.4877 - accuracy: 0.90 - ETA: 1s - loss: 0.4641 - accuracy: 0.90 - ETA: 1s - loss: 0.4577 - accuracy: 0.90 - ETA: 1s - loss: 0.4407 - accuracy: 0.90 - ETA: 1s - loss: 0.4193 - accuracy: 0.91 - ETA: 1s - loss: 0.4009 - accuracy: 0.91 - ETA: 1s - loss: 0.3883 - accuracy: 0.91 - ETA: 1s - loss: 0.3755 - accuracy: 0.91 - ETA: 0s - loss: 0.3641 - accuracy: 0.91 - ETA: 0s - loss: 0.3566 - accuracy: 0.91 - ETA: 0s - loss: 0.4917 - accuracy: 0.91 - ETA: 0s - loss: 0.4746 - accuracy: 0.92 - ETA: 0s - loss: 0.4639 - accuracy: 0.92 - ETA: 0s - loss: 0.5979 - accuracy: 0.92 - ETA: 0s - loss: 0.5808 - accuracy: 0.92 - ETA: 0s - loss: 0.5649 - accuracy: 0.92 - ETA: 0s - loss: 0.5483 - accuracy: 0.92 - ETA: 0s - loss: 0.5338 - accuracy: 0.92 - 4s 3ms/sample - loss: 0.5450 - accuracy: 0.9282 - val_loss: 3.3026 - val_accuracy: 0.5495\n",
      "Epoch 42/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.8119 - accuracy: 0.87 - ETA: 3s - loss: 0.4420 - accuracy: 0.92 - ETA: 2s - loss: 0.5247 - accuracy: 0.93 - ETA: 2s - loss: 0.4386 - accuracy: 0.93 - ETA: 2s - loss: 0.3728 - accuracy: 0.94 - ETA: 2s - loss: 0.3260 - accuracy: 0.94 - ETA: 2s - loss: 0.3173 - accuracy: 0.95 - ETA: 2s - loss: 0.3643 - accuracy: 0.94 - ETA: 2s - loss: 0.3439 - accuracy: 0.94 - ETA: 2s - loss: 0.3938 - accuracy: 0.93 - ETA: 2s - loss: 0.3830 - accuracy: 0.93 - ETA: 2s - loss: 0.3658 - accuracy: 0.93 - ETA: 1s - loss: 0.3857 - accuracy: 0.92 - ETA: 1s - loss: 0.4118 - accuracy: 0.92 - ETA: 1s - loss: 0.3940 - accuracy: 0.92 - ETA: 1s - loss: 0.3767 - accuracy: 0.92 - ETA: 1s - loss: 0.3626 - accuracy: 0.92 - ETA: 1s - loss: 0.3521 - accuracy: 0.92 - ETA: 1s - loss: 0.3423 - accuracy: 0.92 - ETA: 1s - loss: 0.3310 - accuracy: 0.92 - ETA: 1s - loss: 0.3520 - accuracy: 0.92 - ETA: 1s - loss: 0.3432 - accuracy: 0.92 - ETA: 0s - loss: 0.3298 - accuracy: 0.93 - ETA: 0s - loss: 0.3171 - accuracy: 0.93 - ETA: 0s - loss: 0.3081 - accuracy: 0.93 - ETA: 0s - loss: 0.3123 - accuracy: 0.93 - ETA: 0s - loss: 0.3054 - accuracy: 0.93 - ETA: 0s - loss: 0.3076 - accuracy: 0.93 - ETA: 0s - loss: 0.3116 - accuracy: 0.93 - ETA: 0s - loss: 0.3068 - accuracy: 0.93 - ETA: 0s - loss: 0.3338 - accuracy: 0.92 - ETA: 0s - loss: 0.3416 - accuracy: 0.92 - 4s 3ms/sample - loss: 0.3397 - accuracy: 0.9273 - val_loss: 2.1791 - val_accuracy: 0.5553\n",
      "Epoch 43/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.2626 - accuracy: 0.87 - ETA: 2s - loss: 0.1906 - accuracy: 0.90 - ETA: 2s - loss: 0.3121 - accuracy: 0.87 - ETA: 2s - loss: 0.2442 - accuracy: 0.89 - ETA: 2s - loss: 0.1994 - accuracy: 0.91 - ETA: 2s - loss: 0.2134 - accuracy: 0.92 - ETA: 2s - loss: 0.3125 - accuracy: 0.91 - ETA: 2s - loss: 0.3276 - accuracy: 0.92 - ETA: 2s - loss: 0.2971 - accuracy: 0.93 - ETA: 2s - loss: 0.3416 - accuracy: 0.93 - ETA: 2s - loss: 0.3407 - accuracy: 0.92 - ETA: 2s - loss: 0.3250 - accuracy: 0.92 - ETA: 1s - loss: 0.4502 - accuracy: 0.92 - ETA: 1s - loss: 0.4812 - accuracy: 0.92 - ETA: 1s - loss: 0.4624 - accuracy: 0.92 - ETA: 1s - loss: 0.4420 - accuracy: 0.92 - ETA: 1s - loss: 0.4456 - accuracy: 0.92 - ETA: 1s - loss: 0.4254 - accuracy: 0.92 - ETA: 1s - loss: 0.4123 - accuracy: 0.92 - ETA: 1s - loss: 0.4006 - accuracy: 0.92 - ETA: 1s - loss: 0.4041 - accuracy: 0.92 - ETA: 1s - loss: 0.3963 - accuracy: 0.92 - ETA: 0s - loss: 0.5461 - accuracy: 0.91 - ETA: 0s - loss: 0.5338 - accuracy: 0.92 - ETA: 0s - loss: 0.5344 - accuracy: 0.91 - ETA: 0s - loss: 0.5168 - accuracy: 0.92 - ETA: 0s - loss: 0.5340 - accuracy: 0.91 - ETA: 0s - loss: 0.5414 - accuracy: 0.91 - ETA: 0s - loss: 0.5282 - accuracy: 0.91 - ETA: 0s - loss: 0.5191 - accuracy: 0.91 - ETA: 0s - loss: 0.5230 - accuracy: 0.91 - ETA: 0s - loss: 0.5088 - accuracy: 0.91 - 4s 3ms/sample - loss: 0.5014 - accuracy: 0.9206 - val_loss: 1.6628 - val_accuracy: 0.5825\n",
      "Epoch 44/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0854 - accuracy: 0.93 - ETA: 2s - loss: 0.0543 - accuracy: 0.96 - ETA: 2s - loss: 0.0715 - accuracy: 0.96 - ETA: 2s - loss: 0.1935 - accuracy: 0.95 - ETA: 2s - loss: 0.1635 - accuracy: 0.96 - ETA: 2s - loss: 0.1672 - accuracy: 0.96 - ETA: 2s - loss: 0.2008 - accuracy: 0.95 - ETA: 2s - loss: 0.1936 - accuracy: 0.95 - ETA: 2s - loss: 0.1801 - accuracy: 0.95 - ETA: 2s - loss: 0.1800 - accuracy: 0.95 - ETA: 2s - loss: 0.2178 - accuracy: 0.94 - ETA: 1s - loss: 0.2146 - accuracy: 0.94 - ETA: 1s - loss: 0.2143 - accuracy: 0.94 - ETA: 1s - loss: 0.2035 - accuracy: 0.94 - ETA: 1s - loss: 0.1940 - accuracy: 0.94 - ETA: 1s - loss: 0.1861 - accuracy: 0.94 - ETA: 1s - loss: 0.1947 - accuracy: 0.94 - ETA: 1s - loss: 0.1881 - accuracy: 0.94 - ETA: 1s - loss: 0.1907 - accuracy: 0.94 - ETA: 1s - loss: 0.1861 - accuracy: 0.94 - ETA: 1s - loss: 0.1778 - accuracy: 0.95 - ETA: 1s - loss: 0.1711 - accuracy: 0.95 - ETA: 0s - loss: 0.1663 - accuracy: 0.95 - ETA: 0s - loss: 0.1619 - accuracy: 0.95 - ETA: 0s - loss: 0.1562 - accuracy: 0.95 - ETA: 0s - loss: 0.1536 - accuracy: 0.95 - ETA: 0s - loss: 0.1491 - accuracy: 0.95 - ETA: 0s - loss: 0.1445 - accuracy: 0.95 - ETA: 0s - loss: 0.1412 - accuracy: 0.95 - ETA: 0s - loss: 0.1392 - accuracy: 0.95 - ETA: 0s - loss: 0.1351 - accuracy: 0.96 - ETA: 0s - loss: 0.1314 - accuracy: 0.96 - 4s 3ms/sample - loss: 0.1291 - accuracy: 0.9627 - val_loss: 1.3016 - val_accuracy: 0.7340\n",
      "Epoch 45/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.1385 - accuracy: 0.96 - ETA: 2s - loss: 0.0882 - accuracy: 0.96 - ETA: 2s - loss: 0.0784 - accuracy: 0.96 - ETA: 2s - loss: 0.0653 - accuracy: 0.97 - ETA: 2s - loss: 0.0570 - accuracy: 0.98 - ETA: 2s - loss: 0.0497 - accuracy: 0.98 - ETA: 2s - loss: 0.0656 - accuracy: 0.98 - ETA: 2s - loss: 0.0741 - accuracy: 0.97 - ETA: 2s - loss: 0.0932 - accuracy: 0.96 - ETA: 2s - loss: 0.0862 - accuracy: 0.96 - ETA: 2s - loss: 0.0791 - accuracy: 0.97 - ETA: 2s - loss: 0.0737 - accuracy: 0.97 - ETA: 1s - loss: 0.0734 - accuracy: 0.97 - ETA: 1s - loss: 0.0747 - accuracy: 0.97 - ETA: 1s - loss: 0.0724 - accuracy: 0.97 - ETA: 1s - loss: 0.0733 - accuracy: 0.97 - ETA: 1s - loss: 0.0768 - accuracy: 0.97 - ETA: 1s - loss: 0.0809 - accuracy: 0.96 - ETA: 1s - loss: 0.0776 - accuracy: 0.96 - ETA: 1s - loss: 0.0852 - accuracy: 0.96 - ETA: 1s - loss: 0.0813 - accuracy: 0.96 - ETA: 1s - loss: 0.0821 - accuracy: 0.96 - ETA: 0s - loss: 0.0805 - accuracy: 0.96 - ETA: 0s - loss: 0.0791 - accuracy: 0.96 - ETA: 0s - loss: 0.0767 - accuracy: 0.97 - ETA: 0s - loss: 0.0830 - accuracy: 0.96 - ETA: 0s - loss: 0.0878 - accuracy: 0.96 - ETA: 0s - loss: 0.1005 - accuracy: 0.96 - ETA: 0s - loss: 0.1093 - accuracy: 0.96 - ETA: 0s - loss: 0.1208 - accuracy: 0.96 - ETA: 0s - loss: 0.1174 - accuracy: 0.96 - ETA: 0s - loss: 0.1186 - accuracy: 0.96 - 4s 3ms/sample - loss: 0.1248 - accuracy: 0.9608 - val_loss: 0.6506 - val_accuracy: 0.8583\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0197 - accuracy: 1.00 - ETA: 2s - loss: 0.0513 - accuracy: 0.98 - ETA: 2s - loss: 0.0411 - accuracy: 0.98 - ETA: 2s - loss: 0.0333 - accuracy: 0.99 - ETA: 2s - loss: 0.0480 - accuracy: 0.98 - ETA: 2s - loss: 0.0587 - accuracy: 0.97 - ETA: 2s - loss: 0.0749 - accuracy: 0.97 - ETA: 2s - loss: 0.0845 - accuracy: 0.96 - ETA: 2s - loss: 0.0820 - accuracy: 0.97 - ETA: 2s - loss: 0.1717 - accuracy: 0.96 - ETA: 2s - loss: 0.2481 - accuracy: 0.96 - ETA: 2s - loss: 0.2304 - accuracy: 0.96 - ETA: 1s - loss: 0.2219 - accuracy: 0.96 - ETA: 1s - loss: 0.2072 - accuracy: 0.96 - ETA: 1s - loss: 0.1936 - accuracy: 0.97 - ETA: 1s - loss: 0.1928 - accuracy: 0.96 - ETA: 1s - loss: 0.2512 - accuracy: 0.96 - ETA: 1s - loss: 0.2482 - accuracy: 0.95 - ETA: 1s - loss: 0.2433 - accuracy: 0.95 - ETA: 1s - loss: 0.2315 - accuracy: 0.95 - ETA: 1s - loss: 0.2228 - accuracy: 0.95 - ETA: 1s - loss: 0.2156 - accuracy: 0.95 - ETA: 0s - loss: 0.2094 - accuracy: 0.95 - ETA: 0s - loss: 0.2041 - accuracy: 0.96 - ETA: 0s - loss: 0.2009 - accuracy: 0.96 - ETA: 0s - loss: 0.1935 - accuracy: 0.96 - ETA: 0s - loss: 0.1871 - accuracy: 0.96 - ETA: 0s - loss: 0.1812 - accuracy: 0.96 - ETA: 0s - loss: 0.1784 - accuracy: 0.96 - ETA: 0s - loss: 0.1733 - accuracy: 0.96 - ETA: 0s - loss: 0.1698 - accuracy: 0.96 - ETA: 0s - loss: 0.1651 - accuracy: 0.96 - 4s 3ms/sample - loss: 0.1667 - accuracy: 0.9656 - val_loss: 0.6075 - val_accuracy: 0.8563\n",
      "Epoch 47/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0085 - accuracy: 1.00 - ETA: 2s - loss: 0.0202 - accuracy: 1.00 - ETA: 2s - loss: 0.0206 - accuracy: 1.00 - ETA: 2s - loss: 0.0212 - accuracy: 1.00 - ETA: 2s - loss: 0.0171 - accuracy: 1.00 - ETA: 2s - loss: 0.0194 - accuracy: 1.00 - ETA: 2s - loss: 0.0182 - accuracy: 1.00 - ETA: 2s - loss: 0.0316 - accuracy: 0.99 - ETA: 2s - loss: 0.0311 - accuracy: 0.99 - ETA: 2s - loss: 0.0491 - accuracy: 0.99 - ETA: 2s - loss: 0.0505 - accuracy: 0.98 - ETA: 2s - loss: 0.0476 - accuracy: 0.98 - ETA: 1s - loss: 0.0460 - accuracy: 0.99 - ETA: 1s - loss: 0.0443 - accuracy: 0.99 - ETA: 1s - loss: 0.0527 - accuracy: 0.98 - ETA: 1s - loss: 0.0566 - accuracy: 0.98 - ETA: 1s - loss: 0.0590 - accuracy: 0.98 - ETA: 1s - loss: 0.0574 - accuracy: 0.98 - ETA: 1s - loss: 0.0582 - accuracy: 0.98 - ETA: 1s - loss: 0.0560 - accuracy: 0.98 - ETA: 1s - loss: 0.0617 - accuracy: 0.98 - ETA: 1s - loss: 0.0599 - accuracy: 0.98 - ETA: 0s - loss: 0.0586 - accuracy: 0.98 - ETA: 0s - loss: 0.0574 - accuracy: 0.98 - ETA: 0s - loss: 0.0554 - accuracy: 0.98 - ETA: 0s - loss: 0.0674 - accuracy: 0.98 - ETA: 0s - loss: 0.0664 - accuracy: 0.98 - ETA: 0s - loss: 0.0641 - accuracy: 0.98 - ETA: 0s - loss: 0.0705 - accuracy: 0.98 - ETA: 0s - loss: 0.0798 - accuracy: 0.98 - ETA: 0s - loss: 0.0774 - accuracy: 0.98 - ETA: 0s - loss: 0.0751 - accuracy: 0.98 - 4s 4ms/sample - loss: 0.0814 - accuracy: 0.9837 - val_loss: 0.7727 - val_accuracy: 0.7903\n",
      "Epoch 48/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0058 - accuracy: 1.00 - ETA: 2s - loss: 0.0103 - accuracy: 1.00 - ETA: 2s - loss: 0.0135 - accuracy: 1.00 - ETA: 2s - loss: 0.1627 - accuracy: 0.98 - ETA: 2s - loss: 0.1404 - accuracy: 0.98 - ETA: 2s - loss: 0.1794 - accuracy: 0.97 - ETA: 2s - loss: 0.1579 - accuracy: 0.97 - ETA: 2s - loss: 0.1579 - accuracy: 0.97 - ETA: 2s - loss: 0.1442 - accuracy: 0.97 - ETA: 2s - loss: 0.1302 - accuracy: 0.97 - ETA: 2s - loss: 0.1192 - accuracy: 0.97 - ETA: 2s - loss: 0.1206 - accuracy: 0.97 - ETA: 1s - loss: 0.1114 - accuracy: 0.97 - ETA: 1s - loss: 0.1139 - accuracy: 0.97 - ETA: 1s - loss: 0.1080 - accuracy: 0.97 - ETA: 1s - loss: 0.1014 - accuracy: 0.97 - ETA: 1s - loss: 0.0966 - accuracy: 0.97 - ETA: 1s - loss: 0.0921 - accuracy: 0.98 - ETA: 1s - loss: 0.0904 - accuracy: 0.98 - ETA: 1s - loss: 0.0889 - accuracy: 0.97 - ETA: 1s - loss: 0.0883 - accuracy: 0.97 - ETA: 1s - loss: 0.0843 - accuracy: 0.98 - ETA: 0s - loss: 0.0814 - accuracy: 0.98 - ETA: 0s - loss: 0.0805 - accuracy: 0.98 - ETA: 0s - loss: 0.0786 - accuracy: 0.98 - ETA: 0s - loss: 0.0761 - accuracy: 0.98 - ETA: 0s - loss: 0.0739 - accuracy: 0.98 - ETA: 0s - loss: 0.0731 - accuracy: 0.98 - ETA: 0s - loss: 0.0707 - accuracy: 0.98 - ETA: 0s - loss: 0.0683 - accuracy: 0.98 - ETA: 0s - loss: 0.0662 - accuracy: 0.98 - ETA: 0s - loss: 0.0645 - accuracy: 0.98 - 8s 8ms/sample - loss: 0.0643 - accuracy: 0.9856 - val_loss: 0.3098 - val_accuracy: 0.9243\n",
      "Epoch 49/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0040 - accuracy: 1.00 - ETA: 3s - loss: 0.0151 - accuracy: 1.00 - ETA: 3s - loss: 0.0284 - accuracy: 0.98 - ETA: 3s - loss: 0.0361 - accuracy: 0.98 - ETA: 2s - loss: 0.0302 - accuracy: 0.98 - ETA: 2s - loss: 0.0282 - accuracy: 0.98 - ETA: 2s - loss: 0.0275 - accuracy: 0.99 - ETA: 2s - loss: 0.0267 - accuracy: 0.99 - ETA: 2s - loss: 0.0248 - accuracy: 0.99 - ETA: 2s - loss: 0.0225 - accuracy: 0.99 - ETA: 2s - loss: 0.0211 - accuracy: 0.99 - ETA: 2s - loss: 0.0201 - accuracy: 0.99 - ETA: 1s - loss: 0.0202 - accuracy: 0.99 - ETA: 1s - loss: 0.0242 - accuracy: 0.99 - ETA: 1s - loss: 0.1061 - accuracy: 0.98 - ETA: 1s - loss: 0.1001 - accuracy: 0.98 - ETA: 1s - loss: 0.0944 - accuracy: 0.98 - ETA: 1s - loss: 0.0892 - accuracy: 0.98 - ETA: 1s - loss: 0.0971 - accuracy: 0.98 - ETA: 1s - loss: 0.0923 - accuracy: 0.98 - ETA: 1s - loss: 0.0880 - accuracy: 0.98 - ETA: 1s - loss: 0.0854 - accuracy: 0.98 - ETA: 0s - loss: 0.0836 - accuracy: 0.98 - ETA: 0s - loss: 0.0876 - accuracy: 0.98 - ETA: 0s - loss: 0.0863 - accuracy: 0.98 - ETA: 0s - loss: 0.0843 - accuracy: 0.98 - ETA: 0s - loss: 0.0818 - accuracy: 0.98 - ETA: 0s - loss: 0.0791 - accuracy: 0.98 - ETA: 0s - loss: 0.0767 - accuracy: 0.98 - ETA: 0s - loss: 0.0749 - accuracy: 0.98 - ETA: 0s - loss: 0.0726 - accuracy: 0.98 - ETA: 0s - loss: 0.0705 - accuracy: 0.98 - 4s 3ms/sample - loss: 0.0694 - accuracy: 0.9866 - val_loss: 0.3241 - val_accuracy: 0.9223\n",
      "Epoch 50/50\n",
      "1045/1045 [==============================] - ETA: 3s - loss: 0.0037 - accuracy: 1.00 - ETA: 2s - loss: 0.0027 - accuracy: 1.00 - ETA: 2s - loss: 0.0054 - accuracy: 1.00 - ETA: 2s - loss: 0.0157 - accuracy: 0.99 - ETA: 2s - loss: 0.0134 - accuracy: 0.99 - ETA: 2s - loss: 0.0115 - accuracy: 0.99 - ETA: 2s - loss: 0.0195 - accuracy: 0.99 - ETA: 2s - loss: 0.0171 - accuracy: 0.99 - ETA: 2s - loss: 0.0384 - accuracy: 0.98 - ETA: 2s - loss: 0.0350 - accuracy: 0.98 - ETA: 2s - loss: 0.0323 - accuracy: 0.98 - ETA: 2s - loss: 0.0305 - accuracy: 0.98 - ETA: 1s - loss: 0.0294 - accuracy: 0.99 - ETA: 1s - loss: 0.0278 - accuracy: 0.99 - ETA: 1s - loss: 0.0281 - accuracy: 0.98 - ETA: 1s - loss: 0.0284 - accuracy: 0.98 - ETA: 1s - loss: 0.0268 - accuracy: 0.98 - ETA: 1s - loss: 0.0357 - accuracy: 0.98 - ETA: 1s - loss: 0.0342 - accuracy: 0.98 - ETA: 1s - loss: 0.0339 - accuracy: 0.98 - ETA: 1s - loss: 0.0327 - accuracy: 0.98 - ETA: 1s - loss: 0.0326 - accuracy: 0.98 - ETA: 0s - loss: 0.0312 - accuracy: 0.98 - ETA: 0s - loss: 0.0301 - accuracy: 0.98 - ETA: 0s - loss: 0.0291 - accuracy: 0.99 - ETA: 0s - loss: 0.0282 - accuracy: 0.99 - ETA: 0s - loss: 0.0273 - accuracy: 0.99 - ETA: 0s - loss: 0.0391 - accuracy: 0.99 - ETA: 0s - loss: 0.0381 - accuracy: 0.99 - ETA: 0s - loss: 0.0369 - accuracy: 0.99 - ETA: 0s - loss: 0.0366 - accuracy: 0.99 - ETA: 0s - loss: 0.0363 - accuracy: 0.99 - 8s 8ms/sample - loss: 0.0356 - accuracy: 0.9914 - val_loss: 0.3135 - val_accuracy: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d25fcb3eda024f111d3fe23c199f0101</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.9339805841445923</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-conv3_depth: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-conv4_depth: 6</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-pooling: max</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-version: v1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=50,\n",
    "             validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 34, 34, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 14, 14, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 14, 14, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 14, 14, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 16, 16, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 7, 7, 64)     0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 7, 7, 64)     4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 7, 7, 64)     0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 7, 7, 64)     36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 7, 7, 64)     0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 7, 7, 256)    16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 7, 7, 256)    16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 7, 7, 256)    1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 7, 7, 256)    1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 7, 7, 256)    0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 7, 7, 256)    0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 7, 7, 64)     16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 7, 7, 64)     0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 7, 7, 64)     36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 7, 7, 64)     0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 7, 7, 256)    16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 7, 7, 256)    1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 7, 7, 256)    0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 7, 7, 256)    0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 7, 7, 64)     16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 7, 7, 64)     0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 7, 7, 64)     36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 7, 7, 64)     256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 7, 7, 64)     0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 7, 7, 256)    16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 7, 7, 256)    1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 7, 7, 256)    0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2_block3_out (Activation)   (None, 7, 7, 256)    0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool (GlobalMaxPooling2D)   (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 27)           55323       max_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,643,035\n",
      "Trainable params: 23,589,915\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('ResnetBraille.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
